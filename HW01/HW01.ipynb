{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML2021Spring - HW1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meibohuhu/python_projects/blob/main/HW01/HW01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0_QVkxCrX3"
      },
      "source": [
        "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZnPAiwDRWG"
      },
      "source": [
        "Author: Heng-Jui Chang\n",
        "\n",
        "Slides: https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.pdf  \n",
        "Videos (Mandarin): https://cool.ntu.edu.tw/courses/4793/modules/items/172854  \n",
        "https://cool.ntu.edu.tw/courses/4793/modules/items/172853  \n",
        "Video (English): https://cool.ntu.edu.tw/courses/4793/modules/items/176529\n",
        "\n",
        "\n",
        "Objectives:\n",
        "* Solve a regression problem with deep neural networks (DNN).\n",
        "* Understand basic DNN training tips.\n",
        "* Get familiar with PyTorch.\n",
        "\n",
        "If any questions, please contact the TAs via TA hours, NTU COOL, or email.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx3x1nDkG-Uy"
      },
      "source": [
        "# **Download Data**\n",
        "\n",
        "\n",
        "If the Google drive links are dead, you can download data from [kaggle](https://www.kaggle.com/c/ml2021spring-hw1/data), and upload data manually to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMj55YDKG6ch",
        "outputId": "3b8c8239-91ee-4155-e16e-27c1436b0f0c"
      },
      "source": [
        "tr_path = 'covid.train.csv'  # path to training data\n",
        "tt_path = 'covid.test.csv'   # path to testing data\n",
        "\n",
        "!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
        "!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n",
            "To: /content/covid.train.csv\n",
            "100% 2.00M/2.00M [00:00<00:00, 19.0MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n",
            "To: /content/covid.test.csv\n",
            "100% 651k/651k [00:00<00:00, 28.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_4-77xHk44"
      },
      "source": [
        "# **Import Some Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-onQd4JNA5H"
      },
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "myseed = 42069  # set a random seed for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtE3b6JEH7rw"
      },
      "source": [
        "# **Some Utilities**\n",
        "\n",
        "You do not need to modify this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWMT3uf1NGQp"
      },
      "source": [
        "def get_device():\n",
        "    ''' Get device (if GPU is available, use GPU) '''\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
        "    plt.ylim(0.0, 5.)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure(figsize=(5, 5))\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39U_XFX6KOoj"
      },
      "source": [
        "# **Preprocess**\n",
        "\n",
        "We have three kinds of datasets:\n",
        "* `train`: for training\n",
        "* `dev`: for validation\n",
        "* `test`: for testing (w/o target value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ-MdwpLL7Dt"
      },
      "source": [
        "## **Dataset**\n",
        "\n",
        "The `COVID19Dataset` below does:\n",
        "* read `.csv` files\n",
        "* extract features\n",
        "* split `covid.train.csv` into train/dev sets\n",
        "* normalize features\n",
        "\n",
        "Finishing `TODO` below might make you pass medium baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zlpIp9ANJRU"
      },
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
        "    def __init__(self,\n",
        "                 path,\n",
        "                 mode='train',\n",
        "                 target_only=False):\n",
        "        self.mode = mode\n",
        "\n",
        "        # Read data into numpy arrays\n",
        "        with open(path, 'r') as fp:\n",
        "            data = list(csv.reader(fp))\n",
        "            data = np.array(data[1:])[:, 1:].astype(float)\n",
        "        print(f\"data id: {data}:\")\n",
        "        if not target_only:\n",
        "            feats = list(range(93))\n",
        "            print(f\"feats id: {feats}:\")\n",
        "        else:\n",
        "            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n",
        "            pass\n",
        "\n",
        "        if mode == 'test':\n",
        "            # Testing data\n",
        "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
        "            data = data[:, feats]\n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            # Training data (train/dev sets)\n",
        "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
        "            target = data[:, -1]   ## y labels: 1\n",
        "            data = data[:, feats]   ## features: 93\n",
        "\n",
        "            # Splitting training data into train & dev sets\n",
        "            if mode == 'train':\n",
        "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
        "\n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data[indices])\n",
        "            self.target = torch.FloatTensor(target[indices])\n",
        "            print(f\"data.shape: {self.data.shape}\")\n",
        "            print(f\"target: {self.target}\")\n",
        "            print(f\"target.shape: {self.target.shape}\")\n",
        "\n",
        "        # Normalize features (you may remove this part to see what will happen)\n",
        "        self.data[:, 40:] = \\\n",
        "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
        "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "        print(f\"self.dim is {self.dim}\")\n",
        "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
        "              .format(mode, len(self.data), self.dim))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]   # Returns (x, y) pair\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]    # Test mode - only x, no y\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns the size of the dataset\n",
        "        return len(self.data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlhTlkE7MDo3"
      },
      "source": [
        "## **DataLoader**\n",
        "\n",
        "A `DataLoader` loads data from a given `Dataset` into batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlhLk5t6MBX3"
      },
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
        "    return dataloader"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGuycwR0MeQB"
      },
      "source": [
        "# **Deep Neural Network**\n",
        "\n",
        "`NeuralNet` is an `nn.Module` designed for regression.\n",
        "The DNN consists of 2 fully-connected layers with ReLU activation.\n",
        "This module also included a function `cal_loss` for calculating loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49-uXYovOAI0"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        # self.net = nn.Sequential(\n",
        "        #     nn.Linear(input_dim, 64),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(64, 1)\n",
        "        # )\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),  # First layer: input_dim -> 128 neurons\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),         # Second layer: 128 -> 64 neurons\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)           # Output layer: 64 -> 1 neuron\n",
        "        )\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "        self.lambda_l1 = 0.01  # Add this line to initialize lambda_l1  ## mhu\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "        ''' Calculate loss '''\n",
        "        # TODO: you may implement L1/L2 regularization here\n",
        "        # return self.criterion(pred, target)\n",
        "        print(f\"pred: {pred}\")\n",
        "        print(f\"target: {target}\")\n",
        "        return self.l1_loss(pred, target)  # Fixed line      ## mhu\n",
        "\n",
        "    def l1_loss(self, y_pred, y_true):  # Only need self, y_pred, y_true as parameters    ## mhu\n",
        "        # Calculate MSE loss\n",
        "        mse_loss = self.criterion(y_pred, y_true)\n",
        "\n",
        "        # Calculate L1 regularization term\n",
        "        l1_reg = torch.tensor(0., requires_grad=True)\n",
        "        for param in self.net.parameters():\n",
        "            l1_reg = l1_reg + torch.norm(param, 1)\n",
        "            print(f\"parameters shape are: {param.shape}\")\n",
        "            print(f\"parameters are: {param}\")\n",
        "        print(f\"l1_reg is: {l1_reg}\")\n",
        "        # Combine MSE with L1 regularization\n",
        "        total_loss = mse_loss + self.lambda_l1 * l1_reg\n",
        "        print(f\"total_loss {total_loss}\")\n",
        "        return total_loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvFWVjZ5Nvga"
      },
      "source": [
        "# **Train/Dev/Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAM8QecJOyqn"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOqcmYzMO7jB"
      },
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    ''' DNN training '''\n",
        "\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(  ## optimizer is SGD\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    min_mse = 1000.\n",
        "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()                           # set model to training mode\n",
        "        for x, y in tr_set:                     # iterate through the dataloader\n",
        "            optimizer.zero_grad()               # set gradient to zero\n",
        "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
        "            # print(f\"x, y are {x}, {y}\")\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
        "            optimizer.step()                    # update model with optimizer\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "\n",
        "        # After each epoch, test your model on the validation (development) set.\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
        "                .format(epoch + 1, min_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "\n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_mse, loss_record"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hSd4Bn3O2PL"
      },
      "source": [
        "## **Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrxrD3YsN3U2"
      },
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:                         # iterate through the dataloader\n",
        "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0pdrhQAO41L"
      },
      "source": [
        "## **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSBMRFlYN5tB"
      },
      "source": [
        "def test(tt_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    preds = []\n",
        "    for x in tt_set:                            # iterate through the dataloader\n",
        "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            preds.append(pred.detach().cpu())   # collect prediction\n",
        "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
        "    return preds"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvckkF5dvf0j"
      },
      "source": [
        "# **Setup Hyper-parameters**\n",
        "\n",
        "`config` contains hyper-parameters for training and the path to save your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPXpdumwPjE7"
      },
      "source": [
        "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "target_only = False                   # TODO: Using 40 states & 2 tested_positive features\n",
        "\n",
        "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
        "config = {\n",
        "    'n_epochs': 1000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)  Stochastic Gradient Descent\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j1eOV3TOH-j"
      },
      "source": [
        "# **Load data and model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNrYBMmePLKm",
        "outputId": "fea53f6a-e2b0-4cbd-91de-b5c89f8e1d0b"
      },
      "source": [
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
        "print(f\"training set size: {tr_set}\")\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data id: [[ 1.         0.         0.        ... 53.9915494 43.6042293 20.7049346]\n",
            " [ 1.         0.         0.        ... 54.185521  42.6657659 21.2929114]\n",
            " [ 1.         0.         0.        ... 53.6370693 42.972417  21.1666563]\n",
            " ...\n",
            " [ 0.         0.         0.        ... 67.731162  38.740651  12.6134414]\n",
            " [ 0.         0.         0.        ... 67.7950996 38.595125  12.4772268]\n",
            " [ 0.         0.         0.        ... 68.2840782 38.4538196 11.8117187]]:\n",
            "feats id: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92]:\n",
            "data.shape: torch.Size([2430, 93])\n",
            "target: tensor([21.2929, 21.1667, 19.8966,  ..., 12.6134, 12.4772, 11.8117])\n",
            "target.shape: torch.Size([2430])\n",
            "self.dim is 93\n",
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)\n",
            "training set size: <torch.utils.data.dataloader.DataLoader object at 0x7e3351a87b50>\n",
            "data id: [[ 1.         0.         0.        ... 53.9915494 43.6042293 20.7049346]\n",
            " [ 1.         0.         0.        ... 54.185521  42.6657659 21.2929114]\n",
            " [ 1.         0.         0.        ... 53.6370693 42.972417  21.1666563]\n",
            " ...\n",
            " [ 0.         0.         0.        ... 67.731162  38.740651  12.6134414]\n",
            " [ 0.         0.         0.        ... 67.7950996 38.595125  12.4772268]\n",
            " [ 0.         0.         0.        ... 68.2840782 38.4538196 11.8117187]]:\n",
            "feats id: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92]:\n",
            "data.shape: torch.Size([270, 93])\n",
            "target: tensor([20.7049, 14.7807, 15.6246, 16.3530, 21.1403, 20.8325, 24.9998,  3.5714,\n",
            "         8.6364,  5.7692,  8.6777,  2.8689, 13.1818, 16.1972,  6.8915,  6.3984,\n",
            "         5.9165,  7.7938,  7.7073, 12.3563, 12.7403, 14.3317, 11.1861, 21.9149,\n",
            "        15.7216, 20.2072, 25.5939,  7.4021,  6.4085,  6.0283,  5.9251,  5.5663,\n",
            "         7.7832,  7.3929,  6.8333,  4.4167,  8.1111,  8.1560, 10.5540, 19.6793,\n",
            "        19.3069,  3.7081,  3.7349,  3.5714,  5.3172,  7.1256,  9.6074,  9.9155,\n",
            "         9.7659,  9.7680,  9.4623, 12.0087, 10.4674, 14.1234, 13.6284, 16.2547,\n",
            "        12.1887, 13.4219, 11.4552, 13.7278, 14.9270, 16.9451, 13.5416, 24.6665,\n",
            "        25.5589, 31.2903, 33.9516,  8.7232,  9.4743, 10.4471, 10.4545, 13.6004,\n",
            "        21.5362, 24.7947,  8.0300, 10.0231, 10.1980, 13.5331, 17.4769, 24.8762,\n",
            "        26.2595, 15.9436, 16.9328, 17.6547, 20.6308, 22.7727, 35.3088, 36.3085,\n",
            "         9.6535, 14.2492, 17.8857, 18.5279, 27.2095, 34.6939,  5.5838,  8.7310,\n",
            "         5.3524, 10.9467, 10.6357, 15.4454, 17.5906, 15.9164, 12.1667, 11.6864,\n",
            "        18.8136, 16.1972, 20.7895, 19.6934,  3.4328,  5.3623,  6.6978,  4.7965,\n",
            "         7.0447,  7.5002,  2.7955,  2.6699,  2.9236,  4.3846,  2.8400,  4.2266,\n",
            "         6.3151,  3.5552,  5.7635,  9.5210,  7.8600, 11.7246, 21.8559, 21.3177,\n",
            "         8.4688,  9.5714, 10.6358, 13.0657, 15.2333, 25.8462, 23.3341, 26.2862,\n",
            "        24.1377, 25.5078, 32.0859, 34.6538, 32.1228, 27.8052, 21.7863, 24.6114,\n",
            "        23.7782, 25.3970, 25.9979, 19.5248, 25.9552, 25.1661, 25.5945, 22.8514,\n",
            "        21.9144, 24.1784, 18.4365, 21.6929, 25.4017, 24.9391, 25.2821, 27.2217,\n",
            "        21.4053, 18.9927, 11.9544, 13.8410, 14.0538, 13.6969, 15.8808, 13.5315,\n",
            "        19.8848, 16.4687, 18.2368, 13.7259, 17.7635, 15.5539, 14.0926,  6.9774,\n",
            "         8.3083,  9.6499, 11.0942, 12.5183, 13.5763, 12.8692, 12.9802, 13.9286,\n",
            "        18.6407, 18.1189, 20.1045, 20.9195, 20.7997, 23.7527, 24.5305, 26.1734,\n",
            "        24.5663, 26.8204, 25.4401, 20.5535, 22.1942, 26.6685, 28.8944, 28.5828,\n",
            "        35.6474, 26.9797,  9.8705, 11.2216,  9.6731, 13.3239, 12.5317, 12.5703,\n",
            "         8.2829, 19.1983, 22.5969, 23.5935, 25.9001, 24.6988, 25.2553, 21.3563,\n",
            "        12.1133, 16.9385, 17.0957,  8.9584, 13.6514,  9.6829, 10.1373, 10.3420,\n",
            "        17.6791, 20.2152, 20.7517, 25.9487, 24.4629, 20.1631, 20.3369, 21.6015,\n",
            "        23.2329, 24.6127, 28.6281, 25.0085, 27.3285, 22.5122, 25.8700, 23.2383,\n",
            "        27.3183, 31.4549, 20.4373, 12.4127, 15.8738, 17.5510, 21.0565, 19.5545,\n",
            "        24.4510, 22.1006,  9.8401, 10.0151, 11.3076, 11.8321, 10.3945, 11.5500,\n",
            "         9.4237, 16.0550, 16.3664, 19.7704, 20.4319, 23.6292, 21.6321, 16.5551,\n",
            "        21.9787, 20.1007, 18.6773, 12.9403, 17.1829, 13.6446])\n",
            "target.shape: torch.Size([270])\n",
            "self.dim is 93\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 93)\n",
            "data id: [[ 0.         0.         0.        ... 24.7478373 66.1949496 44.8734726]\n",
            " [ 0.         0.         0.        ... 23.5596222 57.0150091 38.3728286]\n",
            " [ 0.         0.         0.        ... 24.9933415 55.291498  38.9072574]\n",
            " ...\n",
            " [ 0.         0.         0.        ... 22.4236395 60.9348512 43.1225126]\n",
            " [ 0.         0.         0.        ... 17.4760626 54.8623859 44.0162552]\n",
            " [ 0.         0.         0.        ... 21.2171063 66.8707632 37.9308586]]:\n",
            "feats id: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92]:\n",
            "self.dim is 93\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHylSirLP9oh"
      },
      "source": [
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX2B_zgSOPTJ"
      },
      "source": [
        "# **Start Training!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrEbUxazQAAZ",
        "outputId": "01d257b9-6a8f-45d4-94f6-c536598a552a"
      },
      "source": [
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [-3.9220e-05, -5.4516e-07,  2.8758e-05,  ..., -7.1590e-07,\n",
            "          1.2932e-05, -2.8335e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.7084e-06,  4.2559e-01,  3.5998e-02,  1.8689e-05, -8.9331e-06,\n",
            "         1.6768e-05, -1.1742e-06,  1.0716e-05,  1.5795e+00, -1.7202e-05,\n",
            "         2.9985e-06, -1.9338e-05, -1.4051e-05,  3.4900e-06, -3.0337e-05,\n",
            "        -8.4935e-06,  9.0654e-06, -1.2462e-05,  1.2374e-05,  6.1391e-06,\n",
            "         3.0761e-06,  2.2951e-06, -1.6343e-06, -3.7745e-06,  1.7168e-05,\n",
            "         1.6260e-05,  1.5772e-05,  1.3502e-01, -2.4685e-05,  9.5109e-06,\n",
            "        -4.8370e-06, -1.2206e-05, -9.2805e-06,  2.8766e-01,  1.1484e-05,\n",
            "         2.0776e-07,  4.4611e-06, -1.0975e-05, -6.2642e-06,  2.4914e-06,\n",
            "        -1.2029e-05, -8.3170e-06,  8.0744e-06,  4.3803e-06, -1.3546e-05,\n",
            "        -2.4170e-05, -1.0441e-05, -1.5043e-05,  2.5203e-05,  2.2359e-04,\n",
            "         1.7137e-06,  5.6751e-06,  7.1843e-08, -5.1583e-06, -1.2284e-05,\n",
            "         2.5519e-06,  7.3844e-05,  6.5708e-06,  1.1854e-05,  4.8938e-06,\n",
            "        -1.5758e-05, -2.2075e-06, -2.6826e-05, -8.0983e-06,  1.8398e-05,\n",
            "         1.0776e-05,  1.0507e-05,  3.3264e-06,  2.1032e-06,  9.4496e-02,\n",
            "        -1.2997e-05,  6.3236e-06,  1.4051e-06, -6.9836e-06, -1.3672e-05,\n",
            "        -4.5732e-06, -3.9334e-06, -2.2668e-05, -9.7291e-06, -1.8337e-03,\n",
            "        -2.6083e-06, -4.3631e-06,  6.7689e-06,  4.1503e-07,  7.9370e-06,\n",
            "         2.9111e-06, -7.3375e-08,  2.4497e-05, -5.9025e-06,  2.0547e-06,\n",
            "         1.0259e-05, -1.2414e-05,  1.0270e-05, -1.1416e-06,  9.8528e-06,\n",
            "         9.1024e-06, -1.1402e-05, -1.1898e-06,  8.3581e-06,  3.8367e-07,\n",
            "         3.4084e-04, -3.0937e-06, -6.0717e-06, -1.6846e-05, -2.0057e-07,\n",
            "         1.9982e-05, -3.4190e-06,  7.0539e-06, -3.7093e-06,  1.6578e-05,\n",
            "         1.0128e-05, -1.3260e-05,  4.6820e-06,  9.1410e-06, -1.3996e-06,\n",
            "        -2.6583e-05, -2.5357e-05,  1.6884e-05,  1.2846e-05, -9.3537e-06,\n",
            "         1.2615e+00, -1.7263e-07, -1.8721e-06,  1.7141e-05, -1.7171e-05,\n",
            "         5.1769e-07,  1.9409e-05,  3.5767e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.0889e-05, -1.1894e-04, -1.0261e-05,  ..., -4.4634e-06,\n",
            "         -1.3256e-05,  1.8123e-05],\n",
            "        [ 8.7731e-06,  1.7391e-06,  2.3556e-05,  ..., -1.8322e-05,\n",
            "         -6.7030e-06,  2.1717e-05],\n",
            "        [ 7.8674e-06,  5.1806e-06, -1.5999e-05,  ..., -4.8358e-07,\n",
            "         -1.2796e-05,  8.1446e-06],\n",
            "        ...,\n",
            "        [-2.6559e-07, -1.0149e-05,  3.5515e-06,  ..., -8.0641e-06,\n",
            "         -3.6667e-06,  1.3935e-05],\n",
            "        [ 1.0026e-05, -4.0431e-05,  2.0937e-04,  ..., -8.4985e-06,\n",
            "          8.0461e-06, -7.2210e-06],\n",
            "        [-4.0740e-06,  8.5479e-05,  3.9002e-05,  ...,  5.7776e-06,\n",
            "          7.1680e-07, -1.5184e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.5096e-02, -6.3857e-06,  6.7769e-06, -1.9758e-06, -8.7111e-06,\n",
            "         1.8830e-05, -1.2603e-05,  6.9734e-07, -6.8402e-06,  7.6594e-06,\n",
            "         2.6562e-06,  7.7645e-06,  1.1807e-05,  5.4202e-06,  8.9598e-06,\n",
            "        -4.3135e-06,  4.5867e-06, -5.1824e-07, -1.1457e-05,  1.2451e-05,\n",
            "        -1.7854e-05,  1.4031e-05, -1.9637e-05, -1.5969e-05, -3.2308e-05,\n",
            "         2.2119e-06, -3.5297e-07,  2.5795e-05,  9.9067e-06,  1.8722e-05,\n",
            "         1.1038e-06,  3.3680e-06,  1.0397e-06, -8.6250e-06, -1.9469e-05,\n",
            "         8.0695e-06,  3.1033e-05,  1.1828e-05,  1.6523e-05, -3.4009e-05,\n",
            "         2.0253e-05, -2.2937e-05,  3.8826e-06, -2.9395e-05, -1.3165e-05,\n",
            "        -1.1038e-05,  6.4901e-06, -1.0253e-05, -5.3336e-06, -4.8463e-06,\n",
            "        -3.3864e-06,  1.0852e+00,  4.8139e-06,  3.6911e-06,  1.1716e-05,\n",
            "         9.0060e-02, -1.2414e-05,  1.2531e-06, -2.9399e-05,  8.3389e-06,\n",
            "        -2.3524e-06,  3.8401e-05,  2.6101e-01,  1.7672e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3576e-01,  1.0921e-05, -1.7282e-05, -3.6306e-05, -5.3796e-06,\n",
            "          1.3848e-05,  1.4885e-05, -5.7578e-06, -9.9661e-06, -1.2599e-05,\n",
            "         -2.4436e-05, -3.0825e-05,  1.2023e-05, -9.8161e-06, -1.2826e-05,\n",
            "          5.4512e-06,  2.3587e-06,  2.0685e-05,  5.0499e-06, -1.6611e-05,\n",
            "          7.8425e-06,  7.6343e-06, -1.9896e-05, -1.0108e-05,  5.4839e-01,\n",
            "          5.7374e-06,  3.4569e-05, -4.6944e-06, -1.4531e-05,  1.1750e-05,\n",
            "         -3.8251e-05, -1.3873e-05,  1.0364e-05,  2.3145e-06, -7.5814e-06,\n",
            "         -1.8265e-05, -1.3592e-06,  6.6918e-06, -1.7065e-05, -1.0739e-05,\n",
            "          8.5675e-06, -6.4076e-07,  3.4991e-06,  4.8716e-05,  1.3114e-06,\n",
            "         -2.9701e-05,  9.9387e-06, -1.8527e-05, -1.9114e-06,  1.0223e-05,\n",
            "          1.0186e-05,  3.2322e+00, -3.8130e-06,  1.2202e-05,  1.5073e-05,\n",
            "          7.8512e-01,  1.1987e-05,  1.1735e-05, -2.4023e-06,  1.2656e-06,\n",
            "          8.9602e-08, -1.8253e-05,  1.0874e+00,  2.4155e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3109], requires_grad=True)\n",
            "l1_reg is: 30.189655303955078\n",
            "total_loss 1.097212791442871\n",
            "pred: tensor([26.5582, 25.4914, 15.5796, 13.9736, 20.4506, 21.5608,  9.5051,  8.3350,\n",
            "        14.3645, 14.2748, 10.2403,  7.6699, 25.5418, 10.0851, 16.9937, 26.9591,\n",
            "        25.6751, 21.5357, 21.1445, 10.3640, 22.2281, 13.3404, 27.1556, 11.1275,\n",
            "         6.7088, 21.2960, 12.1206, 19.3792,  3.0237,  6.2500, 12.8585, 22.4946,\n",
            "        26.6241,  9.3993, 18.2859, 10.2924,  5.6122, 17.0400, 11.7930, 12.6467,\n",
            "         8.3800, 20.2628, 19.6343, 10.5906, 16.9508, 23.1132, 14.5372, 20.4643,\n",
            "        13.5265, 13.6289, 26.9843,  5.0654, 24.2709,  3.7603, 11.6019,  5.9801,\n",
            "        26.9969, 27.9283, 12.1891, 16.6239, 10.4931, 12.7594, 11.9255, 20.2287,\n",
            "        14.7849, 23.1830, 15.7043, 19.4944, 15.7684, 25.7718, 13.2412, 26.5700,\n",
            "         3.5130, 16.4621, 13.8645, 12.8682,  3.5823, 18.5379, 16.4814, 22.2399,\n",
            "        30.5875, 35.6538, 14.0007, 23.2452, 28.0019, 10.0873, 10.3396, 15.6818,\n",
            "        10.1074, 15.7261, 14.4833, 13.2802, 22.2587,  2.8522,  6.7601, 10.7404,\n",
            "        14.0211, 20.6401,  5.5108, 11.9683,  8.4725, 26.1603,  6.2343, 22.7078,\n",
            "        20.7597, 11.9441, 23.9721, 23.0796,  9.1178, 39.8531, 16.9114, 20.8729,\n",
            "        16.6688, 23.2189,  5.4419, 26.0861, 16.4584, 11.7048, 18.6460,  3.5853,\n",
            "        13.5511,  6.8850, 14.9821, 20.1268,  6.0961, 25.1469,  9.9661,  7.8097,\n",
            "        10.4607, 10.3547, 37.9258,  5.9687, 20.4470, 14.8220,  6.4326, 22.2258,\n",
            "         3.2519, 13.5800, 18.3116, 15.5086,  7.6419, 14.5989, 11.5921, 34.0122,\n",
            "         6.6611,  8.7851, 24.2454,  4.8436, 21.9792, 24.2890, 13.3634,  6.3161,\n",
            "        14.7666,  5.0587,  2.9786, 25.4592, 10.6723, 17.0505, 14.2963,  8.0591,\n",
            "        19.5515, 17.0585, 24.4323, 25.4432,  9.1393, 24.2693, 23.4824, 13.1669,\n",
            "        36.9674, 12.1513, 36.6890, 24.9183, 10.6635,  9.3884, 24.3217,  5.1329,\n",
            "        21.8464, 17.8524, 11.3050, 23.9753,  5.5960,  9.4606, 22.0002,  3.8157,\n",
            "        11.9444, 30.6488,  7.6385, 31.4216,  6.2738,  9.5400, 27.0259, 29.5361,\n",
            "        10.1860, 20.5938, 23.5759, 23.3051, 17.4876, 20.3847,  9.5463,  8.1129,\n",
            "        21.6517,  8.8770, 15.2273,  6.6986,  5.6301, 12.8129, 22.0515, 12.4652,\n",
            "        20.8464, 12.9060, 17.5721, 27.8708,  9.4116, 23.9569, 12.6390, 22.9993,\n",
            "         2.8253, 19.9424, 25.3018, 13.2976, 20.8813, 16.2133, 12.5206, 21.5157,\n",
            "        16.3689,  9.2339,  3.6038, 20.8189, 24.0580,  6.5565,  9.9560, 30.7225,\n",
            "        24.3320, 19.1587, 13.2654, 11.3031, 20.4292, 27.4975, 13.6536, 21.4088,\n",
            "        24.2854, 20.1701, 27.1240, 23.8605, 24.7678, 21.7457,  8.6508, 26.6975,\n",
            "        22.4867, 13.4908, 12.6308,  9.7406,  9.6305, 16.4688, 11.7184,  8.7309,\n",
            "        16.2225,  8.9662, 18.3078, 26.0267,  5.4259,  5.7567, 10.1768, 11.4547,\n",
            "        10.7195,  6.8638, 17.1614, 20.4667, 21.7183, 22.6745],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([25.1932, 25.1255, 16.0182, 13.5397, 20.5065, 22.3144,  9.7082,  8.2677,\n",
            "        14.1325, 13.9888,  9.8001,  8.4532, 25.8443,  9.5906, 17.1327, 27.5952,\n",
            "        25.8158, 21.8320, 22.0374, 11.7508, 21.8748, 13.2436, 28.2166, 10.4291,\n",
            "         6.9527, 21.8105, 11.1559, 19.0772,  2.9352,  6.2891, 12.4214, 21.9498,\n",
            "        25.7534,  9.7469, 16.5888, 10.2239,  5.9271, 15.9357, 11.8772, 12.0640,\n",
            "         8.0456, 19.4592, 19.5518, 11.6492, 18.5775, 23.1277, 14.3836, 20.1229,\n",
            "        13.5099, 14.8030, 28.9355,  4.5205, 24.3867,  3.7462, 11.0963,  5.2365,\n",
            "        28.2931, 28.3915, 12.8784, 16.1945,  8.7596, 13.8308, 12.8613, 20.9224,\n",
            "        15.6772, 23.2647, 14.2655, 18.5950, 16.1949, 25.9019, 12.8185, 25.4491,\n",
            "         3.5509, 15.4793, 13.9712, 13.1111,  3.7662, 18.4029, 16.2624, 21.9577,\n",
            "        27.8942, 34.3018, 13.9387, 22.8307, 29.3294, 10.5208,  9.5306, 15.9655,\n",
            "        10.2096, 16.1270, 14.9827, 12.9458, 20.8926,  2.9887,  7.1181, 10.1527,\n",
            "        13.0953, 21.9214,  5.8917, 11.2255,  9.3497, 26.2702,  5.9698, 21.8526,\n",
            "        21.1803, 11.3396, 23.1896, 23.6343,  8.5313, 40.0833, 17.6392, 20.0587,\n",
            "        17.1899, 24.0605,  5.5773, 27.0808, 17.3591, 11.3839, 18.6484,  3.7538,\n",
            "        13.7023,  6.7568, 15.7807, 19.7417,  6.1239, 25.4932,  9.4427,  8.4217,\n",
            "        11.0542,  9.5292, 40.9595,  5.0388, 21.1667, 13.9320,  7.4638, 22.2169,\n",
            "         3.0383, 13.6788, 18.5246, 15.4191,  7.8005, 13.8809, 10.5933, 33.7301,\n",
            "         6.6014,  9.6226, 25.2021,  4.8484, 22.2449, 22.2843, 13.6672,  6.6911,\n",
            "        14.2462,  4.6269,  3.1293, 24.9680, 10.1237, 15.3333, 13.6777,  8.3295,\n",
            "        19.0364, 16.5865, 24.3549, 25.6291,  9.0185, 27.3101, 23.9238, 12.7806,\n",
            "        38.0346, 11.1549, 36.4983, 25.2803,  9.7441, 10.0694, 23.9407,  5.6160,\n",
            "        22.0329, 19.6065, 11.7894, 24.1771,  5.3134,  9.1758, 23.7242,  3.0017,\n",
            "        12.0509, 30.7632,  7.1776, 31.4490,  7.0930, 10.2668, 26.1253, 28.4617,\n",
            "        10.5222, 19.8605, 24.9999, 22.7710, 16.3352, 20.9799,  8.9425,  7.3750,\n",
            "        21.6922,  9.4538, 16.4075,  6.3559,  5.6398, 12.7826, 23.4177, 10.7577,\n",
            "        20.1811, 14.3308, 19.6625, 28.5029,  9.0297, 25.9174, 13.5357, 22.4311,\n",
            "         3.2285, 21.3942, 24.0288, 15.1781, 19.6574, 15.2778, 14.0398, 22.2873,\n",
            "        15.4962,  9.4262,  4.2308, 18.3412, 22.8612,  5.0321,  9.9276, 31.3393,\n",
            "        26.3594, 19.4343, 13.1141, 10.7669, 20.2321, 26.9206, 13.4557, 20.7602,\n",
            "        24.1920, 20.5263, 25.7110, 22.3948, 25.3099, 23.7777,  8.9693, 26.1767,\n",
            "        22.6469, 13.8869, 13.0363, 11.1971,  8.9391, 15.9076, 11.2184,  8.2558,\n",
            "        15.5819,  8.8574, 18.8559, 25.8174,  6.1551,  5.6481,  9.7347, 11.5187,\n",
            "        11.1280,  6.4774, 19.9454, 21.1793, 21.9368, 22.8728])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 7.3443e-06, -1.1882e-05,  5.7794e-06,  ...,  1.4000e-05,\n",
            "          1.2538e-05,  1.3511e-05],\n",
            "        [ 5.4608e-05, -1.7591e-05, -4.8897e-06,  ...,  1.4441e-04,\n",
            "          1.3837e-05,  5.1231e-05],\n",
            "        [-4.5173e-04, -1.4125e-04,  3.2668e-05,  ...,  3.7718e-02,\n",
            "          8.5852e-04, -2.6409e-03],\n",
            "        ...,\n",
            "        [-6.0978e-06, -1.1818e-05,  5.6510e-07,  ..., -2.1589e-05,\n",
            "          4.5480e-06, -1.1914e-05],\n",
            "        [ 2.7324e-05, -6.0397e-06, -1.6804e-06,  ..., -1.0874e-05,\n",
            "         -1.7489e-05, -1.7057e-05],\n",
            "        [-3.9220e-05, -5.4516e-07,  2.8758e-05,  ..., -7.1590e-07,\n",
            "          1.2932e-05, -2.8335e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.7084e-06,  4.2559e-01,  3.5998e-02,  1.8689e-05, -8.9331e-06,\n",
            "         1.6768e-05, -1.1742e-06,  1.0716e-05,  1.5795e+00, -1.7202e-05,\n",
            "         2.9985e-06, -1.9338e-05, -1.4051e-05,  3.4900e-06, -3.0337e-05,\n",
            "        -8.4935e-06,  9.0654e-06, -1.2462e-05,  1.2374e-05,  6.1391e-06,\n",
            "         3.0761e-06,  2.2951e-06, -1.6343e-06, -3.7745e-06,  1.7168e-05,\n",
            "         1.6260e-05,  1.5772e-05,  1.3502e-01, -2.4685e-05,  9.5109e-06,\n",
            "        -4.8370e-06, -1.2206e-05, -9.2805e-06,  2.8766e-01,  1.1484e-05,\n",
            "         2.0776e-07,  4.4611e-06, -1.0975e-05, -6.2642e-06,  2.4914e-06,\n",
            "        -1.2029e-05, -8.3170e-06,  8.0744e-06,  4.3803e-06, -1.3546e-05,\n",
            "        -2.4170e-05, -1.0441e-05, -1.5043e-05,  2.5203e-05,  2.2359e-04,\n",
            "         1.7137e-06,  5.6751e-06,  7.1843e-08, -5.1583e-06, -1.2284e-05,\n",
            "         2.5519e-06,  7.3844e-05,  6.5708e-06,  1.1854e-05,  4.8938e-06,\n",
            "        -1.5758e-05, -2.2075e-06, -2.6826e-05, -8.0983e-06,  1.8398e-05,\n",
            "         1.0776e-05,  1.0507e-05,  3.3264e-06,  2.1032e-06,  9.4496e-02,\n",
            "        -1.2997e-05,  6.3236e-06,  1.4051e-06, -6.9836e-06, -1.3672e-05,\n",
            "        -4.5732e-06, -3.9334e-06, -2.2668e-05, -9.7291e-06, -1.8337e-03,\n",
            "        -2.6083e-06, -4.3631e-06,  6.7689e-06,  4.1503e-07,  7.9370e-06,\n",
            "         2.9111e-06, -7.3375e-08,  2.4497e-05, -5.9025e-06,  2.0547e-06,\n",
            "         1.0259e-05, -1.2414e-05,  1.0270e-05, -1.1416e-06,  9.8528e-06,\n",
            "         9.1024e-06, -1.1402e-05, -1.1898e-06,  8.3581e-06,  3.8367e-07,\n",
            "         3.4084e-04, -3.0937e-06, -6.0717e-06, -1.6846e-05, -2.0057e-07,\n",
            "         1.9982e-05, -3.4190e-06,  7.0539e-06, -3.7093e-06,  1.6578e-05,\n",
            "         1.0128e-05, -1.3260e-05,  4.6820e-06,  9.1410e-06, -1.3996e-06,\n",
            "        -2.6583e-05, -2.5357e-05,  1.6884e-05,  1.2846e-05, -9.3537e-06,\n",
            "         1.2615e+00, -1.7263e-07, -1.8721e-06,  1.7141e-05, -1.7171e-05,\n",
            "         5.1769e-07,  1.9409e-05,  3.5767e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.0889e-05, -1.1894e-04, -1.0261e-05,  ..., -4.4634e-06,\n",
            "         -1.3256e-05,  1.8123e-05],\n",
            "        [ 8.7731e-06,  1.7391e-06,  2.3556e-05,  ..., -1.8322e-05,\n",
            "         -6.7030e-06,  2.1717e-05],\n",
            "        [ 7.8674e-06,  5.1806e-06, -1.5999e-05,  ..., -4.8358e-07,\n",
            "         -1.2796e-05,  8.1446e-06],\n",
            "        ...,\n",
            "        [-2.6559e-07, -1.0149e-05,  3.5515e-06,  ..., -8.0641e-06,\n",
            "         -3.6667e-06,  1.3935e-05],\n",
            "        [ 1.0026e-05, -4.0431e-05,  2.0937e-04,  ..., -8.4985e-06,\n",
            "          8.0461e-06, -7.2210e-06],\n",
            "        [-4.0740e-06,  8.5479e-05,  3.9002e-05,  ...,  5.7776e-06,\n",
            "          7.1680e-07, -1.5184e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.5096e-02, -6.3857e-06,  6.7769e-06, -1.9758e-06, -8.7111e-06,\n",
            "         1.8830e-05, -1.2603e-05,  6.9734e-07, -6.8402e-06,  7.6594e-06,\n",
            "         2.6562e-06,  7.7645e-06,  1.1807e-05,  5.4202e-06,  8.9598e-06,\n",
            "        -4.3135e-06,  4.5867e-06, -5.1824e-07, -1.1457e-05,  1.2451e-05,\n",
            "        -1.7854e-05,  1.4031e-05, -1.9637e-05, -1.5969e-05, -3.2308e-05,\n",
            "         2.2119e-06, -3.5297e-07,  2.5795e-05,  9.9067e-06,  1.8722e-05,\n",
            "         1.1038e-06,  3.3680e-06,  1.0397e-06, -8.6250e-06, -1.9469e-05,\n",
            "         8.0695e-06,  3.1033e-05,  1.1828e-05,  1.6523e-05, -3.4009e-05,\n",
            "         2.0253e-05, -2.2937e-05,  3.8826e-06, -2.9395e-05, -1.3165e-05,\n",
            "        -1.1038e-05,  6.4901e-06, -1.0253e-05, -5.3336e-06, -4.8463e-06,\n",
            "        -3.3864e-06,  1.0852e+00,  4.8139e-06,  3.6911e-06,  1.1716e-05,\n",
            "         9.0060e-02, -1.2414e-05,  1.2531e-06, -2.9399e-05,  8.3389e-06,\n",
            "        -2.3524e-06,  3.8401e-05,  2.6101e-01,  1.7672e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3576e-01,  1.0921e-05, -1.7282e-05, -3.6306e-05, -5.3796e-06,\n",
            "          1.3848e-05,  1.4885e-05, -5.7578e-06, -9.9661e-06, -1.2599e-05,\n",
            "         -2.4436e-05, -3.0825e-05,  1.2023e-05, -9.8161e-06, -1.2826e-05,\n",
            "          5.4512e-06,  2.3587e-06,  2.0685e-05,  5.0499e-06, -1.6611e-05,\n",
            "          7.8425e-06,  7.6343e-06, -1.9896e-05, -1.0108e-05,  5.4839e-01,\n",
            "          5.7374e-06,  3.4569e-05, -4.6944e-06, -1.4531e-05,  1.1750e-05,\n",
            "         -3.8251e-05, -1.3873e-05,  1.0364e-05,  2.3145e-06, -7.5814e-06,\n",
            "         -1.8265e-05, -1.3592e-06,  6.6918e-06, -1.7065e-05, -1.0739e-05,\n",
            "          8.5675e-06, -6.4076e-07,  3.4991e-06,  4.8716e-05,  1.3114e-06,\n",
            "         -2.9701e-05,  9.9387e-06, -1.8527e-05, -1.9114e-06,  1.0223e-05,\n",
            "          1.0186e-05,  3.2322e+00, -3.8130e-06,  1.2202e-05,  1.5073e-05,\n",
            "          7.8512e-01,  1.1987e-05,  1.1735e-05, -2.4023e-06,  1.2656e-06,\n",
            "          8.9602e-08, -1.8253e-05,  1.0874e+00,  2.4155e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3109], requires_grad=True)\n",
            "l1_reg is: 30.189655303955078\n",
            "total_loss 1.0300806760787964\n",
            "pred: tensor([21.9163, 18.5891, 16.6529, 24.5546, 13.4003,  9.2319, 28.7359, 26.4148,\n",
            "        17.6640, 33.3643, 14.0700, 19.8325, 12.8368, 11.3159, 23.1536, 20.7620,\n",
            "        22.1371,  7.4302,  8.9888, 11.2308, 31.1923, 15.8820, 10.4091, 20.9271,\n",
            "         3.2985, 15.9086, 28.5686, 13.6170, 20.9567, 13.7392, 25.9205,  3.1487,\n",
            "         9.2958, 11.0418,  9.5571, 17.9964, 10.4447,  8.8721, 16.1548, 16.3565,\n",
            "        12.6124, 15.0937,  7.1561, 12.1270, 26.8655, 25.4627,  5.5469,  5.9446,\n",
            "        15.0617, 15.7578, 18.7578, 15.6919,  4.4735, 24.6345, 21.2693, 32.1967,\n",
            "        10.0998, 23.4645, 25.6671, 20.1463, 27.2325, 25.2996,  9.4045,  4.2024,\n",
            "        10.6818, 25.7936, 20.0925, 19.3063, 35.4271, 20.9235, 15.9389, 28.0156,\n",
            "        17.2397,  3.8138, 11.9862, 10.0656, 30.6005, 13.2315, 14.7497, 22.6982,\n",
            "        21.8928, 11.5166, 25.6980,  3.1742,  3.5242, 21.7029,  5.4868, 16.2569,\n",
            "        13.7768, 13.5600,  9.4739, 14.7236, 27.0050, 28.3107,  7.3385, 29.3111,\n",
            "        25.5888, 11.4303, 12.6231, 24.5762, 20.2464, 12.3517, 16.6324, 15.8580,\n",
            "        13.7717, 16.0862, 14.1054, 24.5566, 16.6050, 19.0100, 12.1929, 25.2270,\n",
            "        28.1883, 30.3645,  3.0419, 24.4372, 27.1053, 23.2603,  5.6418,  8.4241,\n",
            "        19.7671, 18.3565,  9.7418, 23.0110, 18.5874, 25.4277,  4.2094, 14.2463,\n",
            "        25.9050,  9.2038, 25.0677, 14.6451,  9.9998, 13.4491, 19.1954, 10.5528,\n",
            "        25.0814, 24.7586,  3.0964,  6.9429, 13.7568, 15.0466,  8.5235,  5.5496,\n",
            "        24.8363,  8.6664, 13.9370,  9.4348, 26.6638, 11.3114,  9.1203, 16.8304,\n",
            "        25.1174, 24.5388, 28.3263,  6.8076, 22.5565, 11.9162, 20.9919, 14.2925,\n",
            "        18.9764, 18.2112, 11.3466, 20.6432, 12.6659, 17.7181,  3.8396, 11.7095,\n",
            "         6.7166, 12.4533, 11.0479, 27.3923,  7.1156, 19.7513, 22.4880, 28.9528,\n",
            "         9.4468, 11.0254, 24.7953, 12.3112, 15.5819, 13.9396, 27.3776, 11.2318,\n",
            "        10.0605, 25.9050, 21.7359, 18.5550,  8.1325,  7.1967,  9.6678,  5.2908,\n",
            "        19.0757, 30.7529, 24.9944, 16.7916, 10.7674, 15.7936, 26.5004,  6.7950,\n",
            "        23.0273, 15.4848, 18.3153,  2.9215,  6.2075, 17.2972, 10.8119,  8.4787,\n",
            "         8.2785, 24.3879, 16.3727, 25.5197, 18.6329,  9.4308, 26.5416,  9.6659,\n",
            "        21.0723, 25.2445, 22.3139, 14.4635, 20.8939, 14.4209,  2.6900, 10.5360,\n",
            "         9.5278,  8.7276, 15.1752, 15.6205, 22.6043, 25.9151, 10.2678,  9.4051,\n",
            "         9.6264,  6.7643, 15.0938, 24.8490, 27.4105, 24.7763, 13.5984,  9.6615,\n",
            "         7.2735, 16.9296,  5.2163, 22.0509,  4.3136, 13.4914, 23.8091, 13.3548,\n",
            "        11.0403, 24.3831,  5.1355, 24.2414, 10.6200,  9.5313,  5.8852, 21.8831,\n",
            "        23.3147, 22.5057, 13.0311, 16.3003,  4.9556, 20.7495,  4.1153, 24.6792,\n",
            "        19.9854, 10.1266, 19.8397, 10.6098, 20.5476, 12.5457],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([21.5721, 18.2170, 18.0973, 25.1929, 13.0504,  9.7152, 30.3723, 25.0821,\n",
            "        17.3588, 34.0910, 13.5445, 19.8536, 11.9607, 11.8142, 22.3694, 21.5983,\n",
            "        22.6237,  7.7907,  9.7051, 10.0902, 30.6338, 14.6409, 10.7407, 20.3187,\n",
            "         3.3879, 16.0194, 27.0758, 13.4919, 18.9176, 15.0574, 24.8022,  2.9864,\n",
            "         7.6077, 11.4516,  9.0505, 18.5855, 11.2572,  9.0140, 17.0498, 17.0447,\n",
            "        11.9697, 16.0435,  7.1608, 12.3080, 26.1853, 28.4034,  5.4154,  6.4376,\n",
            "        15.4301, 15.8179, 19.1647, 13.3208,  4.5723, 24.0858, 21.9697, 31.6558,\n",
            "         8.7321, 24.1090, 24.1689, 20.9750, 24.9986, 24.3197,  9.5773,  3.7834,\n",
            "        11.0325, 25.2843, 21.3376, 20.9402, 33.4256, 21.8819, 15.3303, 27.9216,\n",
            "        15.8768,  4.4081, 13.2033,  8.9709, 31.1689, 13.0631, 14.8318, 22.7201,\n",
            "        20.3049, 10.2519, 26.6540,  3.2051,  3.3760, 22.7836,  5.0426, 17.1018,\n",
            "        14.1956, 13.1483,  9.4689, 15.4041, 27.6089, 29.2688,  6.9896, 28.5692,\n",
            "        25.2963, 10.9893, 11.2336, 24.4097, 21.2043, 11.6684, 16.7220, 16.4102,\n",
            "        13.4865, 16.6193, 14.7628, 24.9990, 15.7477, 19.2292, 12.0155, 26.7724,\n",
            "        27.4623, 30.5629,  2.3983, 25.8066, 26.4615, 23.4524,  5.2390,  8.1349,\n",
            "        20.6442, 16.8981, 10.3949, 23.4455, 18.3333, 25.3183,  4.3599, 14.1756,\n",
            "        25.1279,  8.6658, 25.0745, 14.6009,  8.5957, 13.4445, 18.7337,  9.6728,\n",
            "        25.3434, 26.7301,  3.3051,  7.1183, 14.0291, 14.9064,  9.2297,  5.7823,\n",
            "        25.4778,  7.4995, 14.4771,  8.7501, 26.0680, 10.5994,  9.5536, 16.1607,\n",
            "        25.0908, 24.4929, 29.6881,  6.6406, 21.6413, 11.8495, 21.7100, 14.5307,\n",
            "        18.9118, 18.2353, 12.2191, 19.3636, 12.8571, 19.0480,  3.3576, 10.4878,\n",
            "         6.6393, 12.6149, 11.3383, 26.5894,  7.3201, 19.5858, 21.8196, 30.1335,\n",
            "        10.3216, 10.5224, 24.6654, 11.9253, 15.9616, 13.0036, 25.9028, 10.3015,\n",
            "         9.7351, 25.8136, 22.0113, 18.8760,  8.8462,  6.8889,  9.4634,  4.3651,\n",
            "        16.2835, 31.1275, 25.2360, 15.0831, 10.8191, 15.4802, 26.4727,  6.8095,\n",
            "        24.0158, 14.6036, 17.9984,  3.3854,  6.4014, 18.2323, 10.6810,  9.5607,\n",
            "         8.0536, 24.0335, 15.7061, 27.0168, 18.6717, 10.7143, 26.7285,  9.7464,\n",
            "        19.3209, 24.8764, 23.0754, 14.6286, 21.4626, 15.1587,  2.7559, 10.4564,\n",
            "         9.9478,  8.9872, 13.6691, 15.2284, 21.5261, 25.5347, 10.4391,  9.3521,\n",
            "         9.8565,  7.3566, 15.6983, 25.1333, 27.9089, 24.3183, 14.5650,  9.8075,\n",
            "         7.5682, 18.3335,  3.6290, 21.6788,  3.8084, 13.1363, 24.2925, 14.0473,\n",
            "        11.7030, 25.3534,  5.5058, 24.1188, 10.7616,  9.9190,  5.6474, 22.7714,\n",
            "        24.2598, 21.6111, 13.0704, 15.2333,  4.7945, 19.8966,  4.2636, 26.2203,\n",
            "        20.6294, 10.4222, 19.8214, 10.0462, 20.9184, 13.0854])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.5271e-05,  8.8877e-06, -6.1593e-07,  ...,  1.8108e-05,\n",
            "         -3.1560e-06,  1.9458e-05],\n",
            "        [ 1.0716e-04, -6.4948e-06,  1.8889e-05,  ..., -2.5223e-05,\n",
            "         -1.9883e-04, -7.6183e-05],\n",
            "        [-3.9030e-04, -8.6135e-05,  3.4904e-05,  ...,  3.7777e-02,\n",
            "          4.9254e-04, -2.7391e-03],\n",
            "        ...,\n",
            "        [-7.6560e-06,  3.6574e-06, -3.6029e-06,  ..., -8.2822e-06,\n",
            "          7.6452e-07, -1.7815e-05],\n",
            "        [ 2.5141e-05, -4.8646e-06,  1.0267e-05,  ...,  4.8061e-06,\n",
            "         -2.4019e-05, -2.2951e-05],\n",
            "        [-4.5004e-05,  1.7129e-05,  2.8224e-05,  ...,  3.6607e-07,\n",
            "          9.6142e-07, -2.6164e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.8048e-06,  4.2567e-01,  3.6305e-02,  4.6667e-06, -9.0430e-06,\n",
            "         2.6850e-05,  5.3759e-07,  1.6320e-05,  1.5806e+00, -5.2409e-06,\n",
            "        -1.4566e-05, -1.3625e-05, -5.9166e-06,  1.7348e-07, -1.9757e-05,\n",
            "         7.2000e-06,  1.8506e-07, -2.1148e-05,  1.9425e-07, -1.1495e-05,\n",
            "         7.0866e-06, -1.1402e-05,  7.1762e-06,  1.1887e-05,  1.0881e-05,\n",
            "         7.1532e-06, -3.9768e-06,  1.3510e-01, -2.1008e-05,  9.6118e-06,\n",
            "        -6.4354e-07, -5.8999e-06,  7.4331e-06,  2.8781e-01, -4.1867e-06,\n",
            "         3.1896e-06, -1.2854e-05,  4.6940e-06, -1.0367e-05,  5.5148e-06,\n",
            "        -2.0692e-05, -5.8637e-06, -1.0134e-05,  5.8965e-06,  9.2533e-07,\n",
            "        -2.1990e-05, -1.1338e-06, -8.7367e-06,  1.3278e-05,  2.0200e-04,\n",
            "         5.0030e-06,  5.1137e-06, -4.0953e-06,  1.0521e-05, -3.1110e-07,\n",
            "        -8.7548e-06, -2.6436e-04, -5.1335e-06,  1.6461e-05,  1.9280e-06,\n",
            "        -7.9719e-06,  2.2394e-06, -1.4876e-05,  7.5831e-06,  2.5431e-05,\n",
            "         1.0490e-05,  1.6891e-05,  1.1090e-05, -1.8658e-05,  9.4487e-02,\n",
            "         1.4792e-06, -1.5990e-05, -1.6961e-05,  4.5467e-06,  1.7623e-06,\n",
            "         1.8187e-05,  4.9430e-08, -1.0697e-05, -3.4385e-06, -1.8519e-03,\n",
            "         1.8643e-05,  3.4373e-06, -3.7243e-06, -7.9459e-06, -7.7562e-06,\n",
            "         4.3590e-06,  2.2606e-05,  2.2317e-05,  6.0081e-06,  3.4991e-06,\n",
            "         9.6926e-06, -3.0866e-06, -1.0490e-05,  5.4134e-07, -1.1921e-05,\n",
            "        -7.4434e-07,  3.2173e-06,  1.3020e-05, -9.8432e-06, -1.1535e-05,\n",
            "         4.6147e-04, -2.5331e-06, -7.6250e-06, -1.0532e-05,  1.6298e-05,\n",
            "         1.5205e-05, -1.1202e-05,  6.4861e-06,  1.1968e-05,  1.0281e-05,\n",
            "         1.0881e-05, -1.9338e-05,  1.6954e-05,  9.3248e-06,  4.7994e-06,\n",
            "        -4.1537e-05, -2.3184e-05,  9.4543e-06,  1.6957e-05,  5.4111e-06,\n",
            "         1.2622e+00,  1.0430e-05,  2.0802e-06,  1.4984e-05, -1.0846e-05,\n",
            "        -2.9449e-06,  2.9900e-05, -5.1235e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.1033e-05, -1.6955e-05,  4.1702e-05,  ..., -6.6645e-07,\n",
            "         -1.5329e-05,  1.3160e-05],\n",
            "        [ 1.4130e-05, -6.2220e-06,  2.1378e-05,  ..., -1.2017e-05,\n",
            "          1.4063e-05,  1.0643e-05],\n",
            "        [ 1.6556e-05, -3.5298e-06, -2.2553e-05,  ...,  3.0940e-06,\n",
            "         -7.3550e-06, -7.5292e-06],\n",
            "        ...,\n",
            "        [ 8.7048e-06, -1.2142e-05,  7.2809e-06,  ..., -8.1284e-06,\n",
            "         -2.2505e-07,  1.9737e-06],\n",
            "        [ 3.0564e-06,  2.0169e-04,  3.1646e-04,  ..., -6.5730e-06,\n",
            "         -8.9772e-06,  7.7224e-06],\n",
            "        [-7.1366e-06,  7.2780e-05,  7.1708e-06,  ...,  7.3378e-06,\n",
            "         -6.1766e-06,  7.6046e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.5156e-02,  5.3480e-06,  8.3326e-06,  1.8785e-05,  1.7034e-05,\n",
            "         2.9181e-05, -1.4677e-05,  4.3153e-06,  1.5275e-05, -5.0617e-06,\n",
            "         8.8517e-06,  1.1866e-05,  1.4175e-05,  6.9778e-06,  9.1311e-06,\n",
            "        -5.7402e-06, -7.9628e-06,  2.9334e-06, -1.3773e-05,  4.8867e-07,\n",
            "        -2.4403e-05,  7.7236e-06, -6.1550e-06, -1.3142e-05, -5.0905e-05,\n",
            "         5.8923e-06,  1.2594e-05,  2.2255e-05, -4.6499e-06, -7.1065e-07,\n",
            "         5.4924e-07, -8.5340e-08, -1.4782e-05,  1.6791e-06, -1.3165e-05,\n",
            "         6.1403e-06,  2.0461e-05,  1.7419e-05,  1.1550e-05, -3.5861e-05,\n",
            "         2.8942e-05, -1.8253e-05, -7.1032e-07, -2.8722e-05, -1.0239e-05,\n",
            "        -1.6633e-05,  9.7868e-06, -1.5802e-05,  1.5432e-05, -1.6714e-06,\n",
            "        -1.0984e-05,  1.0861e+00, -1.2088e-05,  6.7155e-06,  4.8477e-06,\n",
            "         9.0195e-02, -1.4177e-05, -5.6423e-06, -2.8862e-05,  1.7029e-05,\n",
            "        -6.4583e-06,  3.0062e-05,  2.6124e-01,  5.5595e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3566e-01,  1.9620e-05, -1.1411e-05, -2.7971e-05,  6.8473e-06,\n",
            "          8.4862e-06,  6.7438e-06,  2.9419e-06, -9.7952e-06, -1.0126e-05,\n",
            "         -6.9359e-06, -2.2487e-05,  5.7368e-06,  5.8590e-06, -6.3743e-07,\n",
            "         -2.5137e-05, -8.0774e-06,  1.5910e-05, -2.3621e-06, -2.2756e-05,\n",
            "          5.4023e-06, -1.3136e-05, -6.1990e-06,  8.0526e-06,  5.4829e-01,\n",
            "         -5.7525e-06,  2.6247e-05,  6.6165e-08, -1.8619e-05, -2.7250e-06,\n",
            "         -2.9920e-05, -5.7467e-06,  1.1112e-05, -1.6067e-05, -4.4927e-07,\n",
            "         -1.2195e-05,  1.7488e-05,  3.7367e-07, -2.8445e-06,  1.4745e-06,\n",
            "          9.6935e-06,  9.8523e-06, -8.3842e-06,  4.3912e-05, -1.4331e-05,\n",
            "         -2.9145e-05, -2.7708e-06,  9.1694e-07, -4.3553e-06, -2.4274e-06,\n",
            "          1.0292e-05,  3.2339e+00, -7.5158e-06, -8.5734e-06,  1.9177e-05,\n",
            "          7.8509e-01, -6.1694e-07,  1.5859e-05,  1.0678e-06, -5.6309e-06,\n",
            "         -7.8817e-06,  1.1972e-06,  1.0876e+00,  2.4145e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3111], requires_grad=True)\n",
            "l1_reg is: 30.235441207885742\n",
            "total_loss 0.9600517749786377\n",
            "pred: tensor([10.6932, 30.2133, 21.0783, 24.7854, 15.8118, 12.5789, 12.8361, 12.2660,\n",
            "        23.0446, 14.5681, 13.4135,  9.8548, 14.5103, 10.0195, 10.1260,  6.0096,\n",
            "         4.8042, 11.0452, 12.7798,  6.1020, 26.4191, 32.0593, 13.8272, 17.4772,\n",
            "        11.1373,  6.4061, 29.6031, 16.9668, 30.1260, 13.7364, 20.6028,  6.4683,\n",
            "        26.9376,  2.8170, 14.6742, 17.5102, 24.5882, 18.7504, 16.2707, 19.5248,\n",
            "        23.6109, 22.2414, 22.0212, 24.8464, 24.9558, 11.0920,  7.6462, 11.6476,\n",
            "        22.1091, 14.9650, 30.4413, 24.7024, 23.3464, 11.9427, 21.7830,  6.3780,\n",
            "         6.4460, 18.3140, 11.8358, 27.8389, 24.9628, 10.4769, 13.1613, 20.7087,\n",
            "         9.7170,  9.1250, 10.5814, 24.8644,  5.6170, 24.4075,  3.7574, 18.2595,\n",
            "        21.9105, 20.7482, 20.1445,  7.5693, 16.2556, 19.3043, 25.0825, 11.2535,\n",
            "        15.3320, 25.6185,  9.1477, 25.9141, 24.2411,  7.8266, 24.7445,  9.3431,\n",
            "         9.0047, 21.5037, 25.8820, 11.2479, 25.0797, 17.6799, 26.9768, 11.9574,\n",
            "        12.9829, 15.5636,  3.1395, 23.4598, 19.8307, 16.3272, 15.9920, 11.9734,\n",
            "        23.4759, 23.2440,  8.2017, 12.4656, 14.2164, 14.5009, 16.2567, 25.4351,\n",
            "        18.8832,  3.0624, 23.3061, 10.8356, 16.9461,  4.4992, 17.5815, 16.1572,\n",
            "        18.8472, 33.7052, 10.8308, 15.2155, 21.4408, 14.6698,  6.0122, 24.9761,\n",
            "        24.9711,  6.5609, 10.2933,  7.9301, 16.4043, 27.2136, 11.5758, 21.7256,\n",
            "         7.3888, 18.8137,  5.0056, 20.0680, 15.9891,  2.8874, 19.5534, 29.3732,\n",
            "        21.7719, 12.0087, 20.6746, 15.8946, 12.4055, 10.3279, 24.8690, 21.9700,\n",
            "        15.7553, 26.4250,  6.6469, 23.9752, 34.1273,  9.5058, 10.6856, 19.9885,\n",
            "         5.9410,  5.3764, 18.8754,  9.5799, 30.9870,  5.1103, 11.0562, 15.6637,\n",
            "        26.8942, 25.8183, 35.3509, 25.7617, 12.2884, 13.7763, 21.8110, 12.9535,\n",
            "        14.2969,  5.1587, 28.2400, 28.5687, 11.0814, 21.0467, 14.3736, 12.6891,\n",
            "        21.0872,  9.5540, 23.1167, 15.0123, 28.2775, 13.3443, 14.3289, 21.2792,\n",
            "        25.3265, 11.4039, 25.6444,  7.7306,  7.9675, 22.5477, 25.1603, 21.8102,\n",
            "        16.0724, 22.6215,  8.2585, 12.1569, 21.1681, 13.0021, 10.8838,  5.9837,\n",
            "        20.6521, 14.1776, 10.1725, 20.3988, 19.7871,  5.0881, 13.6282, 20.4113,\n",
            "         3.0296, 15.0094,  8.0327, 19.1888, 21.8462, 15.5250, 12.8385,  9.2533,\n",
            "         8.2867, 16.0234, 32.4510, 14.4447, 28.6538, 23.6747, 20.6573,  8.6216,\n",
            "        22.2316, 20.6675, 18.8237, 19.7940, 13.9872, 18.6555, 23.6533, 14.8791,\n",
            "        13.1023, 23.9271, 15.7539, 15.1354, 22.9268, 20.4720, 10.5075, 21.6959,\n",
            "        16.8744,  5.4753, 11.6579, 35.7032,  5.1021,  6.0229, 21.6864, 10.3475,\n",
            "        15.7111, 24.6734, 10.8068, 13.2283, 13.3971, 16.0563, 33.0318, 12.5123,\n",
            "         8.5974,  3.8808, 14.0588, 27.0585, 10.8549,  4.7036],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([ 9.8279, 30.3057, 17.7417, 24.3212, 15.9248, 12.1732, 14.3835, 13.0026,\n",
            "        22.8468, 14.2534, 14.4196, 10.1734, 13.6488,  9.5381,  9.9684,  6.0440,\n",
            "         5.3297, 11.0834, 12.5437,  5.4318, 25.8165, 32.9856, 13.4760, 19.2529,\n",
            "        11.2189,  6.6757, 29.6748, 17.7502, 29.1736, 14.3454, 21.0445,  6.1922,\n",
            "        25.6844,  2.3387, 15.2496, 17.4472, 22.8793, 18.5914, 17.5000, 19.2695,\n",
            "        21.5702, 20.0336, 21.4534, 25.2887, 24.2466, 12.0150,  8.4529, 11.5051,\n",
            "        22.7647, 15.0697, 31.6662, 22.4271, 23.6040, 12.0289, 21.0874,  6.3057,\n",
            "         5.3161, 18.7693, 11.2208, 27.6427, 24.9279, 10.5069, 12.7005, 19.7423,\n",
            "         8.6810,  8.9869, 10.5865, 24.0300,  6.3559, 26.6413,  3.8793, 20.0467,\n",
            "        21.3608, 20.4538, 20.9017,  6.3798, 16.8874, 19.9216, 21.9274, 11.1299,\n",
            "        15.4052, 24.7328, 10.3821, 26.1270, 23.6043,  8.3335, 24.2194,  8.7021,\n",
            "         8.7883, 20.4727, 24.7987, 12.4807, 24.9036, 15.5175, 27.8016, 11.5707,\n",
            "        12.1835, 13.7427,  3.0333, 25.2984, 18.8784, 15.7240, 15.5514, 11.4865,\n",
            "        23.9115, 23.1116,  8.2237, 12.0735, 14.1613, 13.8726, 15.1712, 25.0734,\n",
            "        18.5266,  2.6391, 24.4763, 11.4987, 16.6667,  4.7149, 17.9593, 13.0685,\n",
            "        18.5585, 35.0674, 11.6045, 15.1577, 21.8640, 15.3727,  6.2500, 25.6022,\n",
            "        25.2529,  6.6176,  8.9286,  7.0025, 16.9725, 25.2176, 12.8861, 21.2779,\n",
            "         6.4413, 20.0433,  4.2692, 20.6560, 17.8601,  2.9914, 19.4706, 30.0542,\n",
            "        23.0299, 10.9914, 19.7479, 16.8269, 12.3903, 11.2188, 24.3948, 20.9574,\n",
            "        14.4231, 26.7993,  7.1010, 24.7383, 34.8000, 10.0308, 10.6060, 19.6534,\n",
            "         5.4820,  5.6319, 18.5195,  9.6626, 26.6320,  4.5714, 11.5597, 15.8894,\n",
            "        29.4108, 25.0153, 35.9483, 25.7552, 12.0312, 12.8462, 21.7220, 11.9179,\n",
            "        14.4573,  5.3960, 27.6146, 28.8653, 11.5176, 23.0469, 15.0729, 12.3650,\n",
            "        21.0684,  9.1595, 22.5898, 13.4191, 28.4531, 13.3394, 14.0640, 20.5418,\n",
            "        25.3752, 11.2903, 26.3721,  7.7273,  8.7156, 22.6358, 26.1624, 21.8326,\n",
            "        16.1858, 23.4489,  7.6803, 12.5605, 21.2428, 13.0247, 11.3391,  6.3338,\n",
            "        20.5772, 13.6535, 10.3077, 21.3147, 19.5808,  4.9911, 13.9302, 21.2700,\n",
            "         2.3849, 13.5161,  8.5520, 15.5303, 20.8235, 15.5172, 13.0259,  8.8788,\n",
            "         8.6037, 15.5823, 33.0460, 13.6179, 30.1929, 24.7600, 21.2262,  8.9577,\n",
            "        22.0198, 19.5238, 20.1040, 18.9801, 14.8246, 19.8397, 22.4624, 13.9031,\n",
            "        12.3044, 22.9409, 15.3680, 14.7273, 22.5572, 21.5107, 10.0000, 21.5198,\n",
            "        15.3266,  5.1471, 11.8489, 37.6466,  5.6349,  6.0344, 22.3171,  8.6269,\n",
            "        15.8154, 22.9460, 10.2113, 11.9910, 14.1771, 17.5345, 32.3296, 12.8270,\n",
            "         7.6426,  4.1165, 15.4348, 25.9997, 11.6667,  4.4715])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.2405e-05,  1.7581e-05,  3.6282e-06,  ...,  1.1806e-05,\n",
            "         -7.2801e-06,  1.4811e-05],\n",
            "        [ 1.2532e-04,  1.6866e-06,  3.8592e-05,  ..., -9.3760e-05,\n",
            "         -1.9714e-04, -6.1704e-05],\n",
            "        [-3.7425e-04, -2.6531e-05,  2.6917e-05,  ...,  3.8000e-02,\n",
            "          4.6928e-04, -2.6445e-03],\n",
            "        ...,\n",
            "        [ 9.4103e-07,  7.5854e-06,  2.6459e-06,  ...,  1.3694e-05,\n",
            "         -1.2637e-05, -1.3123e-05],\n",
            "        [ 1.3179e-05,  6.1944e-06,  1.1019e-05,  ...,  8.9052e-06,\n",
            "         -1.9919e-05, -1.8271e-05],\n",
            "        [-4.0211e-05,  2.3035e-05,  1.7744e-05,  ..., -8.6557e-06,\n",
            "         -1.9801e-05, -1.4204e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.2665e-06,  4.2570e-01,  3.6714e-02, -1.7953e-05,  8.5216e-07,\n",
            "         2.5915e-05, -7.9189e-06,  1.1372e-05,  1.5815e+00,  1.5521e-05,\n",
            "        -2.0384e-05,  1.5172e-06,  1.1405e-05, -1.2798e-05, -2.2838e-07,\n",
            "         1.1322e-05, -1.7805e-05, -1.8966e-05, -2.0767e-05, -1.7367e-05,\n",
            "         6.9402e-07, -1.3735e-05,  5.1091e-06,  1.5982e-05, -4.7827e-06,\n",
            "        -1.1044e-05, -1.1746e-05,  1.3515e-01, -7.6955e-06, -3.0030e-07,\n",
            "         1.3133e-05,  9.7726e-06,  1.2468e-05,  2.8808e-01, -8.2928e-06,\n",
            "        -4.1372e-06, -1.8448e-05,  8.7894e-06, -4.0627e-06, -1.7629e-06,\n",
            "        -1.8489e-05,  6.3421e-06, -1.6527e-05, -2.7415e-06,  3.9432e-06,\n",
            "        -1.0027e-05,  1.7246e-05,  6.9437e-06, -7.4615e-06,  1.9156e-04,\n",
            "        -2.0290e-06, -5.3904e-06,  2.1544e-06,  1.4631e-05,  2.0467e-05,\n",
            "        -8.9310e-06, -3.2912e-04, -5.6709e-06,  1.0604e-05, -1.0736e-05,\n",
            "         9.0641e-06, -3.7491e-06,  5.8781e-06,  1.1698e-05,  2.1762e-05,\n",
            "         2.3747e-07,  1.2639e-05,  8.0756e-06, -2.7347e-05,  9.4458e-02,\n",
            "         4.5078e-06, -2.6068e-05, -2.3497e-05,  4.9242e-06,  5.6539e-06,\n",
            "         2.8671e-05, -6.3663e-06,  1.0074e-05,  1.2221e-05, -1.7088e-03,\n",
            "         2.7773e-05,  4.6221e-07, -3.1639e-06, -5.4720e-06, -1.1871e-05,\n",
            "        -4.3462e-06,  3.3022e-05,  1.0356e-05,  6.7476e-06, -5.2021e-06,\n",
            "        -8.2497e-07,  1.5314e-05, -1.9175e-05, -7.9350e-06, -2.1515e-05,\n",
            "         4.0294e-07,  6.3725e-06,  1.5815e-05, -1.6213e-05, -1.2258e-05,\n",
            "         5.4696e-04,  7.9682e-06,  9.7662e-07,  5.1509e-06,  2.1141e-05,\n",
            "         9.0718e-07, -8.2073e-06, -4.0259e-06,  1.6084e-05, -5.3767e-06,\n",
            "         1.5575e-06, -1.4807e-05,  1.8000e-05, -5.0742e-07,  3.7854e-07,\n",
            "        -4.4995e-05, -1.1229e-05, -7.2340e-06,  1.0653e-05,  8.6985e-06,\n",
            "         1.2629e+00,  9.9714e-06, -4.3597e-06,  3.0463e-06,  4.8373e-06,\n",
            "         3.9389e-06,  2.9363e-05, -2.9567e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.1614e-06,  8.0628e-05,  1.0009e-04,  ...,  1.2753e-05,\n",
            "         -7.2103e-06, -1.3075e-06],\n",
            "        [ 8.9514e-06, -3.3870e-06,  9.4183e-06,  ...,  3.6564e-06,\n",
            "          2.2752e-05, -9.3236e-06],\n",
            "        [ 1.4377e-05, -1.3691e-06, -1.8452e-05,  ..., -3.6861e-06,\n",
            "          7.5420e-06, -1.1636e-05],\n",
            "        ...,\n",
            "        [ 6.7781e-06, -3.9357e-06,  6.3743e-07,  ...,  1.8138e-06,\n",
            "          1.2872e-05, -1.8792e-05],\n",
            "        [-1.3219e-05,  4.0107e-04,  4.4674e-04,  ...,  5.1654e-06,\n",
            "         -1.4328e-05,  1.1169e-05],\n",
            "        [ 1.0711e-07,  5.1352e-05, -3.1477e-05,  ..., -1.2581e-06,\n",
            "         -2.3806e-06,  5.8154e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.5178e-02,  5.9076e-06, -2.6711e-07,  2.7472e-05,  3.0204e-05,\n",
            "         2.8498e-05, -6.5424e-06, -2.4288e-06,  2.5178e-05, -6.5106e-06,\n",
            "         4.4277e-06,  5.5578e-06,  6.3068e-06, -1.6205e-06, -7.1460e-07,\n",
            "         2.9758e-06, -9.2568e-06, -3.9611e-06, -5.8564e-06, -2.0278e-05,\n",
            "        -2.0298e-05, -7.9523e-06,  1.5979e-05, -5.9861e-07, -5.7641e-05,\n",
            "        -7.9522e-07,  1.4247e-05,  9.0690e-06, -7.7494e-06, -8.2001e-06,\n",
            "        -9.9484e-06,  6.8067e-06, -1.9020e-05,  9.5375e-07,  2.5085e-06,\n",
            "        -5.5959e-06,  9.4574e-07,  1.2450e-05, -2.9268e-06, -2.7528e-05,\n",
            "         2.6762e-05, -4.0373e-06,  5.1565e-06, -1.8116e-05,  2.3934e-06,\n",
            "        -1.1669e-05,  2.7539e-06, -1.0796e-05,  2.4122e-05,  1.1186e-05,\n",
            "        -7.8228e-06,  1.0867e+00, -1.7300e-05, -5.6228e-07, -1.1337e-05,\n",
            "         9.0274e-02, -5.7634e-06, -1.8482e-06, -1.8379e-05,  1.4849e-05,\n",
            "        -1.5300e-07,  1.2556e-05,  2.6139e-01,  7.9726e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3556e-01,  1.7447e-05,  3.8725e-06, -1.0467e-05,  7.8514e-06,\n",
            "         -6.3382e-06, -1.0582e-05,  7.7103e-07,  3.5831e-07,  2.1005e-06,\n",
            "          1.8814e-05, -4.9834e-06, -9.9237e-06,  9.9678e-06,  2.0334e-05,\n",
            "         -4.2667e-05, -7.4789e-06,  1.6128e-06,  9.6705e-07, -1.8286e-05,\n",
            "         -6.7942e-06, -2.1833e-05,  1.6128e-05,  1.4390e-05,  5.4819e-01,\n",
            "         -6.0925e-06,  8.7584e-06, -5.6506e-06, -1.2299e-05, -5.7524e-06,\n",
            "         -1.2423e-05,  1.1567e-05,  1.7856e-06, -2.2614e-05,  1.5969e-05,\n",
            "          3.2673e-06,  2.4452e-05, -1.5315e-05,  1.9952e-05,  2.4667e-06,\n",
            "          7.1391e-07,  9.2954e-06, -9.0797e-06,  2.9589e-05, -1.8409e-05,\n",
            "         -1.8645e-05, -4.2111e-06,  8.4163e-06,  3.4394e-06, -3.8134e-06,\n",
            "          3.8765e-07,  3.2354e+00, -8.5081e-07, -1.7269e-05,  1.2867e-05,\n",
            "          7.8503e-01, -1.9611e-06,  9.5705e-06, -5.8100e-06, -1.8356e-06,\n",
            "         -5.0608e-06,  8.7011e-06,  1.0877e+00,  2.4135e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3112], requires_grad=True)\n",
            "l1_reg is: 30.258216857910156\n",
            "total_loss 1.2095744609832764\n",
            "pred: tensor([24.2839,  7.0970, 23.2344, 21.9718, 21.9071, 13.6891, 13.5201,  9.5055,\n",
            "         9.4440, 24.2075, 15.8818, 26.9224, 19.8165, 18.9742, 16.4854, 10.0784,\n",
            "        16.2882, 16.9173, 21.3102,  2.9601, 21.4405, 27.6055, 23.6994, 14.1482,\n",
            "        14.1902, 16.8957,  4.9701, 21.3585, 22.5272, 21.3254,  5.6075, 28.2221,\n",
            "        12.1410, 13.9950, 13.0220, 26.3054,  4.1687, 19.3462,  5.5888, 16.8927,\n",
            "        16.4914,  4.6267, 21.2955, 26.1170, 11.7186, 34.9713, 11.1501, 27.6974,\n",
            "        14.9509, 19.0938,  5.9275, 11.1035, 27.5856, 27.7244, 23.3823, 22.0897,\n",
            "         9.4912, 10.5894, 13.8612,  8.3950, 25.0296,  8.7592, 13.7407, 11.5344,\n",
            "         9.3615, 10.5482, 13.8203, 13.3996, 17.8497, 21.0878, 30.5687,  5.2835,\n",
            "        19.3697,  6.4617,  3.1570,  5.5394,  5.2752, 20.5636, 11.1736, 12.3582,\n",
            "        11.4825, 14.5341, 25.7198, 21.6426, 11.4935, 10.5332,  5.5599, 28.0221,\n",
            "        12.8380, 17.2195,  8.1458, 24.7487, 15.0902, 13.5917, 22.1681, 21.5025,\n",
            "         9.7068, 16.1602,  7.9034, 26.5858,  3.9549,  6.9564, 11.0972,  6.4586,\n",
            "         7.2101, 20.8748, 36.3089, 10.2278, 20.2458, 25.1010, 16.9038, 15.4973,\n",
            "        21.0941, 18.1044, 24.6693, 16.6423, 19.9384, 10.2334, 26.0985,  8.8122,\n",
            "         7.5240, 25.9360, 25.9201,  7.3787, 12.1384,  8.5030, 13.8468,  2.7241,\n",
            "         3.6158, 14.0936, 15.4003, 15.8375, 14.7751, 19.4473, 21.9223, 25.5531,\n",
            "        17.1165, 24.2219, 13.3239,  6.1750, 20.6669, 16.2030, 19.9978,  5.6640,\n",
            "        20.0013,  6.0093, 22.2015, 16.8320, 26.7182, 21.7993, 21.2132,  9.2225,\n",
            "        26.0186, 15.2008, 15.8961, 26.4702, 12.2149, 27.8881, 16.5272, 29.1141,\n",
            "        22.9330,  8.5582, 28.1267, 20.3565, 10.4503, 28.4030, 26.3066,  9.1098,\n",
            "         5.8046, 20.4527,  8.7730, 14.6149,  7.0779, 24.5552, 25.0341, 16.6663,\n",
            "        12.5144, 13.7816, 19.8096, 15.6484, 20.3428,  4.6365,  9.8995, 19.2342,\n",
            "        27.0911, 28.7836, 25.3355,  6.0975, 23.4032, 33.2463, 20.0955, 20.6423,\n",
            "        31.2870,  2.8212, 20.4770, 22.1436, 12.1032, 24.3045, 17.0031, 14.4427,\n",
            "         7.4342, 36.9327, 13.4559, 12.3502, 17.2865, 16.8262, 11.4046, 13.7830,\n",
            "        27.4876,  5.6732, 27.5798, 34.8064, 27.2733, 11.8956, 16.4051, 13.7124,\n",
            "        13.3650, 14.3722, 13.2700, 15.4469, 20.5858, 24.9383, 16.3077, 16.9686,\n",
            "        20.7781, 29.4005, 15.2835,  4.2005,  4.9479, 27.7351, 11.0084, 11.3845,\n",
            "        27.1169, 15.5872, 17.7089,  4.9613, 19.3264, 14.7379, 15.0599, 13.7554,\n",
            "        15.5493, 12.6975, 28.4888, 20.4321,  6.0208, 12.8547,  5.7511, 15.5130,\n",
            "        11.5738, 17.9752,  8.7767, 21.0047, 23.8261, 25.2571, 15.9232, 16.7666,\n",
            "        15.0246,  7.7133, 25.6047, 23.6080, 21.7208, 12.2469, 13.2294, 12.7951,\n",
            "        13.1702,  3.2104, 29.5656, 24.3389,  6.0172, 26.0751],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([22.6834,  6.9288, 23.2301, 25.1133, 22.2456, 13.4441, 12.8218,  9.7305,\n",
            "         9.8216, 23.7807, 14.8657, 27.2146, 16.5860, 19.6914, 13.6355, 10.2067,\n",
            "        19.1049, 17.0279, 20.5967,  3.2286, 21.5825, 27.7032, 23.8618, 14.5338,\n",
            "        13.2863, 16.9849,  5.7261, 22.9497, 22.4202, 20.1764,  5.7801, 27.1171,\n",
            "        11.6439, 13.9567, 14.1966, 26.6139,  4.3382, 18.7735,  5.4799, 14.5425,\n",
            "        15.9629,  5.5891, 22.0973, 25.6052, 11.6739, 33.8413, 10.0882, 26.9071,\n",
            "        14.0370, 17.5585,  5.3168, 11.1362, 26.8546, 25.5266, 22.6298, 22.8089,\n",
            "        10.7772,  8.8495, 13.2268,  7.5058, 22.7811,  8.9440, 12.3529, 11.3705,\n",
            "         9.4027,  9.5732, 15.2404, 12.7754, 16.7125, 19.8781, 31.9832,  5.9224,\n",
            "        19.6373,  5.7616,  2.9763,  5.2606,  5.8000, 20.8847, 10.8934, 10.5796,\n",
            "        11.9273, 13.2216, 25.0882, 21.4369, 10.8720, 10.4300,  5.4434, 28.1975,\n",
            "        12.3930, 18.0751,  8.9939, 25.4667, 15.8497, 13.6148, 24.8666, 21.7208,\n",
            "        10.2986, 15.3233,  8.8367, 25.2300,  3.4038,  5.6818,  9.6923,  6.1372,\n",
            "         7.6659, 20.2473, 36.0293, 10.2500, 22.1143, 26.1508, 17.6020, 15.7130,\n",
            "        22.2998, 17.2200, 25.9200, 16.1333, 21.2929,  9.3152, 28.4876,  9.2040,\n",
            "         7.9767, 25.2012, 24.0979,  5.8988, 11.0619,  8.7828, 13.8511,  2.8186,\n",
            "         2.8868, 13.7214, 15.7150, 15.1120, 14.6175, 18.3327, 21.5185, 25.0184,\n",
            "        15.4452, 25.2080, 12.7119,  6.4091, 19.2753, 15.6387, 20.5191,  6.1396,\n",
            "        19.9219,  4.7111, 24.0582, 17.0326, 26.2982, 22.2379, 20.3947,  9.6741,\n",
            "        25.5564, 14.2097, 15.6076, 24.3048, 11.6902, 26.2064, 16.8294, 28.5535,\n",
            "        21.9823, 10.0399, 25.6981, 21.0106,  9.2334, 27.8580, 25.7021,  9.2548,\n",
            "         5.9091, 20.5062,  8.2869, 15.6164,  7.5116, 24.4002, 23.7816, 16.3600,\n",
            "        12.5389, 13.0735, 19.2678, 16.6146, 19.4142,  4.7112,  9.7826, 20.8937,\n",
            "        24.9590, 27.9032, 25.0859,  6.6406, 22.5502, 33.1963, 19.9705, 20.2477,\n",
            "        32.4809,  2.6395, 19.5712, 23.5169, 12.0117, 24.1904, 15.4370, 14.8276,\n",
            "         8.0952, 36.7231, 12.6670, 12.4772, 15.9774, 17.1398, 11.3636, 12.9426,\n",
            "        29.0540,  6.1958, 26.6424, 33.6615, 27.6397, 11.8117, 16.6193, 15.5242,\n",
            "        14.9485, 13.9880, 13.7270, 16.1538, 20.3132, 24.7221, 18.0235, 15.6183,\n",
            "        20.4839, 29.9533, 14.8438,  4.2411,  4.6879, 25.5027, 11.6278, 11.4877,\n",
            "        28.6013, 15.0278, 19.6378,  4.8105, 19.3151, 15.7830, 15.1563, 12.7916,\n",
            "        15.5292, 13.5350, 29.0553, 21.1832,  5.7299, 12.5347,  7.2487, 15.0293,\n",
            "        12.6457, 16.0614,  9.2253, 20.4319, 22.5008, 26.8806, 17.1809, 17.0751,\n",
            "        16.1979,  8.9623, 23.7457, 23.2506, 21.6329, 11.6320, 13.2050, 12.3256,\n",
            "        13.0290,  2.9711, 32.5764, 23.9864,  6.3095, 25.0707])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.7497e-07,  1.5406e-05, -2.5520e-06,  ..., -3.8740e-06,\n",
            "         -1.0035e-06,  6.2584e-07],\n",
            "        [ 1.1384e-04, -1.1840e-05,  3.3455e-05,  ...,  4.0459e-05,\n",
            "          5.7180e-05,  7.4980e-05],\n",
            "        [-3.2591e-04, -1.4852e-05,  9.7282e-06,  ...,  3.8289e-02,\n",
            "          7.2035e-04, -2.4812e-03],\n",
            "        ...,\n",
            "        [-1.3222e-06,  1.1201e-06, -1.7301e-06,  ...,  2.3474e-05,\n",
            "         -1.4693e-05,  1.1005e-06],\n",
            "        [-7.5831e-06,  6.1497e-06,  1.6961e-06,  ...,  2.5792e-06,\n",
            "         -6.2582e-06, -4.0727e-06],\n",
            "        [-2.5898e-05,  1.8350e-05, -1.6887e-06,  ..., -6.7725e-06,\n",
            "         -2.8482e-05,  6.5610e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-9.2153e-06,  4.2562e-01,  3.6948e-02, -2.8311e-05, -2.5033e-07,\n",
            "         1.5051e-05, -5.5299e-06, -3.0742e-06,  1.5816e+00,  2.4201e-05,\n",
            "        -1.5617e-05,  5.1452e-06,  1.6992e-05, -1.4455e-05,  2.7346e-05,\n",
            "         5.0292e-06, -2.3995e-05, -7.0040e-06, -2.9633e-05, -1.2652e-05,\n",
            "        -1.5062e-05, -5.8500e-06, -6.7447e-06,  9.6672e-06, -8.8808e-06,\n",
            "        -1.7396e-05, -8.7377e-06,  1.3506e-01,  1.4292e-05,  7.8980e-07,\n",
            "         1.5531e-05,  1.3878e-05,  6.9984e-06,  2.8826e-01, -1.9887e-06,\n",
            "        -7.4535e-07, -1.3483e-05,  2.4738e-06,  1.1614e-05,  1.6840e-06,\n",
            "        -6.5044e-06,  7.3355e-06, -1.2282e-05, -5.1109e-07, -3.3486e-06,\n",
            "         1.0741e-05,  2.3779e-05,  1.1064e-05, -1.6123e-05,  2.0053e-04,\n",
            "         1.6498e-06, -4.8444e-06, -2.2288e-06,  8.3311e-06,  2.9172e-05,\n",
            "         9.1151e-07, -1.1948e-04,  3.8424e-06, -4.6683e-06, -1.2118e-05,\n",
            "         1.4404e-05,  8.7200e-07,  1.4556e-05,  5.4025e-06,  8.4596e-06,\n",
            "        -1.8991e-05, -1.1840e-06, -4.6372e-06, -2.5170e-05,  9.4358e-02,\n",
            "        -2.7683e-06, -2.5135e-05, -1.9376e-05, -4.7353e-06, -8.3912e-07,\n",
            "         2.8118e-05, -2.1379e-06,  1.8777e-05,  1.6303e-05, -1.5935e-03,\n",
            "         2.5982e-05, -1.2204e-05,  7.3418e-06,  6.7548e-06, -5.5719e-06,\n",
            "        -2.1988e-06,  3.2395e-05, -1.0412e-05, -2.5715e-06, -3.0321e-06,\n",
            "        -3.0425e-07,  2.1887e-05, -1.6992e-05, -5.5578e-06, -2.0141e-05,\n",
            "        -8.5654e-06, -7.8787e-07,  8.3357e-06, -1.1950e-05, -2.9112e-06,\n",
            "         5.7917e-04,  7.4140e-06, -1.2826e-06,  9.2669e-06,  1.5486e-05,\n",
            "        -2.1971e-05,  4.4910e-06, -3.4861e-06,  9.7913e-06, -9.4441e-06,\n",
            "        -1.6835e-05, -7.2865e-07,  8.9397e-06,  6.4323e-07, -1.3596e-05,\n",
            "        -3.8108e-05,  9.5338e-06, -1.2248e-05, -5.0241e-06,  1.6542e-06,\n",
            "         1.2630e+00, -4.3807e-07, -1.4373e-07, -1.7697e-05,  8.9773e-06,\n",
            "         1.3186e-07,  1.8905e-05,  8.9898e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.7720e-05,  1.1383e-04,  1.2762e-04,  ...,  1.4828e-05,\n",
            "          1.0087e-05, -4.3343e-06],\n",
            "        [-5.7094e-06,  9.1626e-06, -1.1346e-05,  ...,  7.7628e-06,\n",
            "          2.0572e-05, -1.7293e-05],\n",
            "        [ 2.4148e-06,  1.0576e-05, -4.7603e-06,  ...,  2.1172e-07,\n",
            "          1.0949e-05, -5.3314e-06],\n",
            "        ...,\n",
            "        [-4.9559e-06,  1.3449e-05, -1.5342e-05,  ...,  7.6175e-07,\n",
            "          1.4660e-05, -2.7481e-05],\n",
            "        [-1.7860e-05,  4.7989e-04,  5.2349e-04,  ...,  5.7227e-06,\n",
            "         -9.1635e-06,  4.2593e-06],\n",
            "        [-3.3736e-06,  2.2066e-05, -5.6261e-05,  ...,  1.0056e-06,\n",
            "          1.1036e-05, -5.7949e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.5089e-02, -3.5933e-06,  1.9931e-06,  2.5291e-05,  3.2056e-05,\n",
            "         1.7883e-05,  1.0780e-05,  1.5013e-06,  2.4092e-05,  2.1853e-06,\n",
            "        -9.5573e-06, -1.0118e-05, -1.0772e-05,  6.3933e-07,  4.2073e-07,\n",
            "         8.1621e-07, -4.1938e-07, -1.6656e-07,  1.1268e-05, -2.8967e-05,\n",
            "        -6.6030e-06, -1.2054e-05,  2.5898e-05,  2.0687e-05, -5.3704e-05,\n",
            "         3.1860e-06,  5.7327e-06, -1.2798e-05, -5.3891e-07, -4.9395e-06,\n",
            "        -9.3935e-06,  3.0079e-06, -1.2835e-05, -9.6951e-06,  6.6133e-06,\n",
            "        -6.1585e-06, -2.6618e-05, -2.0189e-06, -5.9591e-06, -1.0028e-05,\n",
            "         1.4799e-05,  1.8755e-05,  4.3683e-07,  1.4284e-06,  3.7628e-06,\n",
            "         2.7986e-06, -1.3575e-05,  3.7088e-06,  2.1942e-05,  1.2758e-05,\n",
            "         5.0224e-06,  1.0867e+00, -1.1991e-05,  2.8907e-06, -1.5905e-05,\n",
            "         9.0190e-02,  1.1809e-05,  1.1566e-05,  1.0552e-06,  2.8876e-06,\n",
            "         1.5523e-05, -1.3199e-05,  2.6131e-01,  9.1443e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3546e-01,  5.4888e-06,  7.6278e-06,  1.5280e-05, -1.2520e-06,\n",
            "         -9.6789e-06, -1.6188e-05, -1.1192e-05, -5.0504e-07,  3.1039e-06,\n",
            "          3.1987e-05,  2.0763e-05, -1.4024e-05,  3.6636e-06,  2.9203e-05,\n",
            "         -4.8442e-05,  3.0525e-06, -2.1264e-05, -6.0369e-06, -4.2627e-06,\n",
            "         -7.7710e-06, -1.9665e-05,  2.6222e-05,  1.0082e-05,  5.4809e-01,\n",
            "          3.6016e-06, -1.6987e-05, -7.9578e-07,  3.3895e-06,  1.5177e-06,\n",
            "          1.3322e-05,  1.7146e-05, -1.6608e-05, -1.8517e-05,  2.0742e-05,\n",
            "          7.1836e-06,  2.0719e-05, -1.9438e-05,  3.0453e-05, -6.6414e-06,\n",
            "         -1.7372e-05, -1.2165e-06,  2.9421e-07,  6.6971e-06, -1.2079e-05,\n",
            "          8.0461e-07,  4.4913e-06,  5.1657e-06,  4.3661e-07,  4.9330e-06,\n",
            "         -1.8537e-05,  3.2359e+00,  1.5148e-05, -1.5101e-05, -2.8185e-06,\n",
            "          7.8494e-01,  6.8200e-06, -6.0890e-06, -2.0000e-06,  1.1581e-05,\n",
            "          7.4665e-06,  5.4520e-06,  1.0876e+00,  2.4125e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3112], requires_grad=True)\n",
            "l1_reg is: 30.26873207092285\n",
            "total_loss 1.306595802307129\n",
            "pred: tensor([19.9557, 23.2398,  9.0960, 25.7501, 16.2354, 16.6212, 24.4455, 12.4624,\n",
            "        11.5997, 22.3784, 20.7854,  2.9593, 24.0481,  6.9108,  9.1297, 12.6508,\n",
            "        25.9017, 21.1549, 27.5855, 12.4254, 25.9942,  3.0157,  4.1041,  5.5540,\n",
            "        20.6525, 16.4990,  9.1509,  8.5769,  5.3195,  5.5987, 12.0131,  3.2119,\n",
            "        10.5624,  2.6912, 16.4486, 15.9481, 31.7992, 10.7689, 23.5999, 24.1429,\n",
            "        28.2111, 12.5711, 28.7751, 33.2672, 26.2094, 13.5666, 13.4209, 35.3409,\n",
            "        14.2974, 24.9555,  9.7262, 24.9276,  5.0718, 13.2489,  8.4788, 25.3434,\n",
            "        30.8409, 19.9368, 11.5738, 17.1579, 23.0094,  5.6618, 25.0587, 24.8717,\n",
            "        13.5103, 16.5790, 13.7960,  6.4438, 16.0073, 16.4987,  6.9776, 11.8091,\n",
            "        19.8144, 27.6926, 22.3950, 36.1646, 22.1977, 14.0946, 21.9841,  8.9910,\n",
            "        24.8561, 16.5816, 31.5442, 12.6005,  7.9301, 22.2820, 25.1463, 12.4891,\n",
            "        11.5820, 14.8289, 23.9008,  8.3033,  5.1314, 13.7230, 23.7246, 19.6173,\n",
            "        10.2708,  5.9385,  8.0417,  5.1562, 14.3707, 22.8227, 10.0000,  9.6918,\n",
            "        22.4030, 20.7254, 12.2872, 13.5758, 14.5650,  5.3273,  9.4187, 17.0475,\n",
            "        22.4813, 14.8318, 13.6415,  9.8418, 10.4784, 19.7763,  7.9643, 14.3243,\n",
            "         4.8039,  4.7472,  9.0962, 10.3371, 24.5821, 16.7018,  9.7762, 23.6051,\n",
            "        18.2941,  8.1578, 25.3207, 25.7745, 20.7000, 20.6143,  5.2206, 26.2843,\n",
            "        25.5403, 24.5069, 27.2653, 22.9706,  6.2498,  6.5767, 24.9724, 11.3473,\n",
            "        28.8503, 13.0212, 24.3334, 14.4888,  7.7716, 35.4106, 19.7031, 28.0568,\n",
            "         4.0398, 13.6778,  7.3719, 12.0736, 11.1106, 18.4353, 14.0826,  9.9874,\n",
            "        25.6287, 25.6977,  7.9504,  9.0525, 24.6569, 13.4524, 19.3915, 31.2583,\n",
            "        27.0290, 26.9694, 26.5371, 11.5562, 26.6492, 23.7641, 16.1433, 13.7687,\n",
            "        13.0084, 12.1906, 19.2046, 25.7746,  7.7826,  6.1015, 24.2361, 21.8469,\n",
            "        14.8064,  7.9218, 12.8906, 11.6616, 21.7998, 12.5468, 27.7277,  9.7419,\n",
            "        13.5674, 10.9936,  8.0480,  4.0751,  4.7925, 22.2538, 24.4717, 17.7201,\n",
            "        18.6618, 24.7877,  3.4566, 25.4058, 33.4420, 17.8207, 23.7668, 21.8745,\n",
            "        12.6159, 12.2736, 29.7981, 13.5614, 25.4726, 19.7497, 14.3261, 35.3876,\n",
            "        10.3136, 19.7268,  4.8590,  7.2294,  8.9989, 10.9046, 13.7352, 23.9415,\n",
            "        15.0820,  9.2572, 10.2509, 10.3349, 11.3021, 16.2411, 11.9185, 24.9084,\n",
            "         8.6852, 13.1643,  9.3475, 24.4854, 26.9286, 30.8903,  6.7142,  4.9505,\n",
            "        13.0562, 19.1678,  6.6086,  6.9781, 22.6828, 23.3206, 15.4586,  8.2551,\n",
            "        25.0362, 21.0668,  6.0480, 27.5225, 14.9545,  9.1070, 13.5804, 30.3248,\n",
            "         3.7741, 16.9697,  6.7837, 12.9847, 20.9375,  8.9321, 17.7197, 25.1240,\n",
            "        25.8870,  8.9276, 15.6421, 13.3732, 11.0856, 14.8026],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([19.1687, 23.0878,  8.6930, 26.5690, 16.0288, 17.4081, 22.4621, 12.7419,\n",
            "        11.6967, 22.0434, 21.4650,  2.7835, 21.9933,  7.8824,  8.6887, 12.0164,\n",
            "        23.7378, 20.2236, 29.3879, 13.3165, 25.9673,  2.4964,  3.8066,  6.0261,\n",
            "        19.9495, 14.9121,  9.1349,  8.8915,  5.0824,  5.8940, 12.6669,  3.3276,\n",
            "        10.3292,  3.5024, 15.3364, 14.5522, 32.1687,  9.9701, 24.7881, 23.9214,\n",
            "        29.6129, 13.1460, 28.6023, 33.6783, 25.3011, 14.7017, 14.2595, 35.6195,\n",
            "        13.5708, 24.9055,  9.1212, 23.9575,  5.3867, 12.6357,  7.6252, 25.2709,\n",
            "        28.4758, 19.9588, 11.0437, 16.6667, 21.9457,  5.2326, 25.2018, 25.9682,\n",
            "        13.4342, 17.2241, 13.8787,  7.2207, 17.3588, 18.1604,  6.5972, 11.8714,\n",
            "        19.8440, 27.6650, 22.0323, 35.1006, 21.1755, 14.7177, 20.2788,  8.1231,\n",
            "        22.2626, 16.7238, 32.0161, 11.8580,  7.5672, 24.7259, 24.1835, 12.6549,\n",
            "        10.9001, 15.3285, 24.2089,  7.1429,  5.1852, 13.1744, 22.0525, 18.8388,\n",
            "        10.0293,  5.4622,  7.4477,  4.2700, 14.4099, 22.7441, 10.3358, 10.5634,\n",
            "        22.5453, 20.9787, 13.2615, 12.1542, 15.7759,  5.1181,  8.5330, 19.4611,\n",
            "        22.4144, 14.3872, 12.8787,  9.6474,  9.6956, 20.8130,  8.1708, 14.4799,\n",
            "         5.6575,  4.6756,  8.4304, 10.2318, 25.1940, 16.8010,  9.1734, 23.2959,\n",
            "        16.1303,  7.8224, 24.6491, 24.3040, 22.4324, 20.3443,  5.4569, 24.8762,\n",
            "        24.6207, 25.4290, 27.4537, 23.4949,  6.5385,  6.2667, 23.7057, 10.9200,\n",
            "        28.4408, 12.8757, 25.9556, 15.0504,  7.5074, 36.1161, 17.9237, 25.8522,\n",
            "         3.3276, 14.5794,  9.0463, 13.7851, 10.5968, 18.2288, 12.5806, 10.2887,\n",
            "        25.4995, 26.9901,  8.3572,  8.4420, 23.7793, 13.4997, 17.3852, 29.7360,\n",
            "        26.3172, 23.7784, 26.3706, 13.5715, 25.4348, 22.9585, 15.1990, 13.5361,\n",
            "        13.9191, 13.7664, 19.2308, 24.9442,  8.8633,  7.0349, 24.1173, 22.3123,\n",
            "        15.5626,  7.1078, 12.0427, 12.0462, 21.5427, 13.1496, 25.2593, 10.5809,\n",
            "        15.6390, 10.3828, 12.4000,  3.9589,  4.3307, 22.6352, 23.4348, 18.6427,\n",
            "        20.2343, 25.0780,  2.7879, 24.4827, 30.7192, 17.9615, 24.2404, 21.9444,\n",
            "        12.5976, 11.4345, 29.0925, 13.8693, 24.4875, 21.1737, 14.8241, 35.9269,\n",
            "         9.4371, 18.9278,  4.9312,  7.9269,  9.2930, 10.0635, 13.1617, 23.6692,\n",
            "        16.1818,  9.5583,  9.3175,  9.4370, 10.0828, 14.8727, 11.8827, 23.3247,\n",
            "         8.9643, 11.6033, 10.2011, 21.9658, 26.5404, 30.0670,  5.8161,  5.6016,\n",
            "        12.5554, 18.4841,  6.9476,  6.7507, 22.0358, 24.1517, 14.7400,  8.5251,\n",
            "        23.3949, 22.3315,  6.5972, 26.8387, 15.3904,  8.6667, 12.6138, 30.6270,\n",
            "         4.3103, 19.9029,  6.1983, 12.8758, 19.6073,  8.2031, 16.5177, 24.4880,\n",
            "        25.3500, 10.1438, 15.3179, 13.5947, 11.0390, 15.8537])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.4966e-06,  3.4488e-06,  1.8858e-06,  ..., -7.9800e-06,\n",
            "          1.4655e-05, -2.2137e-05],\n",
            "        [ 7.5739e-05, -1.1291e-05,  1.9360e-05,  ...,  1.1419e-04,\n",
            "          1.7299e-04,  1.3476e-04],\n",
            "        [-3.0318e-04,  1.3301e-05, -1.5742e-05,  ...,  3.8489e-02,\n",
            "          7.1146e-04, -2.4064e-03],\n",
            "        ...,\n",
            "        [ 6.6416e-06, -1.4699e-05,  4.3312e-06,  ...,  2.2277e-05,\n",
            "         -6.5422e-06,  3.9043e-06],\n",
            "        [-1.6269e-05, -3.8905e-06, -1.6694e-05,  ..., -1.3114e-05,\n",
            "          1.6038e-05,  1.8707e-05],\n",
            "        [-3.0154e-06,  4.1331e-06, -9.1782e-06,  ...,  4.9252e-06,\n",
            "         -2.6289e-05,  1.5252e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.6313e-06,  4.2540e-01,  3.6875e-02, -2.7632e-05,  8.7572e-06,\n",
            "        -4.7392e-06,  6.6127e-06, -6.0728e-06,  1.5807e+00,  2.1985e-05,\n",
            "        -1.3227e-06, -1.5898e-06,  1.2021e-05, -5.9481e-06,  4.2163e-05,\n",
            "        -1.0627e-05, -1.9568e-05,  1.3762e-05, -2.7611e-05,  1.5891e-06,\n",
            "        -1.9247e-05,  1.1246e-05, -7.4105e-06, -6.0160e-06, -2.5590e-06,\n",
            "        -1.3107e-05,  3.9771e-06,  1.3485e-01,  2.4090e-05, -8.2259e-06,\n",
            "         7.6893e-06,  7.5710e-06, -7.9035e-06,  2.8811e-01,  1.3691e-05,\n",
            "         1.2300e-05,  9.8491e-07, -1.3208e-05,  1.5722e-05, -5.2146e-06,\n",
            "         1.4281e-05, -1.7713e-06,  1.5304e-06,  1.1496e-05,  8.9162e-08,\n",
            "         1.9434e-05,  1.9656e-05,  4.7667e-06, -1.3909e-05,  2.0821e-04,\n",
            "        -5.0393e-06,  5.6411e-06,  3.8121e-06, -7.3400e-06,  2.7015e-05,\n",
            "        -2.3019e-07,  2.2305e-04,  2.4035e-06, -8.4139e-06, -3.3632e-06,\n",
            "         9.2098e-06, -4.9667e-06,  1.2368e-05, -1.0234e-05, -1.3514e-05,\n",
            "        -2.6297e-05, -3.6259e-06, -6.0800e-06, -1.3208e-05,  9.4167e-02,\n",
            "         6.8058e-07, -1.4292e-05, -5.6668e-06, -3.4288e-06,  3.3173e-06,\n",
            "         1.7632e-05,  1.1670e-05,  1.6608e-05,  9.9750e-06, -1.7467e-03,\n",
            "         1.4370e-05, -1.3598e-05,  6.7965e-06,  7.7601e-06,  1.0095e-05,\n",
            "         9.7367e-06,  2.1819e-05, -1.9120e-05, -9.6244e-07,  8.9165e-06,\n",
            "         1.0160e-05,  1.7802e-05, -5.0272e-06,  6.5761e-06, -8.9056e-06,\n",
            "        -6.6453e-06,  2.7668e-06, -8.3955e-06,  1.8871e-06,  1.5502e-05,\n",
            "         4.1570e-04, -3.0862e-06,  6.6859e-06,  2.9727e-06,  3.9139e-07,\n",
            "        -3.2559e-05,  5.9193e-06,  7.0025e-06, -5.8723e-06, -3.0968e-06,\n",
            "        -2.3389e-05,  2.1935e-05, -9.2137e-06, -8.3201e-06, -1.6170e-05,\n",
            "        -2.1921e-05,  1.8225e-05, -6.7662e-06, -9.1277e-06, -1.4687e-05,\n",
            "         1.2625e+00,  1.9532e-07,  1.3653e-05, -2.6362e-05,  2.6981e-06,\n",
            "        -1.3290e-05, -5.0426e-07,  9.7483e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-2.4727e-05,  5.8026e-05,  8.0747e-05,  ...,  6.6856e-06,\n",
            "          1.5650e-05,  2.9362e-06],\n",
            "        [-8.9041e-06,  1.0457e-05, -2.0034e-05,  ...,  1.4586e-06,\n",
            "          8.6100e-06, -1.4466e-05],\n",
            "        [-1.8351e-05,  1.1326e-05,  1.7562e-05,  ..., -6.2802e-06,\n",
            "          4.0160e-06,  1.0342e-05],\n",
            "        ...,\n",
            "        [-5.5165e-06,  1.9096e-05, -1.9723e-05,  ..., -1.0185e-05,\n",
            "          6.2692e-06, -2.5301e-05],\n",
            "        [-1.2065e-05,  3.8707e-04,  4.5734e-04,  ..., -3.7941e-06,\n",
            "          5.4756e-06, -1.1970e-05],\n",
            "        [ 3.4938e-06, -1.4291e-05, -6.8566e-05,  ..., -6.9570e-06,\n",
            "          1.3110e-05, -6.2442e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.4878e-02, -2.1441e-06, -5.9728e-06,  1.3326e-05,  2.3723e-05,\n",
            "        -1.6692e-06,  1.6374e-05, -4.9591e-06,  1.3114e-05,  1.1065e-08,\n",
            "        -1.2151e-05, -1.4229e-05, -1.6143e-05, -7.3274e-06, -8.5642e-06,\n",
            "        -1.1116e-05,  1.7533e-05,  1.3253e-05,  1.6680e-05, -2.6788e-05,\n",
            "         1.5722e-05, -5.7442e-06,  2.4824e-05,  2.9842e-05, -4.0161e-05,\n",
            "        -3.2308e-06, -1.1926e-05, -2.2479e-05,  1.5950e-05,  7.9947e-06,\n",
            "         1.1030e-06, -1.0415e-05,  2.7319e-06, -9.2741e-06,  3.0312e-07,\n",
            "         3.3351e-06, -4.1426e-05, -5.0377e-06,  1.3052e-06,  1.5721e-05,\n",
            "        -5.9629e-06,  2.9268e-05, -1.3811e-05,  9.0182e-06, -5.0046e-06,\n",
            "         5.8195e-06, -1.8271e-05,  6.7627e-06,  9.9800e-06,  4.1734e-06,\n",
            "         6.5871e-06,  1.0859e+00,  2.7877e-06, -3.9982e-06, -1.0017e-05,\n",
            "         8.9927e-02,  1.7623e-05,  1.3640e-05,  8.5464e-06, -1.7879e-05,\n",
            "         1.9629e-05, -2.6379e-05,  2.6098e-01,  9.1989e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3535e-01, -1.5274e-05,  1.0076e-06,  2.8448e-05,  5.5491e-07,\n",
            "         -2.6911e-06, -1.1253e-05, -1.1978e-05,  8.7165e-06, -5.9974e-06,\n",
            "          3.3829e-05,  3.3934e-05, -7.7152e-06, -1.2011e-05,  2.7167e-05,\n",
            "         -4.3645e-05,  2.5279e-06, -3.1861e-05, -2.3404e-06,  1.8358e-05,\n",
            "          1.3498e-06, -7.7147e-06,  2.5307e-05, -3.8025e-06,  5.4799e-01,\n",
            "          2.3262e-06, -3.0176e-05,  1.3574e-05,  7.5073e-06, -1.9664e-06,\n",
            "          2.6484e-05,  1.2161e-05, -2.3162e-05, -4.8335e-06,  1.5033e-05,\n",
            "          7.0835e-07,  7.3596e-06, -1.3155e-05,  2.9894e-05, -4.8386e-06,\n",
            "         -2.3665e-05, -6.8740e-07, -1.2731e-06, -2.3905e-05,  3.6174e-06,\n",
            "          8.3096e-06,  2.3234e-06, -7.7608e-06, -1.2285e-05,  2.8048e-06,\n",
            "         -2.5584e-05,  3.2349e+00,  1.9546e-05, -3.1729e-06, -6.9406e-06,\n",
            "          7.8480e-01,  4.7073e-06, -1.0183e-05,  1.1429e-05,  1.3656e-05,\n",
            "          8.7330e-06, -7.4722e-06,  1.0874e+00,  2.4115e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3109], requires_grad=True)\n",
            "l1_reg is: 30.268552780151367\n",
            "total_loss 1.3112921714782715\n",
            "pred: tensor([26.6032, 20.8806, 11.2500,  9.3094,  8.0957, 26.5380, 16.3455, 29.1037,\n",
            "        13.6948, 17.1010, 20.9278,  4.2239, 11.1517, 21.9830, 14.3529, 13.2911,\n",
            "        22.7448,  8.0101, 13.7901, 12.0252, 33.0038, 11.8145,  9.7691, 10.4701,\n",
            "        15.6931, 25.4874,  8.2745, 19.5867, 19.0082, 18.8885, 20.3256, 23.2098,\n",
            "         5.6440,  7.0566, 15.9474, 23.7039, 16.5717, 12.3936, 28.5644, 26.0823,\n",
            "        14.3672, 29.1222, 19.8816, 19.8291, 18.6060, 16.3453, 22.6157, 25.8584,\n",
            "        24.7785, 13.5734,  8.6775, 18.9069, 13.5045, 15.3221, 24.7351, 36.7766,\n",
            "        13.6489,  5.3087,  8.1438, 20.4869, 15.3374, 12.4129, 22.4082, 11.7337,\n",
            "        18.7147, 19.9804, 14.5033, 21.2138,  4.0761, 13.2994, 15.0300, 15.7153,\n",
            "        15.7623,  5.6669, 20.2491, 27.1584,  5.2054, 26.3491,  8.1006, 26.6813,\n",
            "        15.7602, 26.6687, 17.6349, 13.9468, 14.4330,  8.3378, 22.2488, 16.5281,\n",
            "         5.2089, 14.6187, 18.9557, 14.4023, 12.2545, 24.3243,  7.7901,  8.7605,\n",
            "        15.2711,  4.0350,  5.2702, 21.7188,  5.9270, 16.2542, 27.1376, 35.1041,\n",
            "        13.6934, 16.6267, 20.5063, 10.6917, 27.0327, 16.2881, 18.9423, 24.8816,\n",
            "         7.4262, 22.4611, 10.2457, 21.5751, 13.9064,  6.5137, 18.2193, 21.1712,\n",
            "        24.5280,  4.1735, 12.3007, 26.2822, 13.8450, 12.5227, 11.4915, 24.9482,\n",
            "        22.9380,  8.0883, 22.3287, 22.0075, 24.5431, 10.0980, 22.4786, 13.9098,\n",
            "        22.1558, 10.8415, 20.5443, 12.9679, 19.0903, 26.3307,  4.8283, 20.7864,\n",
            "        11.0030, 13.2470, 17.6902,  7.3351,  4.3770, 20.5234, 27.0219,  6.6984,\n",
            "         3.9878, 16.7533,  7.2173,  9.9814, 29.6735,  7.7314,  5.3849, 33.6761,\n",
            "        32.4464, 27.0333, 11.8398, 11.3568,  5.2552, 24.2938, 13.0720, 10.7084,\n",
            "         6.3820, 32.9366, 25.8623, 12.4761, 25.9651, 17.0063,  2.7750,  6.1475,\n",
            "        19.9134, 10.9236, 12.9433, 15.5004, 12.8102, 22.8132,  6.7600, 20.2875,\n",
            "        22.6575, 15.4232,  9.6700, 17.7203, 21.8089, 26.4463, 33.9745, 24.2337,\n",
            "        25.3095, 17.2003, 12.2610, 12.2182, 14.8526, 15.7982,  7.1503, 17.8311,\n",
            "         8.8443, 20.6561, 17.4897, 11.7315, 10.5344, 18.6821, 12.6318, 18.6429,\n",
            "        27.1982, 21.9376, 24.3453, 13.1656, 24.8126, 23.7038, 17.7201, 10.3712,\n",
            "         7.5432, 26.3666, 12.5831, 22.3077, 12.6868,  5.3618, 11.6489, 13.8967,\n",
            "        18.0283, 23.0376,  5.2631,  8.9062, 13.8955,  9.0548,  5.7563, 23.9501,\n",
            "        26.0903, 12.6728, 10.6048, 14.7517, 23.2508, 21.2141, 17.2938, 10.9602,\n",
            "         5.5840, 14.5164,  9.7088, 19.6140,  9.8025, 12.9046, 16.6367, 26.3104,\n",
            "        13.9074, 13.4849, 22.5324, 27.2392, 11.0336, 22.0135, 23.1633, 22.8026,\n",
            "         6.3916, 16.9372, 12.9153, 23.9935, 11.1905, 23.6382, 14.0080, 22.3643,\n",
            "        15.9749, 13.2202, 22.6746, 27.7544, 26.3243, 23.9495],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([26.4628, 23.3380, 10.8996,  9.3660,  7.9747, 27.2424, 18.0060, 27.6612,\n",
            "        12.5427, 18.3399, 21.7023,  3.7764, 10.2267, 22.2477, 16.4965, 11.4635,\n",
            "        22.4381,  8.3830, 13.2229, 11.3362, 33.4135, 10.7634,  9.7137, 11.5772,\n",
            "        15.0229, 25.5912,  8.8057, 18.8843, 18.5847, 19.9756, 20.9200, 22.8251,\n",
            "         5.6182,  7.4371, 14.7459, 25.3326, 16.6661, 11.2031, 29.4770, 25.3228,\n",
            "        14.1245, 28.9013, 19.9049, 18.8625, 20.3412, 18.0195, 22.7719, 25.7246,\n",
            "        24.5346, 10.8209,  8.3439, 17.0130, 13.4694, 15.8325, 26.0279, 37.4974,\n",
            "        12.8029,  5.1222,  7.5893, 19.8522, 13.7915, 11.7231, 22.3483, 11.5220,\n",
            "        21.2180, 19.6751, 15.6198, 19.9257,  3.8386, 13.0535, 15.0563, 16.7840,\n",
            "        15.6250,  4.8006, 19.7124, 26.6282,  4.0730, 26.5958,  7.7878, 27.9312,\n",
            "        16.1891, 28.5991, 17.2766, 13.5277, 14.6563,  8.3333, 22.3404, 15.3061,\n",
            "         4.9688, 13.4101, 18.1318, 14.7849, 11.1608, 24.7204,  7.0093,  9.6307,\n",
            "        15.1062,  3.6318,  4.9038, 22.5258,  5.6287, 15.6797, 28.0660, 34.8983,\n",
            "        13.2873, 17.5987, 19.9523, 10.3342, 27.5510, 16.4352, 19.4010, 24.6307,\n",
            "         6.1151, 23.2249,  9.8276, 20.0288, 13.2884,  6.1916, 17.8309, 22.1634,\n",
            "        24.5546,  4.1866, 12.1160, 23.5499, 13.0728, 12.2535, 11.9352, 24.8246,\n",
            "        22.6914,  8.1897, 23.3834, 22.4990, 23.6905, 10.8617, 23.7068, 13.7875,\n",
            "        21.4063, 11.5276, 20.4546, 11.9545, 19.1964, 26.5838,  4.6487, 20.4992,\n",
            "        10.6641, 13.9020, 16.0704,  7.2581,  4.7401, 18.7199, 26.1066,  6.1462,\n",
            "         3.0594, 19.9541,  7.4115,  9.7996, 30.5375,  8.2031,  6.0089, 33.9005,\n",
            "        35.0221, 26.0619, 11.1512, 12.8317,  5.3413, 25.8410, 14.1129, 10.0000,\n",
            "         5.7317, 34.9496, 28.1735, 13.0252, 24.6701, 18.8259,  2.4920,  5.9249,\n",
            "        19.3274, 10.2621, 12.7256, 16.0714, 13.2069, 23.0805,  6.6964, 20.3720,\n",
            "        22.2177, 14.3155,  9.5000, 17.5004, 22.3133, 27.3015, 36.0361, 24.5242,\n",
            "        27.0473, 15.6017, 13.3624, 12.5002, 15.3425, 15.9647,  7.1256, 17.4771,\n",
            "         9.4725, 20.9514, 16.5541, 10.9867, 10.4645, 18.1222, 13.1175, 17.1642,\n",
            "        29.0526, 22.2808, 24.4339, 13.2241, 25.7845, 24.5591, 19.0511,  9.5396,\n",
            "         7.7035, 26.5567, 12.2253, 22.1074, 11.9753,  4.2355, 11.7910, 15.7058,\n",
            "        18.2666, 23.1234,  5.6825,  9.2650, 14.3903,  9.0616,  6.1747, 24.1602,\n",
            "        27.4696, 11.3941,  9.8110, 14.9789, 23.9096, 21.9609, 16.6666, 10.8215,\n",
            "         5.2738, 16.3921, 10.6815, 20.1903, 11.0962, 11.6972, 16.1702, 26.8985,\n",
            "        14.2810, 14.5243, 22.9592, 28.0782, 11.4865, 21.7506, 21.0167, 23.1913,\n",
            "         5.9271, 17.0786, 12.1706, 23.5130, 10.6579, 24.0977, 14.3739, 20.4129,\n",
            "        18.0296, 13.1820, 21.4348, 28.0427, 26.7881, 23.4528])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 7.3140e-06, -1.7313e-05, -4.1202e-06,  ..., -1.6635e-06,\n",
            "          1.8764e-05, -3.2610e-05],\n",
            "        [ 4.6001e-05,  1.5994e-05, -7.4618e-06,  ...,  2.5773e-05,\n",
            "          1.1103e-04,  1.0641e-04],\n",
            "        [-2.4041e-04,  5.7935e-05, -2.8664e-05,  ...,  3.8389e-02,\n",
            "          4.7278e-04, -2.5074e-03],\n",
            "        ...,\n",
            "        [ 3.8081e-06, -1.8937e-05, -2.1342e-07,  ...,  1.1204e-05,\n",
            "          1.0797e-05, -3.5700e-06],\n",
            "        [-1.4087e-05, -2.9267e-06, -2.3245e-05,  ..., -1.7241e-05,\n",
            "          2.6090e-05,  2.9203e-05],\n",
            "        [ 2.7579e-05, -1.8662e-05, -5.9188e-06,  ...,  5.4596e-06,\n",
            "         -1.4310e-05,  1.3076e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.9165e-06,  4.2502e-01,  3.6269e-02, -1.7013e-05,  6.8621e-06,\n",
            "        -1.2564e-05,  7.5293e-06,  1.2275e-06,  1.5789e+00,  9.9566e-06,\n",
            "         2.1537e-05,  2.3522e-06, -2.4535e-06,  1.1702e-05,  4.5501e-05,\n",
            "        -1.4719e-05, -5.5822e-06,  2.2449e-05, -1.5791e-05,  4.4072e-06,\n",
            "        -1.3018e-05,  1.6627e-05,  1.9865e-06, -1.0126e-05,  1.3129e-05,\n",
            "         7.5344e-07,  5.4385e-06,  1.3451e-01,  2.2914e-05, -6.3411e-06,\n",
            "        -9.3706e-06, -8.1087e-06, -1.1315e-05,  2.8740e-01,  1.7807e-05,\n",
            "         1.4041e-05,  4.0143e-06, -1.7324e-05,  9.4073e-06, -1.4234e-06,\n",
            "         2.2987e-05,  2.9761e-08,  3.9544e-06,  1.2300e-05, -6.8178e-06,\n",
            "         1.7257e-05,  5.9386e-06, -1.0911e-05, -1.8975e-06,  1.9158e-04,\n",
            "        -1.0595e-06,  5.0747e-06, -7.5686e-07, -1.1461e-05,  1.5063e-05,\n",
            "         8.7356e-06,  4.2855e-04, -8.8686e-06, -1.8023e-06,  1.4517e-05,\n",
            "        -5.4847e-06, -2.3282e-07,  3.9879e-07, -1.4290e-05, -2.3287e-05,\n",
            "        -2.2871e-05,  4.1768e-06,  2.6230e-06,  7.5635e-06,  9.3885e-02,\n",
            "        -6.2157e-06,  5.4770e-06,  1.6672e-05,  7.7484e-06, -2.9427e-06,\n",
            "        -1.7895e-06,  1.4093e-05,  4.6291e-06, -5.7243e-06, -2.3701e-03,\n",
            "        -6.0691e-06, -4.8580e-06, -3.6933e-06, -1.3250e-06,  1.4175e-05,\n",
            "         1.0483e-05,  2.2997e-06, -1.6963e-05,  1.0474e-05,  9.6660e-06,\n",
            "         9.5807e-06,  4.1208e-06,  1.5741e-05,  7.5086e-06,  1.1205e-05,\n",
            "         5.0835e-06, -4.0379e-06, -1.3459e-05,  4.3361e-06,  2.2083e-05,\n",
            "         7.6953e-05, -2.5363e-06,  3.8633e-06, -1.2695e-05, -2.3192e-05,\n",
            "        -3.2061e-05, -2.8104e-06,  6.4478e-06, -9.9720e-06,  1.2613e-05,\n",
            "        -1.9290e-05,  3.2329e-05, -1.5553e-05, -6.3870e-06, -8.4807e-06,\n",
            "         2.6320e-06,  1.6052e-05,  8.1696e-06, -2.8168e-06, -1.9392e-05,\n",
            "         1.2613e+00, -9.2230e-06,  1.6052e-05, -2.4144e-05, -1.2950e-05,\n",
            "        -1.5365e-05, -7.9700e-06,  4.3172e-07], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-2.1042e-05, -1.1755e-04, -1.1890e-04,  ..., -1.0646e-05,\n",
            "          1.0654e-05, -5.2140e-07],\n",
            "        [-1.7794e-06,  1.6225e-06, -1.7853e-05,  ..., -1.4215e-05,\n",
            "         -1.2156e-05, -1.9219e-06],\n",
            "        [-2.7040e-05,  2.0006e-06,  2.7652e-05,  ..., -2.1229e-06,\n",
            "         -1.2224e-05,  1.4449e-05],\n",
            "        ...,\n",
            "        [ 3.9790e-06,  1.4178e-05, -1.3667e-05,  ..., -1.0037e-05,\n",
            "         -1.1283e-05, -1.3339e-05],\n",
            "        [ 3.1319e-06,  5.9245e-05,  8.8288e-05,  ..., -2.3675e-06,\n",
            "          8.6462e-06, -1.6579e-05],\n",
            "        [-3.2552e-07, -3.7012e-05, -6.9641e-05,  ..., -4.1234e-06,\n",
            "          4.9777e-06,  3.3514e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.4531e-02,  9.1603e-06, -3.1424e-06, -7.4514e-06,  6.2229e-06,\n",
            "        -9.2653e-06,  1.1412e-05, -7.7015e-07, -6.7688e-06, -1.1944e-05,\n",
            "        -4.4964e-06, -7.9290e-06, -1.0977e-05, -4.4975e-06, -6.6564e-06,\n",
            "        -1.1843e-05,  2.3690e-05,  1.5340e-05,  1.1552e-05, -1.4832e-05,\n",
            "         2.5815e-05,  9.9344e-06,  1.3857e-05,  2.8083e-05, -1.7972e-05,\n",
            "         9.9406e-07, -1.7811e-05, -2.1191e-05,  2.0788e-05,  9.6360e-06,\n",
            "         5.4167e-07, -1.2500e-05,  6.7476e-06,  1.1048e-06, -1.5376e-05,\n",
            "         1.8792e-06, -4.4753e-05,  2.2460e-06, -2.1593e-06,  2.8896e-05,\n",
            "        -1.4646e-05,  2.8730e-05, -1.6634e-05,  5.8516e-06, -2.8952e-06,\n",
            "        -1.4617e-06, -1.2498e-05, -4.8667e-07, -1.0783e-05, -1.3553e-05,\n",
            "        -1.9984e-06,  1.0843e+00,  6.0882e-06, -1.9741e-07,  5.2828e-06,\n",
            "         8.9465e-02,  1.2854e-05,  5.5081e-06,  5.2884e-06, -2.6569e-05,\n",
            "         1.3325e-05, -2.8241e-05,  2.6038e-01,  8.2480e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3524e-01, -2.3960e-05, -1.4961e-05,  3.0294e-05, -7.8189e-06,\n",
            "          1.3595e-05,  3.1635e-06, -2.7167e-06,  7.0133e-06, -4.2091e-06,\n",
            "          2.5460e-05,  3.5789e-05,  7.9632e-06, -1.6119e-05,  1.5333e-05,\n",
            "         -2.9338e-05, -7.9511e-06, -3.1416e-05,  1.0986e-05,  2.8713e-05,\n",
            "         -4.4377e-07,  1.3041e-05,  1.4483e-05, -6.3102e-06,  5.4789e-01,\n",
            "         -8.8214e-06, -3.2064e-05,  1.6506e-05,  1.2032e-06,  4.8441e-06,\n",
            "          2.8318e-05, -2.3336e-06, -1.9066e-05,  1.7482e-05, -1.0567e-07,\n",
            "         -1.5131e-05, -1.4664e-05,  2.5004e-06,  1.9389e-05,  6.7854e-06,\n",
            "         -1.9329e-05,  9.7894e-06,  7.3148e-06, -4.1449e-05,  7.7446e-06,\n",
            "          5.0637e-06, -9.6277e-06, -9.4052e-06, -1.3743e-05, -9.1106e-06,\n",
            "         -2.1957e-05,  3.2320e+00,  1.3505e-05,  1.7544e-05, -6.5031e-07,\n",
            "          7.8460e-01, -7.2083e-06, -3.8714e-06,  1.3515e-05,  5.5230e-06,\n",
            "         -1.2695e-07, -9.1040e-06,  1.0869e+00,  2.4105e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3103], requires_grad=True)\n",
            "l1_reg is: 30.24408721923828\n",
            "total_loss 1.1584776639938354\n",
            "pred: tensor([16.6738, 25.2424, 16.1287,  9.2773, 15.7150,  5.8811, 20.1362, 29.2408,\n",
            "        27.1522, 14.6971, 13.8941,  8.7112, 26.0549, 16.5463, 24.8556, 14.2300,\n",
            "        20.0450,  4.4246, 13.8614, 22.8649, 15.0636,  5.5498,  4.0334,  4.9703,\n",
            "        12.9367,  6.9328, 12.4745, 12.5701,  3.0121, 11.1603, 24.0330, 19.1622,\n",
            "        25.4012, 26.0965, 17.6879, 25.1689, 10.3053, 19.7691, 12.7983, 22.9867,\n",
            "         7.2743, 11.5202, 19.5604, 16.7882, 21.4192, 18.7654, 10.9325, 10.4479,\n",
            "        20.4972, 15.1519, 14.2286, 21.3437,  9.4964,  2.9855,  5.6979,  7.0605,\n",
            "        17.3164,  7.4730, 20.5501, 36.9064, 16.7509, 20.8854, 13.5614,  6.8926,\n",
            "        12.3991, 25.0214, 26.8188,  3.1019, 16.5876, 20.6666, 16.6965,  6.8474,\n",
            "         7.8662, 34.9075, 11.8121,  9.5176,  3.5391, 22.2178, 13.4254,  5.6635,\n",
            "        17.1752, 16.0431,  7.8275,  8.2926, 25.4855, 14.8388, 16.2892,  3.8457,\n",
            "        20.2804, 24.9431,  7.1969, 26.4878, 16.2351, 11.8377, 13.4466, 12.6231,\n",
            "        24.6411, 24.5988,  9.4963,  5.5906, 37.4281, 21.2672,  9.7221, 24.9496,\n",
            "        15.7722, 13.5920, 18.7176, 11.1556, 13.8194, 12.1954, 12.8063, 24.5091,\n",
            "        12.7437, 15.6438,  3.0702, 15.9033, 13.5045, 24.7326, 24.6499, 11.1307,\n",
            "         5.8887, 11.9592,  8.0081, 29.0416, 27.2206, 24.9786,  8.6705, 17.8333,\n",
            "        22.5775, 26.2604, 20.3088, 19.0315, 13.6300, 17.8648, 20.8489,  6.0544,\n",
            "         5.9064, 24.6278, 10.0110,  5.9393, 15.2135, 11.5557, 21.2535, 13.0092,\n",
            "        13.8931, 11.6579,  6.7795,  5.4200, 17.2449,  6.2556, 16.1001, 17.8739,\n",
            "         6.1910, 19.9089,  9.9137, 22.7265, 25.6914,  9.2241, 15.9291, 24.4735,\n",
            "        10.1625,  6.1205, 14.9594, 12.0734,  6.3946, 13.0567, 19.1459, 24.4586,\n",
            "        24.3139,  8.1102, 25.4888,  6.2912, 26.0761, 16.7847, 22.4133, 24.5817,\n",
            "        11.4349, 20.1552, 17.5739, 14.4706, 16.0264, 22.4129, 15.0669, 23.9327,\n",
            "        15.8345, 23.7302,  7.4940, 22.0731, 19.0385,  8.7651, 13.4061, 17.4505,\n",
            "        14.2488, 13.8360, 24.1961, 24.0722, 11.7526, 17.2982, 21.9376, 21.4353,\n",
            "        24.2154, 31.7390, 26.9143, 17.5444, 10.2971, 16.5901, 25.8736, 23.6154,\n",
            "        14.8103,  6.3077, 16.8785,  5.7457, 27.1406,  3.7883, 15.2140, 12.5993,\n",
            "         7.8704, 25.3606,  9.9287, 10.6490, 13.6307, 13.0216, 28.7111, 27.4694,\n",
            "         6.6114,  5.4797, 13.6369, 15.2309, 13.2786, 26.2842, 19.9977, 23.5251,\n",
            "         7.5282, 25.7749, 22.2777, 15.9511,  7.2331, 16.0865, 28.6995, 25.2095,\n",
            "        12.3503, 13.6741,  8.7851, 25.4731, 25.1493, 13.2390, 20.6830, 24.8685,\n",
            "        23.2882,  6.3609, 12.5284, 34.7012,  8.8376,  9.4802,  9.6650,  6.9044,\n",
            "         9.3198, 27.1609, 14.5674,  5.9397, 20.4076, 12.6643,  4.0077,  9.4923,\n",
            "        25.2413, 12.5606,  5.7823, 23.3124, 15.4765, 10.3715],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([16.6770, 26.7589, 15.4295,  9.3464, 17.0628,  5.2206, 20.4198, 30.2853,\n",
            "        26.7766, 13.7928, 14.7092,  8.7217, 25.4253, 16.5146, 24.3132, 18.2203,\n",
            "        21.9697,  4.0833, 15.3333, 21.8750, 15.0651,  5.8424,  4.7581,  5.0395,\n",
            "        13.6745,  6.9672, 12.0725, 12.6252,  2.8180, 10.4885, 24.6835, 20.0117,\n",
            "        25.9815, 27.1211, 17.3118, 25.0422, 11.5385, 20.1652, 12.0752, 23.1035,\n",
            "         7.2547, 10.6852, 21.1322, 16.9422, 23.8535, 19.2647, 11.1391, 11.2250,\n",
            "        19.9225, 16.2852, 13.7884, 20.9893,  9.8060,  2.7056,  5.6577,  6.2320,\n",
            "        18.7081,  7.5698, 21.1748, 36.5372, 16.4475, 20.2926, 13.2610,  6.4554,\n",
            "        12.6134, 25.0174, 27.2233,  2.6932, 16.1458, 20.7442, 16.0947,  7.3673,\n",
            "         7.3034, 38.6700, 11.0535,  8.1115,  3.9971, 20.9747, 12.5295,  4.7445,\n",
            "        18.8468, 17.6301,  7.5893,  9.9713, 24.4345, 15.2567, 16.1458,  3.8390,\n",
            "        19.5975, 25.7552,  7.8195, 26.7613, 15.7567, 12.2077, 13.3486, 12.0579,\n",
            "        22.6075, 24.7865,  8.4282,  6.5000, 37.7397, 20.6155,  9.7509, 25.7512,\n",
            "        16.9941, 13.4633, 18.6037, 11.8561, 11.3954, 12.9823, 12.4763, 25.4924,\n",
            "        14.4013, 14.9846,  2.5369, 15.9392, 13.7224, 25.1262, 25.4691,  9.9165,\n",
            "         5.0197, 14.1373,  7.2917, 25.8247, 27.6106, 24.8711,  8.2796, 16.6666,\n",
            "        23.2997, 28.9574, 23.2825, 20.3797, 14.4196, 19.2308, 21.2103,  4.5049,\n",
            "         5.6991, 24.6041,  9.7813,  5.8333, 14.8496, 12.5000, 20.9808, 13.5870,\n",
            "        13.2633, 13.1338,  7.0304,  6.1056, 17.3858,  6.0484, 16.4330, 18.4037,\n",
            "         5.6806, 18.9740,  9.9495, 22.4451, 27.2440,  8.5938, 16.4813, 24.5022,\n",
            "        10.4907,  5.7276, 15.7708, 12.1100,  6.0086, 12.6688, 19.3560, 24.0307,\n",
            "        22.4143,  9.1036, 24.8955,  6.3859, 25.9151, 16.5230, 23.5116, 24.2957,\n",
            "        12.0504, 20.3543, 16.9475, 13.1081, 16.8272, 25.6530, 16.3534, 23.0245,\n",
            "        15.8023, 23.6816,  6.9575, 21.6878, 19.6543,  8.9197, 13.4434, 15.9091,\n",
            "        17.0000, 14.0352, 24.4258, 25.3447, 12.5390, 18.9223, 21.3269, 22.0167,\n",
            "        24.0313, 32.2881, 27.4474, 18.1217, 10.5772, 17.3651, 28.4593, 23.1402,\n",
            "        11.7443,  5.3610, 17.5676,  5.8908, 26.9940,  3.7572, 13.7785, 12.7037,\n",
            "         8.1662, 25.3007,  9.3623, 10.0148, 14.3080, 11.5326, 29.8732, 27.3353,\n",
            "         7.9439,  5.5369, 14.1204, 14.7196, 13.5258, 26.4274, 20.3744, 24.1562,\n",
            "         6.9034, 27.0956, 20.4707, 15.9245,  5.9859, 18.5327, 29.6456, 25.6022,\n",
            "        12.3727, 13.2218,  9.4678, 25.0113, 25.2681, 13.5415, 20.4702, 25.2241,\n",
            "        23.2866,  6.2031, 12.8613, 36.0309,  8.6533,  9.5819,  9.4792,  7.9193,\n",
            "         9.7285, 26.6905, 14.5407,  5.6315, 19.9266, 13.4758,  3.1969,  8.6788,\n",
            "        25.3483, 11.8880,  5.0875, 24.7181, 16.0401, 10.2122])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.2434e-06, -2.5998e-05,  4.7437e-07,  ...,  1.4021e-05,\n",
            "          1.2461e-05, -3.2036e-05],\n",
            "        [ 5.0991e-05,  5.0810e-06, -2.3784e-05,  ..., -1.6982e-04,\n",
            "         -1.4379e-04,  8.5883e-05],\n",
            "        [-1.6265e-04,  4.1213e-05, -3.0295e-05,  ...,  3.8229e-02,\n",
            "          2.0551e-04, -2.3980e-03],\n",
            "        ...,\n",
            "        [-8.7422e-06, -1.2751e-05,  5.6965e-06,  ..., -8.7613e-06,\n",
            "          1.6403e-05, -2.9676e-07],\n",
            "        [-2.1150e-06,  7.9407e-06, -1.9142e-05,  ..., -1.0954e-05,\n",
            "          2.5110e-05,  2.8644e-05],\n",
            "        [ 4.5111e-05, -2.9177e-05,  7.0149e-06,  ..., -4.0530e-06,\n",
            "          6.4802e-06,  1.1179e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.4093e-06,  4.2472e-01,  3.5986e-02,  2.5438e-06, -4.8436e-06,\n",
            "        -9.6169e-06, -1.6456e-06, -2.2013e-06,  1.5776e+00, -1.0824e-05,\n",
            "         3.2106e-05, -4.0997e-06, -5.4790e-06,  1.7591e-05,  3.8506e-05,\n",
            "        -8.3981e-06,  1.7002e-05,  2.0265e-05,  4.8491e-06, -3.0542e-06,\n",
            "         2.5859e-06,  1.1470e-05,  4.4017e-07, -3.8247e-06,  1.7249e-05,\n",
            "         3.2274e-06, -3.2536e-06,  1.3428e-01,  1.1854e-05,  5.3634e-06,\n",
            "        -1.4720e-05, -1.2220e-05, -4.3914e-06,  2.8678e-01,  1.1512e-05,\n",
            "         5.6131e-06, -3.2594e-06, -1.1030e-05, -6.2596e-06,  1.1991e-05,\n",
            "         2.0822e-05, -8.3472e-06, -3.8645e-06,  3.0342e-06, -3.0259e-06,\n",
            "         5.2983e-06, -1.6404e-05, -1.5020e-05,  1.8896e-05,  1.8919e-04,\n",
            "         1.2518e-05, -5.4353e-06,  5.1325e-06, -5.1654e-06, -5.6921e-06,\n",
            "         6.8107e-06,  5.8513e-04, -9.0194e-06,  1.4175e-05,  2.0608e-05,\n",
            "        -8.7187e-06,  1.4047e-05, -2.0374e-05, -7.9302e-06, -2.2084e-05,\n",
            "        -9.7886e-06,  1.2034e-06,  4.5118e-07,  1.6250e-05,  9.3664e-02,\n",
            "        -2.4184e-06,  1.3267e-05,  2.6777e-05,  7.8085e-06,  1.4184e-06,\n",
            "        -9.2738e-06,  6.2762e-06, -1.6134e-05, -9.8637e-06, -2.8190e-03,\n",
            "        -1.4461e-05,  1.3009e-05, -3.1335e-06,  4.9848e-07,  7.8421e-06,\n",
            "         1.1585e-06, -2.5272e-05, -5.0225e-06,  1.0764e-05,  3.4318e-07,\n",
            "        -9.3756e-07, -1.8194e-05,  2.4442e-05, -1.6529e-06,  1.9303e-05,\n",
            "         5.6388e-06, -1.5307e-07, -8.0168e-06, -3.4674e-06,  1.8001e-05,\n",
            "        -1.4255e-04,  7.9603e-06, -8.6746e-06, -1.6799e-05, -3.4415e-05,\n",
            "        -2.1609e-05, -6.6046e-07, -4.0580e-06, -3.6525e-06,  1.6753e-05,\n",
            "        -5.6037e-06,  3.1673e-05, -1.1254e-05,  5.3506e-06,  8.4350e-06,\n",
            "         1.4731e-05,  4.0932e-06,  1.1612e-05,  1.2863e-05, -1.3634e-05,\n",
            "         1.2605e+00, -7.6993e-06,  8.1952e-06, -1.2163e-05, -1.7036e-05,\n",
            "        -7.2329e-06, -4.6952e-06, -1.7953e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-7.7205e-06, -2.0618e-04, -1.9561e-04,  ..., -1.6242e-05,\n",
            "         -3.8455e-06,  6.3638e-06],\n",
            "        [ 1.4633e-05, -1.6328e-05, -5.8899e-06,  ..., -1.8322e-05,\n",
            "         -2.0845e-05,  1.9368e-05],\n",
            "        [-2.4860e-05, -1.6394e-05,  2.6730e-05,  ...,  1.1619e-05,\n",
            "         -1.6840e-05,  8.1446e-06],\n",
            "        ...,\n",
            "        [ 2.5249e-06, -2.4822e-07,  1.7843e-06,  ...,  9.5795e-08,\n",
            "         -1.7079e-05,  7.4262e-06],\n",
            "        [ 6.8205e-06, -1.2520e-04, -6.5047e-05,  ...,  8.9233e-06,\n",
            "          1.4917e-06, -1.0733e-05],\n",
            "        [ 6.2371e-06, -4.7462e-05, -6.0608e-05,  ...,  8.4269e-06,\n",
            "         -1.2342e-05,  1.9875e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.4246e-02,  9.3363e-06,  9.4021e-06, -1.6151e-05, -1.9527e-05,\n",
            "        -6.1002e-06, -3.0536e-06,  1.3000e-05, -1.4662e-05, -1.2704e-05,\n",
            "         1.2398e-05,  7.7412e-06,  3.6724e-06,  8.0494e-06,  5.0597e-06,\n",
            "        -2.5021e-06,  1.9231e-05,  7.2164e-06, -3.0636e-06,  5.9295e-06,\n",
            "         2.4898e-05,  1.4045e-05, -6.0116e-06,  1.6499e-05,  1.1998e-05,\n",
            "        -5.2038e-06, -1.3109e-05, -1.0030e-05,  1.5142e-05,  1.1135e-06,\n",
            "        -9.9654e-06, -4.3759e-06,  3.6047e-07,  4.4583e-07, -1.9487e-05,\n",
            "        -9.4322e-06, -3.7747e-05, -1.1988e-06,  4.7225e-06,  3.0754e-05,\n",
            "        -1.2460e-05,  1.8246e-05, -9.1734e-06, -6.9987e-06,  9.0038e-06,\n",
            "         1.9849e-06,  2.6986e-06,  2.9881e-06, -1.9469e-05, -1.9507e-05,\n",
            "         2.7197e-07,  1.0831e+00, -9.4231e-07,  1.3225e-05,  9.0523e-06,\n",
            "         8.9093e-02, -1.4390e-06, -1.1811e-05, -7.6443e-06, -2.4390e-05,\n",
            "        -2.3492e-06, -1.9917e-05,  2.5990e-01,  6.3923e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3513e-01, -2.1779e-05, -1.9328e-05,  2.1955e-05, -5.3559e-06,\n",
            "          1.8254e-05,  6.1433e-06,  1.5625e-05, -4.5193e-06,  7.4072e-06,\n",
            "          7.9348e-06,  2.7458e-05,  1.2074e-05, -9.8154e-06, -5.3171e-06,\n",
            "         -6.4564e-06, -7.3841e-06, -2.1005e-05,  1.2986e-05,  2.8036e-05,\n",
            "          7.9499e-06,  2.1721e-05, -5.2539e-06,  1.4295e-06,  5.4779e-01,\n",
            "         -8.8550e-06, -2.3762e-05,  9.1477e-06, -1.4470e-05,  9.9723e-07,\n",
            "          1.9969e-05, -5.3790e-06, -5.3712e-06,  2.7565e-05, -3.7301e-06,\n",
            "         -1.9379e-05, -2.4485e-05,  6.5899e-06, -6.4924e-08,  7.2524e-06,\n",
            "         -5.4265e-06,  9.2184e-06,  5.0462e-06, -4.7239e-05,  1.4746e-06,\n",
            "         -7.8591e-06, -1.0385e-05, -8.8287e-07, -5.0560e-06, -9.8345e-06,\n",
            "         -8.6686e-06,  3.2305e+00, -1.9322e-06,  2.6193e-05,  1.5011e-05,\n",
            "          7.8445e-01, -7.9229e-06,  1.1810e-05,  5.3914e-06, -1.1797e-05,\n",
            "          1.8991e-06, -5.7262e-07,  1.0866e+00,  2.4095e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3098], requires_grad=True)\n",
            "l1_reg is: 30.20537567138672\n",
            "total_loss 1.2467002868652344\n",
            "pred: tensor([12.1596, 21.1566,  9.1687,  8.6899, 17.7341, 27.1626, 17.5696, 16.4895,\n",
            "        21.6369, 12.4740, 10.4423, 19.2326, 28.7162, 21.2238,  9.6265, 13.0207,\n",
            "        11.0839, 11.6423, 18.8734, 20.3629,  9.9643, 16.1459, 13.1759, 23.6550,\n",
            "         3.3568, 23.8796, 34.9885,  9.2608, 10.4855, 23.7601, 18.9758, 25.6345,\n",
            "        13.8285, 13.5982, 25.7895,  6.6879, 24.2520, 14.7156, 23.9764, 26.0886,\n",
            "        11.4479, 34.6394, 11.7258, 12.3021, 18.0506, 16.2073,  5.6152,  9.6505,\n",
            "        21.8840, 20.1132, 13.6435, 15.7058, 12.0617, 22.5226, 26.2468, 10.1731,\n",
            "        24.4850,  4.5647, 20.7675,  8.0334,  9.8980, 32.6423, 15.2822,  9.7207,\n",
            "        10.7850, 14.9326, 12.3890,  9.5224, 23.9232, 21.5884,  4.3297,  6.2166,\n",
            "        25.1788, 10.6989, 11.5397,  8.3370, 34.8818,  2.9257,  4.9000, 20.7446,\n",
            "        12.7842, 12.6772, 31.4026, 15.9601, 33.6153, 10.3039, 26.7293, 10.7347,\n",
            "        20.4683,  9.5326, 12.9179,  5.5293, 17.5934, 14.1855, 11.4912,  9.9055,\n",
            "        19.4659,  3.1390, 20.0342, 11.1912, 22.2644, 10.1228, 25.6049, 22.9090,\n",
            "        33.1566, 23.1025,  2.9102, 11.1758, 13.4288,  8.8482, 12.7370, 17.0416,\n",
            "        19.5231, 24.6446,  5.5505, 32.5022,  9.4050, 15.3809, 23.6742, 14.8803,\n",
            "        16.8115, 12.0291, 13.8561, 25.2091, 14.3356, 22.7735,  7.1740,  5.5743,\n",
            "        11.0856, 35.5879, 18.6034, 15.8877, 20.7849, 25.4030, 12.2775, 34.5413,\n",
            "        20.8489, 23.7459, 19.4769, 22.1692, 18.4124, 13.9547, 10.0676, 15.0575,\n",
            "        25.6029, 20.9345, 13.9625, 12.4102,  6.0941, 23.4631, 15.9449, 14.4038,\n",
            "         6.2162, 10.8358, 19.7508, 10.9957, 15.5294, 20.2981, 18.9304, 23.0733,\n",
            "         4.8794,  2.9599, 25.5277,  9.4490, 16.1819, 12.8620,  8.3661, 18.3443,\n",
            "         4.7103, 20.8097, 19.8256, 17.7163, 12.7803, 14.0851, 33.7032, 21.6325,\n",
            "        24.8955, 21.2777,  9.0135, 15.1134, 21.7895, 26.3012, 10.2825, 10.1602,\n",
            "        19.6112, 24.3567, 13.0501,  3.4702, 14.7190, 21.9971, 31.5951,  3.7481,\n",
            "        26.9671, 21.2393, 10.8688, 18.1726, 11.7323,  9.8339, 10.1191, 19.7030,\n",
            "        10.6266, 14.2379, 19.6037,  6.8521, 10.9743,  8.2556, 26.1380, 24.3633,\n",
            "         4.6387,  9.6156, 26.5746, 16.2543, 19.8950, 10.0518, 16.2999, 13.1057,\n",
            "        32.9396, 27.1690, 10.5998, 18.1358, 21.6571,  8.8352, 24.1677, 10.9537,\n",
            "        24.6299, 18.5855, 22.9469, 21.7073, 24.4098,  7.4591, 24.1863, 19.3887,\n",
            "        21.3245, 22.7582, 13.5961, 24.7560, 12.9410, 13.0499, 18.5229,  4.5923,\n",
            "        12.1971, 13.8330, 11.8231,  5.9413, 16.6116, 21.6813, 24.0609, 12.5670,\n",
            "         3.3807, 16.7028, 11.6347,  5.8120, 24.0777, 11.4039, 30.9354, 25.6966,\n",
            "        13.0245,  8.4436, 17.1109, 12.1881, 22.1103, 28.2138, 11.9655, 14.4076,\n",
            "        22.0031,  9.9874, 21.3794, 31.0212,  7.2436, 13.2030],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([11.5782, 20.8073,  8.6165,  9.1936, 16.3677, 30.2764, 17.7887, 16.1602,\n",
            "        22.8967, 12.9687, 10.5818, 20.2719, 29.8231, 21.5129,  9.1305, 15.8105,\n",
            "        10.6081, 13.4940, 19.3056, 20.1714,  9.1693, 16.8718, 13.0089, 24.1852,\n",
            "         2.9032, 23.5312, 37.0889,  9.6395, 11.7996, 24.4616, 16.7639, 26.1120,\n",
            "        13.6426, 13.5933, 25.5729,  6.0052, 24.4639, 14.1510, 24.2843, 26.2393,\n",
            "        10.7930, 34.2969, 11.8084, 10.0535, 18.0294, 16.7516,  5.6280,  9.3750,\n",
            "        23.0624, 21.4280, 13.8732, 16.1064, 11.9079, 22.7183, 25.0308, 10.7596,\n",
            "        27.2477,  3.2394, 21.3192,  7.9873,  8.1884, 33.9020, 15.4825,  9.6324,\n",
            "        10.4350, 15.1882, 11.8373, 10.3742, 25.8145, 21.2901,  4.1837,  6.3316,\n",
            "        25.7795, 10.5463, 11.2653,  7.7073, 36.1679,  2.6613,  4.9716, 21.7207,\n",
            "        12.8408, 13.9719, 32.4405, 16.4095, 33.0257,  9.5795, 26.3991, 11.9047,\n",
            "        22.1461, 10.4667, 12.3327,  5.7059, 17.1996, 14.5788, 11.0691, 10.2048,\n",
            "        19.0345,  2.7578, 18.4755, 10.9784, 21.6737, 10.5945, 25.3122, 21.3639,\n",
            "        33.9858, 21.8545,  2.5944, 11.1170, 13.3827,  8.5499, 12.3064, 18.3226,\n",
            "        20.0732, 25.2707,  5.7545, 35.8095,  8.9678, 15.8711, 23.9563, 15.0182,\n",
            "        16.9548, 12.2768, 13.8469, 25.9811, 14.6109, 24.1536,  6.6825,  5.2190,\n",
            "        11.5024, 33.8672, 17.6503, 14.4366, 21.8573, 27.0030, 12.0716, 35.6916,\n",
            "        21.1683, 24.2159, 19.0292, 21.5116, 20.2325, 13.9200,  9.1658, 15.8363,\n",
            "        26.6461, 21.7878, 13.9587, 13.1169,  5.8006, 24.9138, 16.0910, 15.1129,\n",
            "         6.6741, 10.8127, 19.7808, 10.2976, 16.8852, 20.1877, 20.4918, 24.4875,\n",
            "         5.2515,  2.4374, 25.9189,  9.2012, 16.2340, 13.3752,  8.7530, 16.1643,\n",
            "         4.7692, 21.1477, 19.9239, 17.7139, 11.9545, 14.3967, 33.4507, 20.8610,\n",
            "        24.8489, 21.5556,  8.3162, 15.3726, 22.3770, 26.8926, 10.8994,  9.5076,\n",
            "        19.5946, 23.6161, 13.4036,  3.3958, 14.5089, 23.3532, 28.3824,  3.4606,\n",
            "        27.0749, 22.9484, 10.4752, 18.7356, 10.9756,  9.4932,  9.5855, 18.9845,\n",
            "         9.9079, 14.8030, 19.2588,  5.9441, 11.1947,  7.4468, 27.1144, 26.8413,\n",
            "         5.4192,  9.3103, 27.2539, 16.2214, 20.4491,  9.4130, 17.2330, 13.5729,\n",
            "        32.7656, 28.4202, 12.3094, 17.1342, 22.1138,  9.4238, 24.4311, 10.9720,\n",
            "        25.6379, 20.6139, 22.6690, 22.3817, 26.2859,  7.4901, 25.6826, 19.3611,\n",
            "        22.8458, 22.6914, 13.2845, 24.6485, 13.1766, 12.5824, 18.3941,  4.9550,\n",
            "        12.2582, 13.9722, 12.0438,  6.5705, 15.6231, 21.4763, 23.2263, 12.4759,\n",
            "         3.4974, 16.0898, 11.0313,  5.7692, 24.0284, 11.3733, 29.8007, 25.5555,\n",
            "        13.3160,  7.0442, 17.6570, 12.3069, 24.7080, 28.4644, 11.6762, 14.6181,\n",
            "        21.5773,  9.4027, 22.1484, 32.6551,  7.5861, 13.1442])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-6.6196e-06, -2.3815e-05, -5.3906e-06,  ...,  1.8137e-05,\n",
            "         -3.2139e-06, -2.1520e-05],\n",
            "        [ 5.5212e-05, -2.0116e-05, -3.1030e-05,  ..., -3.0553e-04,\n",
            "         -3.4624e-04,  1.4212e-04],\n",
            "        [-8.5440e-05,  1.3644e-05, -2.1763e-05,  ...,  3.8202e-02,\n",
            "          2.0143e-04, -1.9754e-03],\n",
            "        ...,\n",
            "        [-1.0038e-05,  2.8158e-06,  1.0154e-06,  ..., -1.6730e-05,\n",
            "          1.1449e-05,  1.2649e-05],\n",
            "        [ 1.8662e-05,  7.7215e-06, -5.4496e-06,  ...,  4.6970e-06,\n",
            "          1.4215e-05,  1.8138e-05],\n",
            "        [ 5.0890e-05, -2.8641e-05,  8.6554e-06,  ..., -2.6151e-06,\n",
            "          1.5190e-05, -1.9646e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-9.0433e-06,  4.2459e-01,  3.6125e-02,  1.0145e-05, -5.3725e-06,\n",
            "         3.0347e-06,  8.9014e-08,  4.7115e-06,  1.5775e+00, -1.9507e-05,\n",
            "         3.1623e-05,  9.5775e-08,  1.7975e-06,  1.2884e-05,  2.2217e-05,\n",
            "         7.2872e-06,  2.7329e-05,  8.2970e-06,  1.3432e-05,  2.3009e-07,\n",
            "         6.6236e-06, -3.1760e-06, -1.0951e-05,  1.1846e-05,  1.0957e-05,\n",
            "        -4.5473e-06, -1.0743e-06,  1.3425e-01, -8.0970e-06,  5.9078e-06,\n",
            "        -9.5329e-06, -5.9209e-06,  1.1845e-05,  2.8660e-01, -4.1537e-06,\n",
            "        -1.1988e-05,  1.9044e-07,  4.6431e-06, -1.0347e-05,  1.4063e-05,\n",
            "         8.8740e-06, -5.8895e-06, -9.1053e-07, -1.5304e-05,  1.0387e-05,\n",
            "        -1.5454e-05, -2.6517e-05, -8.7216e-06,  2.7614e-05,  1.6673e-04,\n",
            "         1.4734e-05, -4.8955e-06,  4.2942e-07,  1.0490e-05, -1.4374e-05,\n",
            "        -4.9184e-06,  6.3023e-04,  8.3515e-07,  1.8571e-05,  1.6100e-05,\n",
            "        -1.6297e-06,  1.6921e-05, -2.9061e-05,  7.7845e-06, -1.1001e-05,\n",
            "         1.1978e-05, -1.1469e-05, -1.1504e-05,  1.4073e-05,  9.3563e-02,\n",
            "         1.0997e-05,  1.0286e-05,  2.5872e-05, -2.1301e-06, -4.6484e-06,\n",
            "        -5.9991e-06, -1.0761e-05, -2.4813e-05, -3.6103e-06, -2.8951e-03,\n",
            "        -1.2018e-05,  1.9094e-05,  7.3678e-06, -7.8567e-06, -7.8568e-06,\n",
            "        -1.7225e-05, -4.0087e-05,  1.5722e-05,  1.0208e-06, -1.8048e-05,\n",
            "        -4.0525e-07, -2.8281e-05,  2.2271e-05,  1.0039e-07,  1.6591e-05,\n",
            "        -3.8632e-06,  1.3348e-05,  6.8819e-06, -4.9259e-07,  4.3270e-06,\n",
            "        -1.6192e-04,  7.4075e-06, -9.9592e-06, -1.0493e-05, -3.4517e-05,\n",
            "        -2.2018e-06,  1.1274e-05, -3.5154e-06,  1.2035e-05,  1.0479e-05,\n",
            "         1.6711e-05,  2.1064e-05,  2.6105e-06,  5.9185e-06,  1.3651e-05,\n",
            "         1.5619e-05, -1.6663e-05,  4.7087e-06,  1.6981e-05,  1.5489e-06,\n",
            "         1.2604e+00,  3.6758e-06, -8.8739e-06,  8.6113e-06, -1.0708e-05,\n",
            "         1.0086e-05,  8.2614e-06, -2.4499e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.4273e-05, -1.7829e-04, -1.6259e-04,  ..., -1.1279e-05,\n",
            "         -6.8921e-06,  2.5589e-06],\n",
            "        [ 1.9404e-05, -2.2488e-05,  1.4873e-05,  ..., -1.2017e-05,\n",
            "         -1.8665e-05,  2.8529e-05],\n",
            "        [-1.2898e-05, -2.2950e-05,  1.5900e-05,  ...,  1.3986e-05,\n",
            "         -1.0995e-05, -7.5292e-06],\n",
            "        ...,\n",
            "        [-8.7837e-06, -3.2319e-06,  5.6902e-06,  ..., -7.8446e-07,\n",
            "         -1.2296e-05,  1.6115e-05],\n",
            "        [ 1.4800e-07, -8.2892e-05, -6.1470e-06,  ...,  9.0829e-06,\n",
            "         -1.4941e-05,  4.5247e-06],\n",
            "        [ 2.1454e-06, -4.2677e-05, -4.2560e-05,  ...,  9.7227e-06,\n",
            "         -1.7928e-05, -9.2404e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.4126e-02, -5.1122e-07,  1.0692e-05, -1.3980e-05, -3.2701e-05,\n",
            "         6.7485e-06, -6.0727e-06,  1.5394e-05, -1.1767e-05, -3.3867e-06,\n",
            "         1.7604e-05,  1.1851e-05,  6.8592e-06,  9.3388e-06,  5.6043e-06,\n",
            "         1.5904e-05,  5.2165e-06, -1.0101e-05, -6.2136e-06,  1.4615e-05,\n",
            "         1.4075e-05,  7.7448e-06, -1.3894e-05, -3.9258e-06,  2.8971e-05,\n",
            "        -7.8440e-07,  1.1228e-06,  1.0018e-05,  5.7978e-08, -1.6556e-05,\n",
            "        -9.4218e-06,  1.2935e-05, -1.5389e-05, -1.0147e-05, -1.3188e-05,\n",
            "        -9.6131e-06, -2.1442e-05,  5.7011e-06,  9.1614e-07,  2.2428e-05,\n",
            "        -4.9368e-07, -1.1905e-06,  7.5422e-06, -8.5628e-06,  9.7134e-06,\n",
            "        -4.9153e-06,  6.3759e-06, -3.8845e-06, -1.7286e-05, -1.4865e-05,\n",
            "        -7.6870e-06,  1.0828e+00,  2.7297e-06,  1.5311e-05,  2.4448e-06,\n",
            "         8.8964e-02, -4.3041e-06, -1.7398e-05, -9.2827e-06, -1.2428e-05,\n",
            "        -6.4556e-06, -2.4257e-06,  2.5976e-01,  4.6933e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3503e-01, -9.8078e-06, -1.3258e-05,  4.4502e-06,  6.8608e-06,\n",
            "          1.2447e-05, -1.1749e-06,  2.2132e-05, -4.8986e-06,  7.8707e-06,\n",
            "         -1.7837e-05,  9.9628e-06,  5.7786e-06,  5.8636e-06, -1.3903e-05,\n",
            "          2.4141e-05,  3.1264e-06, -1.6294e-06,  4.8022e-06,  1.7426e-05,\n",
            "          5.5207e-06,  1.9534e-05, -1.3015e-05, -1.6020e-06,  5.4769e-01,\n",
            "          1.1418e-06, -6.2899e-06, -7.4597e-06, -1.8574e-05, -1.2448e-05,\n",
            "          2.4544e-06,  1.8802e-06,  1.6958e-05,  2.6641e-05,  3.0128e-06,\n",
            "         -1.3202e-05, -2.3324e-05,  2.7016e-07, -7.5738e-06, -2.3213e-06,\n",
            "          1.7086e-05, -1.2955e-06, -6.9822e-06, -4.2450e-05, -1.4143e-05,\n",
            "         -9.4763e-06, -1.0668e-06,  1.6787e-05,  1.2763e-05, -4.8618e-07,\n",
            "          1.3309e-05,  3.2308e+00, -5.8114e-06,  2.3981e-05,  1.9106e-05,\n",
            "          7.8435e-01,  1.4384e-06,  1.5924e-05, -1.1918e-05, -1.7384e-05,\n",
            "         -6.2774e-06,  1.7106e-05,  1.0866e+00,  2.4085e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3097], requires_grad=True)\n",
            "l1_reg is: 30.18828773498535\n",
            "total_loss 1.1148885488510132\n",
            "pred: tensor([25.7160, 33.9090, 19.0979, 24.7275,  4.0987,  8.1788, 15.8627, 21.3643,\n",
            "        17.9873, 16.3730,  2.7033, 22.2148, 22.1139, 21.9739, 16.8012,  6.5888,\n",
            "        13.5324, 14.3931, 12.3262, 10.8153, 18.0369, 23.5994, 14.7514, 22.6624,\n",
            "        16.1399, 12.3105, 13.3595, 14.0945, 25.0781, 25.8638, 18.1985, 10.8321,\n",
            "        11.4734, 34.0927,  4.1663, 21.4012, 14.1858, 17.8527,  9.5074, 24.2418,\n",
            "        11.5314, 24.9174, 20.2650,  2.9489,  5.3131, 29.7178, 12.8769, 26.3357,\n",
            "        23.1361, 14.0551, 21.8724, 17.9293, 23.4372,  7.0718, 14.4003, 19.0627,\n",
            "        23.8812, 12.9668,  5.1842, 24.1860, 16.0714, 22.7227,  6.3060, 22.9330,\n",
            "        18.4352,  6.6488, 16.1740, 26.2929, 24.8745,  9.0019, 19.8756,  4.0466,\n",
            "        13.5334, 16.7423, 10.3097,  6.1720,  7.5422,  9.8645, 23.4610, 18.9460,\n",
            "        22.2400, 24.9210,  9.6642, 25.4982, 19.6338, 24.0537, 24.2046, 24.4249,\n",
            "        15.8860, 28.2957,  6.9390, 14.3880, 23.4077,  8.1131,  9.8882, 20.5096,\n",
            "        30.2713, 15.6253, 10.2980, 14.9954,  8.1256, 16.9398, 26.4248, 21.3598,\n",
            "        12.0533, 24.6078,  2.6937, 25.0188, 24.0182, 17.4844, 27.0010,  8.5502,\n",
            "        20.2629, 10.2530, 31.2519, 21.9855, 33.1656, 10.3746, 12.8378, 25.6669,\n",
            "        12.2243,  8.7528, 24.2477, 26.4043,  8.9860,  9.7341, 21.0248, 18.8083,\n",
            "        13.0460, 23.8160, 24.6899, 26.7010, 17.3848,  8.6809,  5.3217,  8.0864,\n",
            "         9.1533,  7.4238, 19.9797, 12.2430, 16.1834, 10.8029, 27.1543, 10.6920,\n",
            "        24.6985,  6.9888, 23.8720,  5.8060, 27.7178, 22.2823,  2.7781, 24.1403,\n",
            "        28.5876, 13.4963,  6.1708, 25.1947, 22.1725, 24.5024, 16.6920,  8.6377,\n",
            "        12.1781, 21.5685,  9.7517, 17.3494, 10.0779, 19.9581,  9.3810, 18.7173,\n",
            "        27.7903,  5.7809, 25.6569, 24.1950, 24.0357, 12.5737, 13.0945, 17.8747,\n",
            "        23.6762, 16.3665, 22.6545,  7.4523, 16.5237, 19.8533, 21.3409, 23.4934,\n",
            "        16.8267, 10.2304, 12.9985, 20.3881, 25.9424, 14.6725,  5.8499,  6.2264,\n",
            "        20.5541,  9.9070, 23.7465, 14.8318, 19.6980, 10.5633, 26.4789, 25.4239,\n",
            "         5.3061, 18.9180, 17.6371, 24.0637,  5.3783,  9.8574, 18.6053, 27.9397,\n",
            "        25.8266, 21.2263,  2.9300, 19.1415,  2.9457, 12.5730, 26.0719,  7.5299,\n",
            "        13.5670, 27.9218,  6.4119, 24.4699, 15.3211,  6.4848, 23.3602, 10.1247,\n",
            "        15.9175, 13.3477, 12.8112,  8.0955, 12.5527,  7.7183, 11.9850, 15.0461,\n",
            "        17.2377, 17.3907,  5.6379, 34.3582, 16.0259, 23.1685, 12.5501, 23.6794,\n",
            "        21.5402,  8.9105,  2.9546, 13.3907, 21.9708, 27.4780,  9.9789, 14.4343,\n",
            "        10.4628,  2.9747,  9.6280, 14.4534,  9.9323, 29.8394, 19.1171, 27.3529,\n",
            "         7.9763, 15.2654,  8.2139, 25.7304, 10.5389,  6.6900, 29.6691, 11.7236,\n",
            "        26.2257, 16.7434, 11.5851, 20.2784, 20.3500, 26.1501],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([26.6361, 32.6948, 18.5960, 24.6943,  4.4160,  9.1015, 15.9004, 21.8468,\n",
            "        18.2678, 17.0052,  2.3693, 19.1094, 22.1881, 20.8498, 15.7272,  6.9184,\n",
            "        13.5650, 15.1367, 11.6519,  9.6549, 18.7927, 22.9610, 15.4278, 23.0122,\n",
            "        16.7753, 12.4330, 14.7830, 13.8385, 25.0183, 27.1796, 19.5478, 10.5912,\n",
            "        11.8088, 34.7197,  5.9055, 19.6202, 13.5145, 17.5070, 10.0034, 21.7978,\n",
            "         9.8086, 25.8577, 20.7734,  2.7512,  5.8053, 30.0807, 12.9086, 25.8740,\n",
            "        24.5000, 14.9629, 22.8746, 16.7586, 23.2051,  6.8346, 13.9843, 18.5107,\n",
            "        23.2718, 14.9214,  4.7562, 25.6969, 15.7793, 22.9166,  6.8539, 22.6680,\n",
            "        17.4884,  6.5350, 16.1682, 26.0477, 25.6026,  9.0231, 19.0535,  3.3824,\n",
            "        13.3983, 16.1866,  9.7607,  7.5397,  8.2609, 10.0550, 21.3319, 18.6713,\n",
            "        21.9080, 24.7070,  9.3069, 24.4949, 20.1784, 24.4859, 25.8186, 23.7719,\n",
            "        13.8672, 29.0552,  7.2034, 11.6007, 23.4956,  8.0049,  8.9404, 21.0008,\n",
            "        29.0246, 15.0994, 11.3787, 14.7871,  9.0476, 13.7531, 26.3140, 21.5122,\n",
            "        12.1094, 25.7940,  2.5701, 26.0153, 24.2602, 17.6362, 26.6688,  8.2176,\n",
            "        20.1553, 10.4626, 31.0876, 21.5638, 30.6897, 11.8498, 13.3920, 25.8747,\n",
            "        12.6981,  9.8713, 22.2416, 27.2260,  8.8821,  9.8642, 21.1850, 17.5696,\n",
            "        12.2727, 24.7277, 25.2111, 27.7791, 16.3948,  8.8863,  5.1470,  8.1948,\n",
            "         8.7413,  6.8069, 20.3410, 12.1834, 15.6540,  9.8086, 28.0444, 11.2198,\n",
            "        21.9030,  7.7447, 24.1348,  5.8912, 28.6885, 22.5318,  2.9935, 24.0851,\n",
            "        27.7095, 12.7061,  6.7016, 24.6225, 19.8565, 24.7660, 15.2945,  7.3276,\n",
            "        12.8266, 22.0613,  9.7919, 16.3235, 11.1029, 19.0391,  8.7097, 20.0685,\n",
            "        27.2075,  5.0395, 26.2010, 23.6003, 24.4635, 11.8335, 12.4621, 17.2109,\n",
            "        25.3044, 16.6668, 24.4056,  6.7536, 17.6947, 19.5906, 19.6756, 24.3694,\n",
            "        17.6767, 10.2741, 11.8230, 19.6629, 24.5410, 14.5754,  6.5000,  6.3984,\n",
            "        20.2940,  9.2326, 23.7640, 15.0254, 20.6137, 10.3589, 25.9839, 24.9691,\n",
            "         5.3610, 22.1965, 16.9453, 23.4127,  5.3072, 10.1481, 18.6476, 27.1687,\n",
            "        25.2827, 23.3032,  2.8817, 18.9134,  2.6650, 12.4596, 26.6844,  7.2944,\n",
            "        12.3762, 27.5793,  5.7522, 23.7257, 15.7985,  6.0000, 25.1746,  9.2018,\n",
            "        16.4249, 12.3585, 13.5349,  7.0238, 13.2304,  7.5309, 11.8317, 17.0101,\n",
            "        17.3989, 18.8368,  6.2374, 33.9546, 16.6666, 23.9938, 12.1004, 24.4991,\n",
            "        21.2334,  8.3654,  3.0583, 13.0085, 22.0620, 27.4634, 10.5894, 13.9889,\n",
            "        11.4049,  2.9360,  9.7303, 14.0666,  9.3224, 29.6610, 19.5034, 26.3507,\n",
            "         9.1024, 15.1599,  7.3643, 24.6717, 10.0948,  6.8519, 27.3711, 12.0991,\n",
            "        25.0120, 20.1595, 12.6276, 20.0649, 20.5136, 26.7078])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-7.2959e-06, -1.1850e-05, -6.6914e-07,  ...,  1.1840e-05,\n",
            "         -7.3227e-06, -2.0577e-06],\n",
            "        [ 6.0885e-05, -3.8697e-05, -2.9281e-05,  ..., -4.1554e-04,\n",
            "         -5.1393e-04,  2.1928e-04],\n",
            "        [ 9.4715e-06, -2.1168e-05, -4.0833e-06,  ...,  3.8193e-02,\n",
            "          1.7119e-04, -1.4745e-03],\n",
            "        ...,\n",
            "        [-1.2033e-06,  6.8263e-06, -1.3198e-05,  ..., -1.3899e-05,\n",
            "         -3.0088e-06,  1.4299e-05],\n",
            "        [ 2.7362e-05, -2.4758e-06,  1.6873e-05,  ...,  8.7789e-06,\n",
            "         -5.5925e-06, -1.3115e-06],\n",
            "        [ 4.6091e-05, -1.8158e-05,  1.3187e-07,  ...,  8.6802e-06,\n",
            "          1.3029e-05, -2.8334e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.4496e-06,  4.2466e-01,  3.6736e-02,  6.9815e-06,  4.1483e-06,\n",
            "         4.4136e-06, -8.3547e-06,  9.2480e-07,  1.5785e+00, -1.7324e-05,\n",
            "         2.1188e-05, -6.1329e-06, -1.6540e-06, -1.3636e-06, -2.4366e-06,\n",
            "         1.1405e-05,  2.6618e-05, -1.2482e-05,  1.1154e-05, -6.8174e-06,\n",
            "         2.5749e-07, -6.3584e-06, -1.1216e-05,  1.5947e-05, -4.7038e-06,\n",
            "        -1.5438e-06,  1.0888e-05,  1.3442e-01, -1.6053e-05, -3.6058e-06,\n",
            "         5.1366e-06,  9.7392e-06,  1.6464e-05,  2.8689e-01, -8.2545e-06,\n",
            "        -1.7839e-05, -6.7065e-06,  8.7582e-06, -4.0183e-06,  5.9187e-06,\n",
            "        -1.1895e-05,  6.3043e-06,  1.1749e-05, -2.1816e-05,  1.2463e-05,\n",
            "        -2.4106e-05, -2.5619e-05,  6.9479e-06,  2.5464e-05,  1.4212e-04,\n",
            "         6.7289e-06,  5.5921e-06, -1.3807e-05,  1.4567e-05, -1.2195e-05,\n",
            "        -5.4733e-06,  6.2123e-04, -2.9521e-07,  1.2528e-05,  2.0498e-06,\n",
            "         1.4742e-05,  9.5226e-06, -2.6873e-05,  1.1930e-05,  8.9875e-06,\n",
            "         2.1563e-05, -1.2880e-05, -1.2265e-05,  2.1130e-06,  9.3578e-02,\n",
            "         1.3067e-05, -2.3945e-06,  1.5062e-05, -1.0640e-06, -1.1358e-07,\n",
            "         6.9551e-06, -1.6095e-05, -2.2620e-05,  1.2008e-05, -2.5216e-03,\n",
            "         1.9053e-07,  1.4580e-05,  6.8099e-06, -5.3746e-06, -1.1995e-05,\n",
            "        -2.3761e-05, -4.3422e-05,  2.4389e-05, -1.7752e-05, -2.4619e-05,\n",
            "         1.0076e-05, -2.7361e-05,  1.0317e-05, -8.3220e-06,  4.1504e-06,\n",
            "        -2.4140e-06,  1.5492e-05,  1.0291e-05,  1.2186e-05, -1.7966e-05,\n",
            "         6.4625e-05, -3.0838e-06, -1.1125e-06,  5.1689e-06, -2.4607e-05,\n",
            "         2.5266e-05,  1.2004e-05,  6.9830e-06,  1.6155e-05, -5.1667e-06,\n",
            "         2.6788e-05,  1.5026e-06,  5.0725e-06, -3.5658e-06,  8.3396e-06,\n",
            "         6.4182e-06, -2.5333e-05, -1.1499e-05,  1.0694e-05,  5.2194e-06,\n",
            "         1.2611e+00,  3.9193e-06, -1.4236e-05,  1.7307e-05,  4.9941e-06,\n",
            "         1.5674e-05,  9.9479e-06, -2.0390e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.4068e-05, -1.7617e-05,  1.3675e-06,  ...,  3.1864e-06,\n",
            "          3.7050e-07, -1.0867e-05],\n",
            "        [ 1.3698e-05, -1.8034e-05,  2.3557e-05,  ...,  3.6564e-06,\n",
            "         -6.7030e-06,  2.6774e-05],\n",
            "        [ 7.8674e-06, -1.8850e-05, -3.8461e-06,  ...,  6.1166e-06,\n",
            "          4.2664e-06, -1.1636e-05],\n",
            "        ...,\n",
            "        [-8.9615e-06,  4.0828e-06, -7.9433e-07,  ...,  8.4233e-06,\n",
            "          2.0082e-06,  1.3935e-05],\n",
            "        [-1.5854e-05,  2.2019e-04,  3.0919e-04,  ..., -7.7678e-07,\n",
            "         -1.9721e-05,  8.2551e-06],\n",
            "        [-1.1536e-05,  2.7798e-05,  3.9579e-05,  ...,  8.8739e-07,\n",
            "         -1.2954e-05, -9.3459e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.4175e-02,  6.2240e-07,  1.8541e-06, -2.0266e-06, -3.4558e-05,\n",
            "         8.3124e-06,  1.2101e-06,  7.5520e-06,  8.3901e-07,  1.5001e-05,\n",
            "         1.2291e-05,  5.5533e-06, -2.7072e-07,  5.0104e-07, -3.9053e-06,\n",
            "         2.2472e-05, -1.7396e-05, -1.5686e-05,  9.5253e-07,  1.2431e-05,\n",
            "        -5.6635e-06, -7.9249e-06, -1.0992e-05, -1.2309e-05,  3.2317e-05,\n",
            "         1.3193e-05,  3.9314e-06,  1.8058e-05, -2.3524e-05, -2.2459e-05,\n",
            "         1.0675e-06,  1.8515e-05, -1.9564e-05, -9.6818e-06,  2.4813e-06,\n",
            "         2.2426e-07,  3.2227e-06,  1.9111e-06, -1.2512e-05,  4.9344e-06,\n",
            "         2.0276e-05, -8.6831e-06,  1.2584e-05,  3.2843e-08,  3.4750e-07,\n",
            "        -1.1286e-06, -3.1463e-07, -6.9943e-08, -5.3221e-06, -6.8739e-07,\n",
            "        -4.8463e-06,  1.0836e+00, -3.9673e-06,  7.1882e-06, -1.3496e-05,\n",
            "         8.9083e-02,  3.1174e-06, -1.2427e-05, -7.6104e-07,  8.3366e-06,\n",
            "        -1.5347e-07,  2.3317e-05,  2.5997e-01,  9.4530e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3493e-01,  1.0979e-05,  2.2041e-06, -2.1304e-05,  7.8558e-06,\n",
            "         -2.7792e-06,  2.2387e-06,  1.7988e-05,  4.7608e-06, -1.7016e-06,\n",
            "         -3.1032e-05, -1.5766e-05, -9.8699e-06,  9.9983e-06, -1.1630e-05,\n",
            "          4.1679e-05,  2.5928e-06,  2.5809e-05, -1.2554e-05, -2.1218e-06,\n",
            "         -6.6519e-06,  7.5664e-06, -9.9989e-06,  5.6732e-06,  5.4759e-01,\n",
            "          1.8409e-07,  1.9435e-05, -1.2385e-05, -1.2262e-05, -1.4549e-05,\n",
            "         -2.3309e-05, -1.5876e-06,  2.7055e-05,  1.5808e-05, -9.1514e-07,\n",
            "          2.3579e-06, -1.2263e-05, -1.5413e-05, -4.3261e-06, -9.3922e-07,\n",
            "          2.7346e-05, -7.5811e-07, -7.7876e-06, -2.8140e-05, -1.8177e-05,\n",
            "         -9.1713e-07,  1.7318e-05,  2.2690e-05,  1.8799e-05,  1.7928e-05,\n",
            "          2.3092e-05,  3.2334e+00,  7.2192e-07,  1.1990e-05,  1.2796e-05,\n",
            "          7.8432e-01, -1.3638e-07,  9.6262e-06, -1.7477e-05, -1.2413e-05,\n",
            "         -3.6313e-06,  2.3016e-05,  1.0868e+00,  2.4075e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3099], requires_grad=True)\n",
            "l1_reg is: 30.233789443969727\n",
            "total_loss 1.1848143339157104\n",
            "pred: tensor([20.1712, 15.1241, 17.2662, 17.5428, 19.7203, 21.4208, 23.7293,  4.6706,\n",
            "         8.3077,  6.1136,  7.7072,  5.0066, 13.6680, 17.9193,  6.6752,  6.2990,\n",
            "         5.7126,  6.9257,  7.8795, 12.9678, 13.2750, 15.1546, 12.8745, 22.5766,\n",
            "        16.5138, 21.0575, 26.1176,  6.7673,  5.3688,  6.0534,  5.2976,  5.1717,\n",
            "         7.1894,  7.5218,  6.2032,  5.0954,  7.1776,  7.8824,  9.3615, 18.6098,\n",
            "        21.1130,  3.3009,  3.0655,  3.8576,  4.9352,  6.1112,  8.8902, 10.0359,\n",
            "         9.6782,  9.5604,  9.4107, 11.8122, 10.1421, 13.5690, 14.4604, 15.0448,\n",
            "        12.0319, 13.9558, 12.9181, 14.6740, 15.9271, 18.0989, 15.7741, 25.8422,\n",
            "        25.8189, 33.3969, 33.2265,  8.9717,  9.6329, 10.6014, 10.6065, 14.0373,\n",
            "        20.4677, 25.6838,  8.8020,  9.7646, 10.2492, 14.8577, 18.7868, 23.6761,\n",
            "        27.3388, 16.6527, 17.9673, 16.1250, 21.2523, 23.5288, 34.9503, 37.3784,\n",
            "        10.9333, 16.2050, 17.1105, 17.2491, 27.8140, 33.4071,  6.2434,  9.4684,\n",
            "         6.4571, 10.1104,  9.8148, 14.1832, 16.2845, 16.0926, 12.3022, 13.2523,\n",
            "        18.6512, 17.8043, 19.1323, 20.7596,  3.8047,  5.1304,  4.7322,  5.4737,\n",
            "         6.7092,  8.2648,  2.6145,  2.7250,  3.0056,  3.5021,  3.1364,  4.5959,\n",
            "         5.8076,  4.5789,  7.0105,  9.6769,  9.0459, 12.0939, 20.4104, 21.9356,\n",
            "         6.8732,  8.6602, 10.4671, 13.7787, 15.0936, 23.8148, 25.9398, 26.4851,\n",
            "        24.8148, 26.8214, 31.0146, 35.5318, 32.4345, 29.5729, 23.4373, 24.5683,\n",
            "        23.3443, 26.5632, 24.8814, 20.1441, 25.4134, 25.8509, 24.0929, 23.5389,\n",
            "        22.7015, 24.8366, 17.8636, 23.8374, 27.5436, 25.9199, 25.1356, 25.6494,\n",
            "        21.3001, 20.9733, 11.7515, 14.1656, 15.0607, 12.4395, 15.2049, 13.0370,\n",
            "        18.9388, 17.3543, 17.4782, 14.4866, 16.9802, 15.2932, 14.5247,  6.3181,\n",
            "         7.5129,  8.9372, 10.1100, 11.9562, 13.2240, 11.7999, 13.3922, 14.1943,\n",
            "        18.4000, 18.1535, 20.8372, 21.2464, 21.3096, 22.8779, 25.5210, 26.4075,\n",
            "        23.9439, 26.2923, 26.0225, 20.6423, 23.7469, 28.0854, 28.9987, 30.3220,\n",
            "        34.5616, 28.2637,  9.8298, 10.9696, 10.4984, 12.1079, 12.7529, 12.2908,\n",
            "         9.4749, 18.7664, 23.4170, 24.0394, 26.1290, 25.1512, 24.7350, 21.6048,\n",
            "        14.0321, 14.9776, 15.8164, 10.4041, 12.5708,  9.5715,  9.6359, 12.6302,\n",
            "        18.5134, 20.1657, 21.4201, 25.7151, 25.6204, 19.4920, 20.8820, 22.4099,\n",
            "        22.9425, 25.6014, 28.5455, 25.4246, 27.0376, 22.7857, 26.0069, 23.3952,\n",
            "        27.3598, 30.0127, 19.5938, 11.8800, 15.2751, 16.7060, 21.0127, 19.4774,\n",
            "        24.1941, 21.5703,  9.5880, 10.9003, 11.6720, 11.2121, 11.0181, 10.9151,\n",
            "         9.1163, 17.0639, 16.4807, 19.1141, 21.1231, 24.2740, 22.4636, 17.0146,\n",
            "        21.6873, 19.5743, 18.3537, 13.7476, 15.6872, 14.8344])\n",
            "target: tensor([20.7049, 14.7807, 15.6246, 16.3530, 21.1403, 20.8325, 24.9998,  3.5714,\n",
            "         8.6364,  5.7692,  8.6777,  2.8689, 13.1818, 16.1972,  6.8915,  6.3984,\n",
            "         5.9165,  7.7938,  7.7073, 12.3563, 12.7403, 14.3317, 11.1861, 21.9149,\n",
            "        15.7216, 20.2072, 25.5939,  7.4021,  6.4085,  6.0283,  5.9251,  5.5663,\n",
            "         7.7832,  7.3929,  6.8333,  4.4167,  8.1111,  8.1560, 10.5540, 19.6793,\n",
            "        19.3069,  3.7081,  3.7349,  3.5714,  5.3172,  7.1256,  9.6074,  9.9155,\n",
            "         9.7659,  9.7680,  9.4623, 12.0087, 10.4674, 14.1234, 13.6284, 16.2547,\n",
            "        12.1887, 13.4219, 11.4552, 13.7278, 14.9270, 16.9451, 13.5416, 24.6665,\n",
            "        25.5589, 31.2903, 33.9516,  8.7232,  9.4743, 10.4471, 10.4545, 13.6004,\n",
            "        21.5362, 24.7947,  8.0300, 10.0231, 10.1980, 13.5331, 17.4769, 24.8762,\n",
            "        26.2595, 15.9436, 16.9328, 17.6547, 20.6308, 22.7727, 35.3088, 36.3085,\n",
            "         9.6535, 14.2492, 17.8857, 18.5279, 27.2095, 34.6939,  5.5838,  8.7310,\n",
            "         5.3524, 10.9467, 10.6357, 15.4454, 17.5906, 15.9164, 12.1667, 11.6864,\n",
            "        18.8136, 16.1972, 20.7895, 19.6934,  3.4328,  5.3623,  6.6978,  4.7965,\n",
            "         7.0447,  7.5002,  2.7955,  2.6699,  2.9236,  4.3846,  2.8400,  4.2266,\n",
            "         6.3151,  3.5552,  5.7635,  9.5210,  7.8600, 11.7246, 21.8559, 21.3177,\n",
            "         8.4688,  9.5714, 10.6358, 13.0657, 15.2333, 25.8462, 23.3341, 26.2862,\n",
            "        24.1377, 25.5078, 32.0859, 34.6538, 32.1228, 27.8052, 21.7863, 24.6114,\n",
            "        23.7782, 25.3970, 25.9979, 19.5248, 25.9552, 25.1661, 25.5945, 22.8514,\n",
            "        21.9144, 24.1784, 18.4365, 21.6929, 25.4017, 24.9391, 25.2821, 27.2217,\n",
            "        21.4053, 18.9927, 11.9544, 13.8410, 14.0538, 13.6969, 15.8808, 13.5315,\n",
            "        19.8848, 16.4687, 18.2368, 13.7259, 17.7635, 15.5539, 14.0926,  6.9774,\n",
            "         8.3083,  9.6499, 11.0942, 12.5183, 13.5763, 12.8692, 12.9802, 13.9286,\n",
            "        18.6407, 18.1189, 20.1045, 20.9195, 20.7997, 23.7527, 24.5305, 26.1734,\n",
            "        24.5663, 26.8204, 25.4401, 20.5535, 22.1942, 26.6685, 28.8944, 28.5828,\n",
            "        35.6474, 26.9797,  9.8705, 11.2216,  9.6731, 13.3239, 12.5317, 12.5703,\n",
            "         8.2829, 19.1983, 22.5969, 23.5935, 25.9001, 24.6988, 25.2553, 21.3563,\n",
            "        12.1133, 16.9385, 17.0957,  8.9584, 13.6514,  9.6829, 10.1373, 10.3420,\n",
            "        17.6791, 20.2152, 20.7517, 25.9487, 24.4629, 20.1631, 20.3369, 21.6015,\n",
            "        23.2329, 24.6127, 28.6281, 25.0085, 27.3285, 22.5122, 25.8700, 23.2383,\n",
            "        27.3183, 31.4549, 20.4373, 12.4127, 15.8738, 17.5510, 21.0565, 19.5545,\n",
            "        24.4510, 22.1006,  9.8401, 10.0151, 11.3076, 11.8321, 10.3945, 11.5500,\n",
            "         9.4237, 16.0550, 16.3664, 19.7704, 20.4319, 23.6292, 21.6321, 16.5551,\n",
            "        21.9787, 20.1007, 18.6773, 12.9403, 17.1829, 13.6446])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.0979e-06,  8.9188e-06,  1.3581e-05,  ..., -3.8353e-06,\n",
            "         -1.0405e-06,  2.5457e-05],\n",
            "        [ 2.9874e-05, -4.5575e-05, -2.1390e-05,  ..., -2.8666e-04,\n",
            "         -3.4319e-04,  2.8016e-04],\n",
            "        [-4.6177e-06, -6.1137e-05,  2.1828e-05,  ...,  3.8470e-02,\n",
            "          5.9032e-04, -1.0647e-03],\n",
            "        ...,\n",
            "        [ 1.6748e-05,  4.3567e-07, -1.5989e-05,  ..., -1.3467e-06,\n",
            "         -6.0168e-06,  5.7852e-06],\n",
            "        [ 2.5193e-05, -1.6539e-06,  2.6964e-05,  ...,  2.4573e-06,\n",
            "         -1.3412e-05, -8.8156e-06],\n",
            "        [ 3.1771e-05,  1.2760e-06, -1.7540e-05,  ...,  8.8499e-06,\n",
            "          1.0949e-06, -2.6151e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 2.0965e-06,  4.2465e-01,  3.7229e-02, -5.8623e-06,  2.7157e-06,\n",
            "        -4.3367e-06, -5.9501e-06, -1.2494e-05,  1.5790e+00, -5.3654e-06,\n",
            "         1.8054e-06, -1.7364e-06,  5.2358e-06, -4.1907e-06, -1.4627e-05,\n",
            "         5.1112e-06,  1.5978e-05, -2.1172e-05, -8.8388e-07, -3.1620e-06,\n",
            "        -1.5472e-05,  7.7810e-07, -1.4362e-06,  9.6385e-06, -8.8016e-06,\n",
            "         1.1160e-05,  1.1655e-05,  1.3450e-01, -1.3203e-05, -2.1678e-06,\n",
            "         8.3376e-06,  1.3834e-05,  1.0622e-05,  2.8728e-01, -1.9468e-06,\n",
            "        -1.3100e-05, -2.9123e-06,  2.4688e-06,  1.1694e-05, -1.1394e-05,\n",
            "        -2.0575e-05,  7.2725e-06,  1.3147e-05, -1.7684e-05,  4.3268e-06,\n",
            "        -2.1888e-05, -1.4808e-05,  1.1052e-05,  1.3514e-05,  1.1329e-04,\n",
            "        -1.0479e-05,  5.0306e-06, -1.6619e-05,  8.2377e-06, -2.3562e-07,\n",
            "         4.0265e-06,  8.3806e-04,  8.6731e-06, -2.9097e-06, -2.0594e-05,\n",
            "         1.9494e-05, -7.1363e-06, -1.4904e-05,  5.6575e-06,  1.6961e-05,\n",
            "         2.0195e-05, -4.1500e-06, -2.9499e-06, -1.8644e-05,  9.3548e-02,\n",
            "         4.9294e-06, -3.8040e-06, -4.6658e-06,  9.9013e-06,  1.3976e-05,\n",
            "         8.6141e-06, -1.0896e-05, -1.0645e-05,  1.6067e-05, -2.0573e-03,\n",
            "         1.1849e-06,  5.1290e-07, -3.6936e-06,  6.8614e-06, -5.7133e-06,\n",
            "        -1.9644e-05, -3.6423e-05,  2.2185e-05, -2.4646e-05, -2.0495e-05,\n",
            "         9.4928e-06, -1.6547e-05, -1.0443e-05, -5.9063e-06, -1.7041e-05,\n",
            "         8.8831e-06,  7.4217e-06,  3.3603e-06,  1.3605e-05, -2.8026e-05,\n",
            "         2.8124e-04, -2.5256e-06,  1.6861e-05,  9.2766e-06, -5.7076e-06,\n",
            "         3.9981e-05,  2.6728e-06,  6.4122e-06,  9.8627e-06, -9.2390e-06,\n",
            "         2.5862e-05, -2.6106e-05, -2.6930e-06, -2.0988e-06, -6.4358e-06,\n",
            "        -1.1862e-05, -2.3138e-05, -1.6092e-05, -4.9563e-06, -1.4780e-06,\n",
            "         1.2615e+00, -5.8606e-06, -9.0627e-06,  1.5134e-05,  9.1259e-06,\n",
            "         1.0706e-05,  1.4690e-06, -6.6991e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.2875e-05,  1.0044e-04,  1.1752e-04,  ...,  6.2222e-06,\n",
            "         -3.0883e-06, -1.2954e-05],\n",
            "        [-1.4376e-06, -4.0269e-06,  2.1373e-05,  ...,  7.7628e-06,\n",
            "          1.4063e-05,  1.5194e-05],\n",
            "        [ 1.6556e-05, -5.1594e-06, -1.1618e-05,  ..., -1.0966e-05,\n",
            "          8.0013e-06, -5.3314e-06],\n",
            "        ...,\n",
            "        [ 8.7843e-07,  6.6586e-07,  3.3701e-06,  ...,  6.7103e-06,\n",
            "          4.8824e-06,  1.9737e-06],\n",
            "        [-2.0275e-05,  4.0870e-04,  5.3949e-04,  ...,  3.8443e-07,\n",
            "         -1.4013e-05,  1.6031e-06],\n",
            "        [-1.3854e-05,  6.4775e-05,  9.3867e-05,  ..., -1.7057e-05,\n",
            "          1.5250e-06,  5.5713e-07]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.4163e-02, -8.3590e-06, -1.6100e-05,  1.8730e-05, -2.6230e-05,\n",
            "        -2.8026e-07, -2.2353e-06, -9.5056e-06,  2.1836e-06,  2.1550e-05,\n",
            "        -2.4919e-06, -1.0114e-05,  3.3135e-06, -1.7454e-05, -2.4639e-06,\n",
            "         1.8384e-05, -2.7747e-05, -1.0713e-05, -2.5993e-06,  4.6554e-07,\n",
            "        -1.3427e-05, -1.2028e-05,  1.6190e-06, -9.8537e-06,  2.4414e-05,\n",
            "         1.5774e-05, -3.5424e-06,  1.5295e-05, -3.4748e-05, -1.7772e-05,\n",
            "         5.0935e-07,  1.3538e-05, -1.3321e-05,  7.3553e-07,  6.5841e-06,\n",
            "        -9.2209e-07,  1.5422e-05, -1.1497e-05, -1.4597e-05, -2.0810e-05,\n",
            "         2.8968e-05, -5.4265e-06,  7.1223e-06, -2.2287e-06, -1.8079e-05,\n",
            "         1.2280e-05,  3.6661e-06,  1.3363e-05,  1.5446e-05,  2.2071e-05,\n",
            "         7.7124e-06,  1.0841e+00,  5.2824e-09, -1.0123e-05, -1.7846e-05,\n",
            "         8.9112e-02, -2.0326e-07,  2.0466e-06,  1.6910e-05,  1.7025e-05,\n",
            "         1.5519e-05,  3.6484e-05,  2.6005e-01,  1.0656e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3483e-01,  1.9680e-05,  6.1208e-06, -3.4483e-05, -1.2487e-06,\n",
            "         -6.4815e-06, -4.6890e-06,  4.2584e-06,  3.4540e-06, -3.1321e-07,\n",
            "         -3.2908e-05, -2.8920e-05, -1.3954e-05,  3.7095e-06,  4.1501e-07,\n",
            "          4.7464e-05, -7.8970e-06,  4.0503e-05, -1.8173e-05, -9.7150e-06,\n",
            "         -7.6110e-06, -1.3204e-05,  2.7171e-06,  2.2209e-06,  5.4749e-01,\n",
            "         -1.0692e-05,  3.2586e-05, -6.8180e-06,  3.4184e-06, -6.4399e-06,\n",
            "         -3.6496e-05,  5.2809e-06,  2.6142e-05, -3.9477e-06,  5.5520e-06,\n",
            "          6.3615e-06,  7.6902e-06, -1.9534e-05,  8.5946e-06,  1.0305e-05,\n",
            "          2.6580e-05,  9.7256e-06,  1.4804e-06, -5.2663e-06, -1.1812e-05,\n",
            "          1.6782e-05,  2.3865e-05,  1.8003e-05,  1.4232e-05,  2.4483e-05,\n",
            "          2.1897e-05,  3.2351e+00, -3.4019e-06, -8.8018e-06, -2.8913e-06,\n",
            "          7.8425e-01,  8.4514e-06, -6.0424e-06, -1.2487e-05,  2.0616e-06,\n",
            "          8.7420e-06,  1.8338e-05,  1.0869e+00,  2.4065e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3099], requires_grad=True)\n",
            "l1_reg is: 30.266632080078125\n",
            "total_loss 1.1562647819519043\n",
            "pred: tensor([ 7.5051, 22.4814,  9.5784, 14.6386,  8.1570,  9.5985, 10.7497, 13.1413,\n",
            "         8.2873, 13.9845,  5.3629, 24.4088, 10.9619,  9.0672,  4.4409, 34.3755,\n",
            "        20.8975, 25.5364, 22.2792,  9.3814,  9.3761,  3.8691, 18.4168,  5.0029,\n",
            "        27.4310, 28.2061, 10.4578, 19.5304, 13.4915, 16.3050,  8.0817, 16.4520,\n",
            "        21.1370, 35.3591, 12.0608, 13.0865,  6.2976, 10.5006,  7.8739, 19.5691,\n",
            "        15.0791, 16.1008, 16.2071, 22.0151, 14.8607, 19.8683,  6.8701, 11.4848,\n",
            "        24.6818, 11.9038, 38.0913,  2.6053, 20.3196, 14.1052, 21.8116, 23.1640,\n",
            "        28.9541,  5.2563, 35.3214, 18.8974,  9.3550,  4.7489,  8.2381, 24.7386,\n",
            "        13.0282, 22.0643, 11.0274,  9.6474, 20.6469,  9.9774, 33.8840, 19.5397,\n",
            "        25.2099, 24.6282, 26.1606, 16.2924,  9.5624, 19.6417,  9.0424,  9.2572,\n",
            "        13.2937, 18.5765, 16.1934, 27.1191, 15.4985, 28.9955,  2.9371,  3.9321,\n",
            "        16.1789, 23.2916, 24.3001,  8.6449, 13.1289, 10.2100, 21.3385, 17.5646,\n",
            "        17.0934, 18.5255,  5.1126, 19.6182, 15.0051, 26.1081, 19.5578, 11.3491,\n",
            "        13.0550, 12.6839, 21.5093, 25.0222, 31.2416,  7.0499, 16.1530, 24.6203,\n",
            "        25.4486, 29.9998, 21.3206, 17.4362, 25.4534,  6.3597, 25.1296, 15.8660,\n",
            "        22.7867, 13.9340, 20.9055, 26.0804, 14.1273, 20.4583, 14.4561, 27.9497,\n",
            "         6.4180,  5.9825, 18.6853, 21.2755, 12.9651, 12.0238, 14.5905, 38.9807,\n",
            "        21.7075,  4.2933, 23.2652, 25.3619, 22.7630, 36.6431, 21.8487, 12.6398,\n",
            "        23.6331, 16.4101, 12.5865, 19.8654,  9.4830,  4.9941, 19.0984, 12.7924,\n",
            "        23.6892, 17.1656, 27.3292, 26.1440, 18.2640, 14.5748, 23.6767, 14.6309,\n",
            "        21.6353,  9.3931, 29.6793, 27.1565,  3.0582, 13.2768,  2.8846,  9.8115,\n",
            "        23.5761, 12.0995, 23.7403, 10.7167, 16.4327, 26.8085, 20.5179, 28.8369,\n",
            "        20.8543, 11.0949,  4.5989, 11.3546, 13.1540, 10.4378,  6.0692, 19.4601,\n",
            "         7.1189, 14.8852,  5.7686,  7.6738, 24.9317, 15.9246, 11.9183, 13.0253,\n",
            "        21.9026, 24.3152,  6.4445, 20.5237,  2.7032, 13.3678, 17.1587, 13.4444,\n",
            "        18.5767, 23.2205, 10.0645, 11.4874, 16.6417, 13.9709, 15.3045,  2.8211,\n",
            "        27.2148,  2.5341, 33.9384, 14.4878, 18.3935, 10.1851, 16.4800,  2.7332,\n",
            "        19.0443, 14.6686,  8.9238, 36.0193, 12.7280,  6.8839, 21.0019, 13.7927,\n",
            "        13.5396, 12.5032,  6.2371,  5.6274,  9.4315, 22.9494, 10.4624, 20.5784,\n",
            "        26.2374, 14.8226, 16.5908, 19.6247, 21.1848, 14.7828, 10.1236,  9.1934,\n",
            "         2.9134, 16.8966, 29.9716,  5.8354,  9.2448, 32.4731,  9.1994, 15.6548,\n",
            "        22.4172, 11.0348, 15.0005,  7.3611, 21.4160, 25.7402, 15.9478, 19.6572,\n",
            "        27.2886, 18.7879, 10.4462,  7.8152,  8.5559, 11.1319, 15.4295, 24.8919,\n",
            "         9.7838, 11.3811, 13.2210, 16.2445,  9.0166, 14.7451],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([ 5.8988, 20.4129,  9.6324, 15.2496,  7.0442,  9.7826, 11.2198, 13.1460,\n",
            "         8.2176, 13.5445,  5.0824, 21.7978, 10.5994,  8.9678,  4.9716, 33.9858,\n",
            "        21.5983, 25.0734, 22.7714, 10.4667,  9.3069,  4.7401, 19.2308,  5.2190,\n",
            "        28.2166, 27.1171,  9.4370, 18.3327, 13.6148, 15.6076,  7.1429, 16.9725,\n",
            "        22.2998, 36.0361, 13.0854, 12.4621,  6.5350,  8.8495,  8.0049, 21.1322,\n",
            "        15.7130, 17.8601, 16.1064, 22.2379, 17.0000, 19.8440,  7.4371, 11.6902,\n",
            "        25.3447, 10.9914, 37.4974,  2.9887, 20.9200, 13.6535, 22.0113, 22.4381,\n",
            "        30.1929,  5.9271, 33.8413, 17.1642,  9.8060,  4.6269,  8.6037, 25.2018,\n",
            "        12.8185, 24.7259, 11.0535,  9.4634, 21.2043, 11.6492, 35.0221, 20.1784,\n",
            "        24.8246, 25.4667, 28.1735, 16.6668,  9.8075, 19.4706,  8.1231,  8.8915,\n",
            "        15.8105, 18.7693, 17.0498, 27.4474, 15.3285, 27.7095,  3.0583,  4.1866,\n",
            "        15.5514, 23.6343, 23.2866,  9.4538, 13.7270,  9.5306, 20.4702, 19.4611,\n",
            "        18.3335, 17.4884,  5.3610, 21.2180, 15.0697, 26.1120, 20.2343, 10.3828,\n",
            "        14.9214, 11.9607, 21.8468, 22.7811, 31.1689,  7.4115, 16.0714, 22.8793,\n",
            "        23.7057, 29.8732, 20.5418, 17.0326, 24.3132,  5.6806, 24.4097, 19.1049,\n",
            "        22.7201, 15.4348, 21.9214, 25.2843, 14.5794, 21.2700, 14.1756, 26.9206,\n",
            "         7.4638,  5.7616, 17.9615, 22.9497, 13.1744, 13.3165, 13.6777, 37.7397,\n",
            "        21.8105,  4.3382, 21.8526, 25.6022, 22.8728, 34.3018, 21.2779, 12.7419,\n",
            "        23.9096, 16.1458, 13.9719, 20.1903, 10.2668,  3.6290, 19.5034, 12.1732,\n",
            "        23.4956, 16.4352, 25.7110, 25.0422, 17.5070, 13.7915, 22.4624, 13.8726,\n",
            "        20.8073,  9.2548, 30.0542, 23.5499,  3.4974, 14.1956,  2.9711, 10.3292,\n",
            "        23.1277, 11.9545, 22.9610, 10.6060, 16.8874, 25.0821, 20.5136, 30.3723,\n",
            "        18.9176, 10.9720,  5.2515, 11.0313, 12.3585,  9.3152,  5.6991, 17.0130,\n",
            "         6.8069, 15.6198,  5.7299,  7.0025, 25.1262, 15.3233, 11.5782, 13.1111,\n",
            "        21.4763, 24.6835,  7.4901, 21.3942,  2.3849, 14.7017, 16.9548, 14.1245,\n",
            "        18.6476, 22.4311, 11.5772, 11.8714, 14.5425, 13.5145, 15.8325,  2.9914,\n",
            "        29.0540,  2.6613, 30.7192, 13.9320, 19.8397, 11.1947, 15.7240,  2.4920,\n",
            "        17.6503, 15.7058,  8.9643, 35.9269, 12.8029,  7.3201, 17.7417, 13.7023,\n",
            "        13.5397, 12.6149,  6.5385,  6.1747,  8.1884, 21.8196, 10.4564, 19.9495,\n",
            "        25.5555, 14.8318, 17.1398, 19.1687, 20.2926, 14.6563, 10.5222,  8.7097,\n",
            "         2.8817, 18.0235, 32.5764,  5.9091,  8.7501, 32.9856, 10.3216, 15.9616,\n",
            "        21.9577, 11.6278, 15.6772,  8.2031, 21.2103, 25.2963, 15.6540, 19.4343,\n",
            "        25.2176, 18.5914, 10.4291,  8.9939,  8.9693, 10.0902, 11.7443, 22.9460,\n",
            "         9.1658, 11.8088, 13.9200, 13.0685,  8.6533, 14.7849])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.0979e-06,  8.9188e-06,  1.3581e-05,  ..., -3.8353e-06,\n",
            "         -1.0405e-06,  2.5457e-05],\n",
            "        [ 2.9874e-05, -4.5575e-05, -2.1390e-05,  ..., -2.8666e-04,\n",
            "         -3.4319e-04,  2.8016e-04],\n",
            "        [-4.6177e-06, -6.1137e-05,  2.1828e-05,  ...,  3.8470e-02,\n",
            "          5.9032e-04, -1.0647e-03],\n",
            "        ...,\n",
            "        [ 1.6748e-05,  4.3567e-07, -1.5989e-05,  ..., -1.3467e-06,\n",
            "         -6.0168e-06,  5.7852e-06],\n",
            "        [ 2.5193e-05, -1.6539e-06,  2.6964e-05,  ...,  2.4573e-06,\n",
            "         -1.3412e-05, -8.8156e-06],\n",
            "        [ 3.1771e-05,  1.2760e-06, -1.7540e-05,  ...,  8.8499e-06,\n",
            "          1.0949e-06, -2.6151e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 2.0965e-06,  4.2465e-01,  3.7229e-02, -5.8623e-06,  2.7157e-06,\n",
            "        -4.3367e-06, -5.9501e-06, -1.2494e-05,  1.5790e+00, -5.3654e-06,\n",
            "         1.8054e-06, -1.7364e-06,  5.2358e-06, -4.1907e-06, -1.4627e-05,\n",
            "         5.1112e-06,  1.5978e-05, -2.1172e-05, -8.8388e-07, -3.1620e-06,\n",
            "        -1.5472e-05,  7.7810e-07, -1.4362e-06,  9.6385e-06, -8.8016e-06,\n",
            "         1.1160e-05,  1.1655e-05,  1.3450e-01, -1.3203e-05, -2.1678e-06,\n",
            "         8.3376e-06,  1.3834e-05,  1.0622e-05,  2.8728e-01, -1.9468e-06,\n",
            "        -1.3100e-05, -2.9123e-06,  2.4688e-06,  1.1694e-05, -1.1394e-05,\n",
            "        -2.0575e-05,  7.2725e-06,  1.3147e-05, -1.7684e-05,  4.3268e-06,\n",
            "        -2.1888e-05, -1.4808e-05,  1.1052e-05,  1.3514e-05,  1.1329e-04,\n",
            "        -1.0479e-05,  5.0306e-06, -1.6619e-05,  8.2377e-06, -2.3562e-07,\n",
            "         4.0265e-06,  8.3806e-04,  8.6731e-06, -2.9097e-06, -2.0594e-05,\n",
            "         1.9494e-05, -7.1363e-06, -1.4904e-05,  5.6575e-06,  1.6961e-05,\n",
            "         2.0195e-05, -4.1500e-06, -2.9499e-06, -1.8644e-05,  9.3548e-02,\n",
            "         4.9294e-06, -3.8040e-06, -4.6658e-06,  9.9013e-06,  1.3976e-05,\n",
            "         8.6141e-06, -1.0896e-05, -1.0645e-05,  1.6067e-05, -2.0573e-03,\n",
            "         1.1849e-06,  5.1290e-07, -3.6936e-06,  6.8614e-06, -5.7133e-06,\n",
            "        -1.9644e-05, -3.6423e-05,  2.2185e-05, -2.4646e-05, -2.0495e-05,\n",
            "         9.4928e-06, -1.6547e-05, -1.0443e-05, -5.9063e-06, -1.7041e-05,\n",
            "         8.8831e-06,  7.4217e-06,  3.3603e-06,  1.3605e-05, -2.8026e-05,\n",
            "         2.8124e-04, -2.5256e-06,  1.6861e-05,  9.2766e-06, -5.7076e-06,\n",
            "         3.9981e-05,  2.6728e-06,  6.4122e-06,  9.8627e-06, -9.2390e-06,\n",
            "         2.5862e-05, -2.6106e-05, -2.6930e-06, -2.0988e-06, -6.4358e-06,\n",
            "        -1.1862e-05, -2.3138e-05, -1.6092e-05, -4.9563e-06, -1.4780e-06,\n",
            "         1.2615e+00, -5.8606e-06, -9.0627e-06,  1.5134e-05,  9.1259e-06,\n",
            "         1.0706e-05,  1.4690e-06, -6.6991e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.2875e-05,  1.0044e-04,  1.1752e-04,  ...,  6.2222e-06,\n",
            "         -3.0883e-06, -1.2954e-05],\n",
            "        [-1.4376e-06, -4.0269e-06,  2.1373e-05,  ...,  7.7628e-06,\n",
            "          1.4063e-05,  1.5194e-05],\n",
            "        [ 1.6556e-05, -5.1594e-06, -1.1618e-05,  ..., -1.0966e-05,\n",
            "          8.0013e-06, -5.3314e-06],\n",
            "        ...,\n",
            "        [ 8.7843e-07,  6.6586e-07,  3.3701e-06,  ...,  6.7103e-06,\n",
            "          4.8824e-06,  1.9737e-06],\n",
            "        [-2.0275e-05,  4.0870e-04,  5.3949e-04,  ...,  3.8443e-07,\n",
            "         -1.4013e-05,  1.6031e-06],\n",
            "        [-1.3854e-05,  6.4775e-05,  9.3867e-05,  ..., -1.7057e-05,\n",
            "          1.5250e-06,  5.5713e-07]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.4163e-02, -8.3590e-06, -1.6100e-05,  1.8730e-05, -2.6230e-05,\n",
            "        -2.8026e-07, -2.2353e-06, -9.5056e-06,  2.1836e-06,  2.1550e-05,\n",
            "        -2.4919e-06, -1.0114e-05,  3.3135e-06, -1.7454e-05, -2.4639e-06,\n",
            "         1.8384e-05, -2.7747e-05, -1.0713e-05, -2.5993e-06,  4.6554e-07,\n",
            "        -1.3427e-05, -1.2028e-05,  1.6190e-06, -9.8537e-06,  2.4414e-05,\n",
            "         1.5774e-05, -3.5424e-06,  1.5295e-05, -3.4748e-05, -1.7772e-05,\n",
            "         5.0935e-07,  1.3538e-05, -1.3321e-05,  7.3553e-07,  6.5841e-06,\n",
            "        -9.2209e-07,  1.5422e-05, -1.1497e-05, -1.4597e-05, -2.0810e-05,\n",
            "         2.8968e-05, -5.4265e-06,  7.1223e-06, -2.2287e-06, -1.8079e-05,\n",
            "         1.2280e-05,  3.6661e-06,  1.3363e-05,  1.5446e-05,  2.2071e-05,\n",
            "         7.7124e-06,  1.0841e+00,  5.2824e-09, -1.0123e-05, -1.7846e-05,\n",
            "         8.9112e-02, -2.0326e-07,  2.0466e-06,  1.6910e-05,  1.7025e-05,\n",
            "         1.5519e-05,  3.6484e-05,  2.6005e-01,  1.0656e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3483e-01,  1.9680e-05,  6.1208e-06, -3.4483e-05, -1.2487e-06,\n",
            "         -6.4815e-06, -4.6890e-06,  4.2584e-06,  3.4540e-06, -3.1321e-07,\n",
            "         -3.2908e-05, -2.8920e-05, -1.3954e-05,  3.7095e-06,  4.1501e-07,\n",
            "          4.7464e-05, -7.8970e-06,  4.0503e-05, -1.8173e-05, -9.7150e-06,\n",
            "         -7.6110e-06, -1.3204e-05,  2.7171e-06,  2.2209e-06,  5.4749e-01,\n",
            "         -1.0692e-05,  3.2586e-05, -6.8180e-06,  3.4184e-06, -6.4399e-06,\n",
            "         -3.6496e-05,  5.2809e-06,  2.6142e-05, -3.9477e-06,  5.5520e-06,\n",
            "          6.3615e-06,  7.6902e-06, -1.9534e-05,  8.5946e-06,  1.0305e-05,\n",
            "          2.6580e-05,  9.7256e-06,  1.4804e-06, -5.2663e-06, -1.1812e-05,\n",
            "          1.6782e-05,  2.3865e-05,  1.8003e-05,  1.4232e-05,  2.4483e-05,\n",
            "          2.1897e-05,  3.2351e+00, -3.4019e-06, -8.8018e-06, -2.8913e-06,\n",
            "          7.8425e-01,  8.4514e-06, -6.0424e-06, -1.2487e-05,  2.0616e-06,\n",
            "          8.7420e-06,  1.8338e-05,  1.0869e+00,  2.4065e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3099], requires_grad=True)\n",
            "l1_reg is: 30.266632080078125\n",
            "total_loss 1.38367760181427\n",
            "pred: tensor([ 9.6221, 23.1155, 24.4259, 19.7884, 23.7012,  6.5306, 30.7920,  8.9274,\n",
            "        13.0241,  9.4641, 13.9539, 24.1574, 10.6035, 22.0280, 10.7917, 17.1010,\n",
            "         6.2980, 13.9644, 22.0779, 29.4490, 24.8619, 32.9244, 16.6783, 16.0207,\n",
            "         6.3039, 10.0881, 24.7070, 15.1580,  7.4802, 22.6451, 13.9541,  8.2016,\n",
            "         9.9491,  8.0148, 26.9839, 10.6507, 13.1339, 20.4134,  6.4510,  8.8728,\n",
            "         2.6244,  4.4332,  7.5561, 20.6455, 22.1892, 26.6852,  3.7670,  5.0013,\n",
            "         6.0539, 28.0220,  8.2457, 24.6600, 32.5886,  5.8742, 18.0455, 11.5085,\n",
            "        26.0555, 15.0154, 14.7972,  8.9687, 20.0251, 10.1461, 23.1515, 10.5945,\n",
            "        24.9680, 13.7480, 13.9627,  8.4962, 12.0616,  2.6571, 12.7414, 13.4557,\n",
            "        14.9960, 21.5367, 25.9516, 24.9472,  4.6074,  4.6390,  3.6699,  5.2609,\n",
            "        27.9715, 19.4005, 16.3941, 26.3588, 11.4670, 20.1899, 14.3338, 24.8369,\n",
            "        17.1823, 15.2781, 25.9241, 16.7146,  7.6563,  5.3941, 11.7722, 28.1835,\n",
            "        24.9596, 20.0498,  9.9797, 13.2296,  7.0361, 19.3597, 26.7680, 12.3679,\n",
            "        13.8935, 15.2851,  4.7749,  7.3831,  7.1409, 27.4890, 23.9292,  8.1941,\n",
            "        16.8282, 24.3180, 12.5604, 13.1875, 16.7008, 22.0251, 24.2737,  5.9489,\n",
            "        17.8746, 11.5139,  5.9794, 12.6312, 25.5140, 26.7182,  7.5319, 21.4621,\n",
            "        25.8403,  5.9950, 13.7486, 25.3248, 19.7076,  3.8541, 13.7561, 12.0504,\n",
            "        25.1598, 35.8252, 37.3260,  5.0822, 19.0120,  5.4280, 21.1543, 22.2069,\n",
            "         6.6962, 10.2528, 29.7484,  2.6534, 10.5180, 26.8617, 12.6384,  3.5996,\n",
            "        22.5403, 25.3418, 15.2570,  2.5654, 21.6243,  5.1831, 11.8239, 13.4570,\n",
            "        24.6975, 24.6325, 19.3198, 14.3922, 21.8137, 17.2706, 16.9495,  6.4657,\n",
            "        12.8213, 19.3738, 20.0299,  6.3273, 23.4567,  9.4531,  6.6199,  3.4097,\n",
            "        11.3912, 24.2273,  7.4479, 20.2693, 13.6446, 12.7634, 22.6277, 14.9123,\n",
            "         9.1603, 11.5046, 18.9684, 18.9739,  4.5206, 22.8501, 36.0595, 17.6417,\n",
            "         6.7534,  6.6202, 21.2560, 11.9846, 12.7684, 23.8946, 15.1946, 17.5906,\n",
            "         7.6518, 26.3122,  7.6547, 26.2504,  9.3165, 17.7237, 23.4538, 10.9225,\n",
            "         5.5564, 17.8871,  5.1432, 14.4303, 25.8310, 14.7108,  5.9709, 21.4588,\n",
            "        21.8061, 20.1561, 11.3142, 19.0989, 25.6575, 10.8365, 24.1329,  9.6853,\n",
            "        24.0297, 16.2132, 36.4777, 38.3494,  7.0778,  8.9898, 14.4385, 16.8920,\n",
            "         6.0979, 25.6577, 15.9298, 18.2593, 12.6179, 27.8223, 37.8033,  3.8226,\n",
            "         3.7387,  5.6447, 27.1561, 16.3166, 26.6916, 12.5978, 25.7605, 10.3575,\n",
            "        23.0472, 22.1132, 25.5097, 23.7049,  3.3220, 10.4298,  4.7801,  8.0849,\n",
            "        27.0205,  8.9709, 15.2944,  7.3705, 28.0397, 26.7071, 24.5615, 11.7311,\n",
            "        12.8980, 21.3105, 10.1960, 23.1420, 12.8496, 16.6348],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([ 9.9495, 24.1536, 23.5312, 16.7639, 25.1746,  7.7447, 30.6270,  9.7051,\n",
            "        13.2845,  9.5819, 13.7884, 22.9409, 10.8127, 23.0624, 11.5276, 16.1702,\n",
            "         7.0349, 14.3967, 22.1138, 30.1335, 23.2263, 32.3296, 16.7238, 16.8272,\n",
            "         6.8095, 10.5772, 23.9864, 15.4825,  8.1662, 22.5572, 14.4771,  8.3830,\n",
            "        10.4391,  8.1897, 25.4253,  9.9079, 13.0290, 19.7124,  6.0000,  8.6165,\n",
            "         2.6395,  4.6756,  9.1024, 19.8966, 22.2477, 25.9151,  5.9055,  5.6825,\n",
            "         6.3057, 26.6424,  9.3497, 24.1602, 28.3824,  6.3095, 17.4771, 11.2903,\n",
            "        25.2012, 15.1577, 13.4191,  9.4262, 20.4491, 10.0462, 21.9823,  9.7441,\n",
            "        24.2194, 12.3762, 13.9567,  8.5499, 11.0619,  2.5701, 12.0752, 13.8693,\n",
            "        15.0182, 21.8640, 24.8955, 24.3183,  5.0395,  4.5714,  3.0594,  5.6398,\n",
            "        26.8546, 18.5960, 16.6193, 27.1796, 11.3362, 20.8130, 15.0563, 23.6003,\n",
            "        16.6667, 14.7273, 25.8136, 15.4793, 12.4000,  5.7692, 12.2582, 29.3879,\n",
            "        26.8413, 19.9705, 10.5208, 12.6357,  8.0952, 19.3151, 26.0477, 12.3903,\n",
            "        13.8469, 15.8363,  4.9911,  7.3034,  7.7035, 26.6688, 24.7181,  7.3276,\n",
            "        16.9422, 24.4616, 13.3752, 13.5947, 15.7061, 20.0288, 24.2159,  6.4014,\n",
            "        16.3677, 11.9273,  4.7111, 14.3835, 24.4875, 26.2982,  8.9623, 23.2825,\n",
            "        25.0908,  7.9439, 13.4694, 24.6654, 17.9237,  4.4160, 13.4919, 12.0289,\n",
            "        25.2887, 35.6916, 36.4983,  4.2355, 20.1040,  5.4622, 19.9523, 22.7836,\n",
            "         6.9476, 11.2188, 25.8247,  2.6650, 11.0390, 26.4727, 13.2069,  3.0017,\n",
            "        23.3834, 24.6307, 16.2852,  2.8180, 21.8320,  5.8908, 12.6276, 12.8218,\n",
            "        25.8066, 26.3594, 18.4841, 14.7628, 22.0613, 18.0973, 16.1458,  7.2034,\n",
            "        13.2610, 19.3560, 19.0535,  7.9193, 21.8750, 10.7772,  7.2547,  3.7662,\n",
            "        10.5933, 24.7600,  8.4529, 19.5238, 15.3333, 12.4763, 21.6111, 15.3904,\n",
            "         9.3521, 11.8561, 20.4918, 16.2835,  4.8484, 21.6737, 38.6700, 16.9453,\n",
            "         7.3673,  6.5972, 20.2236, 12.8784, 13.0535, 22.5008, 15.1563, 18.9223,\n",
            "         7.0238, 27.2440,  7.5893, 26.6540,  9.4130, 18.5855, 23.1035, 11.4049,\n",
            "         5.6474, 16.3235,  6.1551, 14.7177, 25.0153, 14.5407,  5.3161, 21.7208,\n",
            "        21.5427, 18.9740, 11.1170, 19.9216, 25.6291, 10.6641, 21.9933, 10.4626,\n",
            "        24.4991, 15.2945, 34.8983, 36.5372,  6.7507,  9.9478, 14.9629, 19.9029,\n",
            "         6.6176, 25.2681, 14.9846, 17.6362, 13.5357, 26.8387, 38.0346,  3.7834,\n",
            "         3.8386,  6.1958, 27.1211, 16.1858, 26.4615, 13.0735, 25.3500, 12.3094,\n",
            "        23.2249, 22.2449, 25.2803, 23.1913,  3.7572, 11.1029,  5.1852,  8.1349,\n",
            "        26.7285,  7.6077, 15.9248,  6.3798, 27.6650, 26.7993, 22.2843, 12.0509,\n",
            "        11.9910, 21.8573,  9.8001, 22.4451, 12.4214, 17.6301])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.5166e-07,  1.7612e-05,  1.6405e-05,  ..., -7.9464e-06,\n",
            "          1.4616e-05,  4.0221e-05],\n",
            "        [-7.8555e-06, -5.4135e-05, -2.2479e-06,  ..., -2.3390e-05,\n",
            "         -1.2693e-04,  3.0158e-04],\n",
            "        [-7.2979e-06, -1.0978e-04,  3.5148e-05,  ...,  3.8947e-02,\n",
            "          8.2761e-04, -9.2624e-04],\n",
            "        ...,\n",
            "        [ 2.2903e-05, -1.5316e-05, -8.5019e-06,  ...,  1.9949e-05,\n",
            "          1.2755e-06, -1.1877e-05],\n",
            "        [ 1.3240e-05,  9.0867e-06,  2.6045e-05,  ..., -1.3238e-05,\n",
            "         -1.0450e-05, -5.5664e-06],\n",
            "        [ 8.8826e-06,  8.7672e-06, -2.3444e-05,  ..., -9.9833e-07,\n",
            "         -1.9647e-05, -1.4188e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.6045e-06,  4.2456e-01,  3.7334e-02, -7.4277e-06, -8.5747e-06,\n",
            "        -2.2110e-06,  6.2126e-06, -1.4567e-05,  1.5790e+00,  1.5396e-05,\n",
            "        -2.5630e-05,  1.2217e-05,  1.4348e-06,  3.2657e-06, -1.5597e-05,\n",
            "        -1.0553e-05, -3.6008e-06, -1.8994e-05, -1.7164e-06,  1.0125e-05,\n",
            "        -1.9627e-05, -2.7942e-06,  1.7379e-05, -6.0402e-06, -2.4948e-06,\n",
            "         1.2594e-05,  2.3409e-06,  1.3446e-01, -6.3503e-07,  9.1262e-06,\n",
            "         1.2191e-06,  7.5081e-06, -4.6201e-06,  2.8737e-01,  1.3729e-05,\n",
            "         1.1633e-06,  1.0500e-05, -1.3172e-05,  1.5854e-05, -1.6969e-05,\n",
            "        -1.8377e-05, -1.8631e-06,  4.4054e-06, -3.9660e-06, -1.2994e-05,\n",
            "        -9.8964e-06,  4.9190e-06,  4.7473e-06, -7.2398e-06,  4.6990e-05,\n",
            "        -1.5966e-05, -5.4768e-06, -9.1464e-06, -7.4584e-06,  2.0527e-05,\n",
            "         2.5742e-06,  9.0826e-04,  6.7356e-06, -6.8134e-06, -3.0964e-05,\n",
            "         1.3782e-05, -1.2134e-05,  5.8791e-06, -1.0009e-05,  1.4129e-05,\n",
            "         8.9585e-06,  1.3712e-05,  1.5434e-05, -2.7324e-05,  9.3446e-02,\n",
            "        -1.2401e-05,  4.9276e-06, -1.2418e-05,  9.7714e-06,  1.6655e-05,\n",
            "         1.0425e-07,  3.7838e-06,  1.0126e-05,  9.7211e-06, -1.8506e-03,\n",
            "        -7.9345e-06, -2.2146e-05, -3.1540e-06,  7.8700e-06,  9.9456e-06,\n",
            "        -5.9411e-06, -2.0125e-05,  1.0196e-05, -2.0851e-05, -6.7720e-06,\n",
            "        -1.0341e-06,  3.1823e-06, -1.9125e-05,  6.2682e-06, -2.6117e-05,\n",
            "         9.0457e-06, -9.8412e-06, -1.2877e-05,  4.8783e-06, -2.7079e-05,\n",
            "         3.5419e-04,  7.9750e-06,  2.3031e-05,  2.9717e-06,  2.1289e-05,\n",
            "         4.3184e-05, -1.5725e-05, -4.1149e-06, -5.7984e-06, -2.8999e-06,\n",
            "         1.5028e-05, -4.0957e-05,  3.2210e-07,  9.2226e-06, -9.7330e-06,\n",
            "        -1.8319e-05, -1.1155e-05, -1.0222e-05, -9.0466e-06,  2.5087e-06,\n",
            "         1.2615e+00, -4.6561e-06,  5.5974e-06,  3.1781e-06,  2.8482e-06,\n",
            "        -3.7659e-06, -1.6160e-05,  1.5622e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.1798e-05,  1.1392e-04,  1.0782e-04,  ..., -1.0329e-06,\n",
            "          3.8014e-06, -4.8369e-06],\n",
            "        [-5.0595e-06,  1.8580e-05,  9.4069e-06,  ...,  1.4586e-06,\n",
            "          2.2752e-05, -5.2274e-06],\n",
            "        [ 1.4377e-05,  1.7162e-05, -8.6128e-06,  ..., -1.6340e-05,\n",
            "          1.3628e-06,  1.0342e-05],\n",
            "        ...,\n",
            "        [-2.6559e-07, -1.2412e-05, -2.8856e-06,  ..., -4.8314e-06,\n",
            "         -2.5308e-06, -1.8792e-05],\n",
            "        [-1.4260e-05,  4.0017e-04,  5.2492e-04,  ..., -8.5447e-06,\n",
            "          1.1296e-06, -1.4392e-05],\n",
            "        [-5.9417e-06,  5.0815e-05,  8.5823e-05,  ..., -2.3201e-05,\n",
            "          4.5573e-06, -5.3209e-07]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.4067e-02, -6.4423e-06, -2.2259e-05,  2.7417e-05, -8.7338e-06,\n",
            "         1.9855e-06,  4.6637e-06, -1.4858e-05, -6.6063e-06,  1.7444e-05,\n",
            "        -5.7966e-06, -1.4210e-05, -3.4608e-06, -2.3614e-05,  8.8333e-06,\n",
            "         4.7094e-06, -2.7062e-05,  3.7631e-06,  4.2040e-06, -2.0304e-05,\n",
            "        -1.0413e-05, -5.7201e-06,  2.9687e-06,  2.3560e-06,  2.9715e-06,\n",
            "         8.0971e-06, -2.6871e-07,  2.8072e-06, -3.4849e-05, -3.5534e-06,\n",
            "        -9.9877e-06, -9.4307e-07,  2.2974e-06,  1.1184e-07,  2.7681e-07,\n",
            "         8.0457e-06,  1.6403e-05, -1.3564e-05, -6.4744e-06, -3.3981e-05,\n",
            "         2.6787e-05,  7.5043e-06, -7.7932e-06,  5.7370e-06, -2.4662e-05,\n",
            "         1.4347e-05, -2.7519e-06,  1.5454e-05,  2.4137e-05,  3.2550e-05,\n",
            "         9.0159e-06,  1.0840e+00, -6.4194e-06, -1.5702e-05, -1.1759e-05,\n",
            "         8.9017e-02,  6.8069e-06,  5.0735e-06,  2.2816e-05,  1.4844e-05,\n",
            "         1.9622e-05,  3.8333e-05,  2.5995e-01,  7.3285e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3473e-01,  1.7512e-05, -3.5363e-07, -3.6357e-05,  5.5727e-07,\n",
            "          1.8862e-07, -9.2370e-07, -1.8104e-05, -7.7210e-06,  1.0928e-05,\n",
            "         -2.4596e-05, -3.0770e-05, -7.6303e-06, -1.1951e-05,  1.2558e-06,\n",
            "          4.2672e-05, -7.3389e-06,  4.3727e-05, -1.3231e-05, -6.5486e-06,\n",
            "          1.5235e-06, -2.1898e-05,  4.1628e-06, -1.0886e-05,  5.4739e-01,\n",
            "         -1.0490e-05,  3.4423e-05,  8.1927e-06,  7.5309e-06,  1.0858e-05,\n",
            "         -3.8367e-05,  1.4449e-06,  1.5321e-05, -1.1740e-05,  1.3730e-06,\n",
            "         -3.6287e-08,  1.5650e-05, -1.3242e-05,  1.0211e-05,  1.0421e-05,\n",
            "          1.5886e-05,  9.1613e-06, -1.7808e-07,  2.5312e-05,  3.9175e-06,\n",
            "          2.2711e-05,  1.9758e-05,  3.7847e-06,  1.2223e-07,  2.0345e-05,\n",
            "          1.0822e-05,  3.2351e+00,  2.8867e-06, -1.7515e-05, -7.0157e-06,\n",
            "          7.8414e-01,  6.1793e-06, -1.0159e-05,  1.9891e-06,  5.0882e-06,\n",
            "          9.8645e-06,  4.1139e-06,  1.0867e+00,  2.4055e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3099], requires_grad=True)\n",
            "l1_reg is: 30.26616668701172\n",
            "total_loss 1.2874722480773926\n",
            "pred: tensor([12.4434, 25.5950, 22.4023, 16.4913, 13.9972, 12.8910, 15.8665,  9.0333,\n",
            "        23.7191, 25.7464, 15.9982, 13.8495,  3.0246, 26.7309, 14.1659,  5.9086,\n",
            "        15.3763,  6.2492, 25.4834, 19.7071, 16.5588,  7.2499, 24.7365, 19.4782,\n",
            "         7.9257,  8.3957, 26.2979, 20.0890, 30.6565, 22.5283,  9.2542, 14.8666,\n",
            "        22.3104, 13.8950, 23.9242, 14.7888, 26.3009, 17.6176,  5.1269, 16.3025,\n",
            "        29.9844, 23.4508, 19.3421, 10.3996, 25.5939,  9.6899, 20.7678,  2.9630,\n",
            "         2.8328, 21.0550, 21.7595, 28.8460, 21.7759, 24.5213, 10.9276, 11.4237,\n",
            "        27.2338, 33.7257, 29.6851, 12.8207, 22.5131, 14.3674,  6.0669, 17.2610,\n",
            "        13.9765, 26.5551, 14.2054, 25.2876, 25.7526, 25.9570, 14.9796, 27.7034,\n",
            "        12.3995, 27.0089, 20.6177,  9.6855, 16.9666,  8.2174, 12.6527, 19.3427,\n",
            "        16.6260, 26.6673, 27.4093, 12.0974, 29.7039, 19.2750,  9.0558, 26.3514,\n",
            "        10.1098, 24.2857, 13.2710, 13.9743, 14.1527, 25.6539, 22.8527, 21.3503,\n",
            "         4.8933, 24.1737,  6.4540,  5.3685,  9.0913, 25.9910, 11.9520, 20.6245,\n",
            "        26.5478, 27.0717, 19.6439, 32.3578, 15.5178, 32.5426,  5.2814, 22.1950,\n",
            "         9.1961, 13.0682, 26.8967, 13.1754, 12.7710, 28.1688, 13.8527, 16.6155,\n",
            "        13.3908,  9.4822, 14.7971,  9.9059, 12.5401,  4.2999, 14.6698, 13.5184,\n",
            "         9.2538, 14.7371, 24.2808, 11.9116, 15.0640,  6.2939, 27.6866, 13.3215,\n",
            "        27.2793, 27.3217, 16.1608, 22.8914, 10.0956, 21.3959, 20.5216, 11.6363,\n",
            "        11.1850, 21.0184,  6.0284, 24.1348,  4.0063, 22.2346,  6.0545, 23.0247,\n",
            "        13.0211, 24.5387,  4.8454,  5.8861, 19.5949, 11.1233, 14.6780, 11.8302,\n",
            "        14.9642, 20.3850, 32.4462, 31.6812, 24.2142, 34.7823, 16.8237, 18.9087,\n",
            "        21.2004, 12.3046,  9.8524, 15.2659, 19.9382, 13.6595, 12.7056, 23.1753,\n",
            "        22.3965,  2.7611, 27.9788, 18.2139,  3.7841, 22.3128,  4.8146, 24.2604,\n",
            "        21.0020,  5.9738,  9.9672, 17.2354,  6.7214, 23.2848, 16.1022,  4.2427,\n",
            "        10.6140, 16.4904,  8.6503, 16.6323,  9.8951, 17.0225, 10.3662, 12.6164,\n",
            "        16.2244,  9.2457, 23.6586, 12.9545, 24.8754, 20.9514, 24.8387, 16.4740,\n",
            "        21.0630,  5.5034, 25.2202, 26.5393, 27.9986, 12.0988, 10.3764,  9.4000,\n",
            "        10.0163, 26.5257, 11.8570, 29.3971, 15.5156,  5.7622, 25.4141, 13.9036,\n",
            "        24.1733, 11.7286, 14.0317,  9.9882, 23.2962, 26.6525, 17.1342,  7.6693,\n",
            "         8.6602, 24.4756, 13.9128,  8.0749, 14.5402, 13.4450, 31.3913, 20.5668,\n",
            "        20.0648, 26.5562,  3.2281,  2.8523, 14.8821, 20.7983, 19.3147,  6.2799,\n",
            "        31.2887, 12.4310,  5.4983, 14.3995,  8.5105, 14.5865, 26.0698, 20.6401,\n",
            "        29.5098, 12.0887, 22.0799, 16.6098, 10.1012, 24.7768, 31.1831,  2.9921,\n",
            "        24.5317,  6.4471, 20.4135, 13.1807, 25.3851, 20.1911],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([13.1496, 24.6717, 22.8967, 17.1018, 13.7214, 14.3308, 15.5172, 10.1438,\n",
            "        22.9585, 24.9442, 15.4802, 13.5361,  3.3276, 28.9355, 13.5277,  7.5397,\n",
            "        15.8894,  6.6406, 25.6026, 19.0345, 15.6231,  6.1151, 24.4002, 19.6373,\n",
            "         8.3572,  8.0456, 25.3011, 21.2929, 28.4758, 24.7080,  8.4304, 14.9789,\n",
            "        22.4202, 14.5788, 24.1771, 13.6691, 25.7021, 16.6666,  5.3413, 16.2340,\n",
            "        30.2853, 22.5502, 19.0772,  9.6728, 28.4876,  9.0505, 20.1229,  2.4964,\n",
            "         3.5024, 22.1634, 20.9808, 28.5535, 22.8458, 24.6041, 11.4516, 11.9352,\n",
            "        26.3991, 33.0257, 28.9013, 12.1706, 20.9747, 14.9827,  6.2031, 15.9774,\n",
            "        14.7830, 26.2393, 14.5754, 25.4778, 25.4995, 26.6139, 15.8537, 27.7032,\n",
            "        12.0155, 25.7534, 20.3132,  9.7347, 15.8768,  8.3439, 12.7037, 18.9134,\n",
            "        16.6661, 27.7791, 27.2233, 11.8117, 31.6662, 19.6543,  8.5938, 26.7078,\n",
            "        10.5069, 26.2203, 14.5243, 13.0085, 12.9426, 24.0288, 21.6413, 22.2873,\n",
            "         4.2692, 22.3948,  6.6825,  5.4154,  9.4725, 26.6461, 11.9545, 20.3543,\n",
            "        27.1144, 28.2931, 17.5696, 32.2881, 14.4231, 33.1963,  5.7823, 23.3532,\n",
            "        10.2011, 12.7061, 25.4491, 14.1966, 12.5389, 29.0552, 13.9889, 15.7793,\n",
            "        13.5349,  9.0297, 14.4573,  9.7509, 12.8266,  4.4715, 14.1613, 15.6390,\n",
            "         9.2326, 16.4965, 21.9274, 12.4596, 15.0651,  5.7317, 27.6106, 13.6672,\n",
            "        27.6427, 25.6981, 15.9245, 23.4455,  9.7303, 19.1094, 21.3376, 11.5187,\n",
            "        11.3636, 20.3947,  5.2365, 24.0284,  3.7764, 21.4534,  6.3859, 22.3694,\n",
            "        12.3044, 22.4271,  5.5891,  5.8912, 18.7735, 10.0828, 14.6109, 11.2653,\n",
            "        16.1979, 22.1143, 31.6558, 31.4490, 24.1188, 36.1161, 16.0947, 20.0685,\n",
            "        21.3192, 12.0312,  9.7351, 13.7785, 20.9224, 14.1204, 12.6549, 24.0605,\n",
            "        22.3404,  2.9935, 27.4623, 18.7927,  3.3576, 21.8748,  4.3651, 21.9658,\n",
            "        20.0587,  6.4376,  9.6474, 16.5230,  6.4774, 22.8307, 15.6387,  3.9589,\n",
            "        10.0635, 16.7220,  9.6226, 16.1607,  9.1212, 16.1945, 10.2239, 13.5350,\n",
            "        15.0831,  8.6788, 24.5000, 12.1834, 25.2707, 21.0008, 24.4929, 17.0279,\n",
            "        22.9484,  5.1181, 26.9901, 26.7881, 29.2688, 11.6439, 11.7996,  9.8216,\n",
            "         9.1734, 26.8985, 12.8861, 28.4617, 16.3534,  5.2326, 24.7328, 13.7875,\n",
            "        24.3867, 11.6739, 14.0666, 10.2067, 21.5702, 26.8926, 16.7516,  8.8462,\n",
            "         9.4678, 26.6413, 13.2268,  7.3643, 15.1587, 13.2873, 31.0876, 19.2753,\n",
            "        20.6137, 26.4628,  3.0333,  2.7056, 15.2567, 19.8522, 19.2647,  5.9271,\n",
            "        32.1687, 12.3727,  5.6319, 15.1129,  8.0536, 15.5626, 24.8762, 20.9787,\n",
            "        29.0925, 11.9253, 20.8498, 18.0195,  9.8276, 25.0780, 32.4809,  2.7835,\n",
            "        22.2626,  5.0321, 20.0649, 12.5554, 25.1333, 20.9017])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.0840e-05,  1.5435e-05,  8.9479e-06,  ..., -1.6445e-06,\n",
            "          1.8711e-05,  4.3518e-05],\n",
            "        [-5.3470e-05,  9.3388e-09,  3.3202e-05,  ...,  2.4114e-04,\n",
            "         -1.0864e-04,  1.0291e-06],\n",
            "        [-1.9224e-05, -1.0144e-04,  3.7136e-05,  ...,  3.9178e-02,\n",
            "          5.4900e-04, -1.3743e-03],\n",
            "        ...,\n",
            "        [ 1.8443e-05, -1.9493e-05,  8.2368e-06,  ...,  2.9114e-05,\n",
            "         -2.1566e-06, -1.7766e-05],\n",
            "        [-7.5172e-06,  8.7507e-06,  1.5218e-05,  ..., -1.7366e-05,\n",
            "          2.2305e-06,  7.3700e-06],\n",
            "        [-2.1715e-05,  5.5069e-06, -1.8758e-05,  ...,  1.3674e-07,\n",
            "         -2.8311e-05,  6.5878e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.8294e-06,  4.2444e-01,  3.6860e-02,  1.1633e-06, -8.7383e-06,\n",
            "         9.6933e-06,  7.1688e-06, -6.4319e-06,  1.5788e+00,  2.4074e-05,\n",
            "        -4.0309e-05,  1.4772e-05, -1.1981e-05, -8.4948e-09, -6.4685e-06,\n",
            "        -1.4651e-05, -1.1227e-05, -7.0338e-06,  7.5333e-06,  1.2064e-05,\n",
            "        -1.3370e-05,  3.9926e-06,  2.4308e-05, -1.0151e-05,  1.3187e-05,\n",
            "         3.8851e-06, -1.6035e-05,  1.3430e-01,  2.0677e-05,  9.2934e-06,\n",
            "        -1.5187e-05, -8.1957e-06, -8.3385e-06,  2.8729e-01,  1.7836e-05,\n",
            "         3.9966e-06,  1.2571e-05, -1.7236e-05,  9.5936e-06, -1.1996e-05,\n",
            "        -6.4077e-06, -8.3889e-08, -1.3463e-05,  1.8377e-05, -1.8583e-05,\n",
            "         1.0903e-05,  1.2676e-05, -1.0941e-05, -1.5925e-05, -1.0954e-04,\n",
            "        -1.0905e-05, -4.9354e-06,  7.5798e-06, -1.1586e-05,  2.9214e-05,\n",
            "        -8.7330e-06,  4.8801e-04, -5.0117e-06, -3.3145e-07, -3.0298e-05,\n",
            "        -1.3590e-06, -6.6294e-06,  1.4584e-05, -1.4097e-05,  1.5806e-06,\n",
            "        -1.1159e-05,  1.9796e-05,  2.1979e-05, -2.5138e-05,  9.3289e-02,\n",
            "        -1.8008e-05,  2.7918e-06, -9.3773e-06, -3.4873e-07,  9.0640e-06,\n",
            "        -1.7553e-05,  6.9959e-06,  1.8807e-05, -5.9841e-06, -2.0790e-03,\n",
            "        -6.1396e-06, -3.2547e-05,  7.3396e-06, -1.2178e-06,  1.4042e-05,\n",
            "         1.6391e-05,  4.5507e-06, -1.0594e-05, -7.4361e-06,  1.5581e-05,\n",
            "        -5.1068e-07,  1.0938e-05, -1.6937e-05,  7.2341e-06, -2.4285e-05,\n",
            "        -8.0827e-07, -1.5374e-05, -1.7490e-05, -1.2981e-05, -1.6223e-05,\n",
            "         2.3721e-04,  7.4229e-06,  1.8579e-05, -1.2689e-05,  3.5585e-05,\n",
            "         3.6057e-05, -2.2284e-05, -3.5930e-06, -9.8920e-06,  1.2804e-05,\n",
            "        -4.7149e-06, -4.4323e-05, -6.9626e-06,  9.4115e-06, -2.7035e-06,\n",
            "        -1.4137e-05,  9.6273e-06,  5.0707e-06, -2.7258e-06, -3.9173e-06,\n",
            "         1.2613e+00,  6.4375e-06,  8.7910e-06, -1.7581e-05, -1.2803e-05,\n",
            "        -6.7866e-06, -2.2024e-05,  2.5705e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-8.1771e-06,  2.1170e-05, -3.6512e-05,  ...,  2.4319e-06,\n",
            "          1.1084e-09,  1.2476e-05],\n",
            "        [ 1.6807e-06,  2.8924e-05, -1.1365e-05,  ..., -1.4215e-05,\n",
            "          2.0572e-05, -1.3607e-05],\n",
            "        [ 2.4148e-06,  2.7251e-05,  4.0921e-06,  ..., -1.1177e-05,\n",
            "         -1.4612e-05,  1.4449e-05],\n",
            "        ...,\n",
            "        [ 8.7048e-06, -1.4183e-05,  1.4834e-06,  ..., -5.2189e-06,\n",
            "          7.9726e-07, -2.7481e-05],\n",
            "        [ 1.1412e-06,  1.8966e-04,  2.4657e-04,  ..., -6.5923e-06,\n",
            "          4.7558e-06, -1.8774e-05],\n",
            "        [ 1.1177e-05, -1.4434e-05,  1.2084e-05,  ..., -1.8733e-05,\n",
            "         -2.7141e-06,  8.4908e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3953e-02,  5.2811e-06, -1.7802e-05,  2.5236e-05,  1.7012e-05,\n",
            "        -5.9752e-06,  8.7259e-07, -9.6706e-06, -4.5185e-06,  3.7454e-06,\n",
            "         1.2333e-06, -7.8960e-06,  4.4242e-07, -1.9157e-05,  9.0007e-06,\n",
            "        -1.7597e-05, -1.6446e-05,  6.7907e-06,  3.2703e-07, -2.8995e-05,\n",
            "         2.2987e-06,  9.9579e-06, -5.8157e-06,  3.3427e-06, -2.5547e-05,\n",
            "        -8.8146e-06,  1.2677e-05, -1.8431e-05, -2.4940e-05,  1.9243e-05,\n",
            "        -9.4319e-06, -3.9761e-06,  6.3524e-06, -1.0447e-05, -1.5400e-05,\n",
            "         6.1167e-06,  7.2874e-06, -5.4240e-06,  1.0837e-05, -3.5838e-05,\n",
            "         1.4824e-05,  9.1417e-06, -1.1217e-05,  2.9014e-06, -2.0588e-05,\n",
            "         6.2104e-06,  1.4687e-06,  7.3349e-06,  2.1958e-05,  3.1980e-05,\n",
            "         1.8922e-07,  1.0838e+00, -2.2016e-06, -1.0724e-05,  3.7187e-06,\n",
            "         8.8897e-02,  3.1149e-06, -2.2008e-06,  1.8132e-05,  2.8814e-06,\n",
            "         1.3314e-05,  2.9996e-05,  2.5982e-01,  2.5816e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3462e-01,  5.5585e-06,  3.8090e-06, -2.8056e-05, -7.8211e-06,\n",
            "         -3.8046e-06,  1.2467e-05, -2.8237e-05, -7.7720e-06,  1.1033e-05,\n",
            "         -7.1275e-06, -2.2449e-05,  8.0613e-06, -1.6046e-05, -7.9915e-06,\n",
            "          2.8359e-05,  3.1635e-06,  3.6629e-05,  1.2171e-06,  6.3002e-06,\n",
            "         -2.4747e-07, -1.9722e-05, -4.5318e-06, -1.2675e-05,  5.4729e-01,\n",
            "         -3.0332e-07,  2.6073e-05,  1.1702e-05,  1.2321e-06,  1.6427e-05,\n",
            "         -3.0051e-05, -1.2016e-05, -4.4251e-06, -8.7618e-06, -1.2388e-05,\n",
            "          4.2028e-06,  1.2815e-05,  2.4198e-06,  1.6666e-06,  5.2315e-07,\n",
            "         -3.7491e-06, -1.3542e-06,  8.3293e-06,  4.2831e-05,  8.0737e-06,\n",
            "          1.8048e-05,  6.0590e-06, -1.9010e-05, -2.2572e-05,  6.5931e-06,\n",
            "         -9.1448e-06,  3.2334e+00, -1.4536e-06, -1.5356e-05, -7.2771e-07,\n",
            "          7.8399e-01, -5.8744e-06, -3.8787e-06,  5.0178e-06, -2.1934e-06,\n",
            "          8.7302e-07, -1.8692e-05,  1.0864e+00,  2.4045e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3097], requires_grad=True)\n",
            "l1_reg is: 30.24888038635254\n",
            "total_loss 1.0792620182037354\n",
            "pred: tensor([28.3006, 22.9919,  8.3716,  6.6980, 20.2283, 27.3297, 16.9255, 18.8545,\n",
            "        15.8795,  9.8527, 13.4150, 13.3943, 15.3416, 19.7850, 20.8462, 19.1304,\n",
            "        10.7691,  5.9924,  7.5123, 20.5794, 17.7469,  5.7512, 18.8431, 21.4819,\n",
            "        11.1560, 27.6493, 13.7646, 13.7026,  6.6520, 16.0817, 15.2481, 20.2972,\n",
            "        24.2790,  7.5886,  6.1882, 14.1174,  9.5929, 12.5021, 17.9410,  8.6601,\n",
            "         6.4179, 13.4157, 14.1531, 23.9947, 11.8586, 17.1527, 24.9798, 19.6817,\n",
            "        30.3446, 18.7399, 21.8800, 12.2891,  4.5901,  4.2397, 29.9548, 26.2414,\n",
            "        13.8814, 38.9470, 22.5990, 14.7098, 23.5294,  7.0581, 20.0801, 10.1325,\n",
            "        16.7243, 13.2048, 34.7863, 12.8850, 20.3754,  5.9358, 10.2163, 22.6121,\n",
            "        21.5129, 10.7229, 27.3766,  9.7968, 22.2216, 25.2141, 21.6852, 31.1316,\n",
            "        33.3653, 16.1934,  5.7407, 11.6349,  7.9067, 13.1071, 22.0051, 24.6294,\n",
            "        16.0024, 13.2333, 10.3620,  8.8626, 21.4701, 10.4692, 26.9860,  9.5302,\n",
            "        10.6785,  5.5814, 25.4683,  7.7752,  9.8437, 22.0984, 24.0218, 14.6111,\n",
            "        32.6933, 10.5464, 22.7234,  8.1200, 11.7375, 21.2861, 26.7607, 16.5540,\n",
            "        11.9123, 15.6595, 25.5684, 22.0130, 22.9533,  9.0450, 15.8779,  8.5915,\n",
            "         5.5874,  2.7797, 11.9629, 14.7758,  9.7453, 22.0047, 15.8028,  7.0745,\n",
            "        21.6696, 26.2189, 17.2330, 13.0089, 18.5850, 18.3436, 12.4178, 17.7484,\n",
            "        26.2806, 14.6720, 13.1219, 14.1321,  8.7865,  9.6239, 10.4770, 23.4916,\n",
            "        18.1675, 15.7041, 23.5690, 16.6957, 21.5798, 12.8513,  7.4382, 13.7655,\n",
            "        21.1505, 14.3097, 24.4554, 15.9556,  9.4325,  7.1756,  6.0035, 24.1569,\n",
            "        26.9411, 22.2543, 17.8732, 24.1711, 18.8773, 19.8316, 21.0307, 13.6698,\n",
            "         9.4349, 11.1142,  2.9398,  5.9403,  8.8021, 21.6693,  8.3466, 22.5037,\n",
            "         9.2565, 18.3070, 25.8610, 11.9859,  5.9502, 22.6356, 20.7631, 11.5271,\n",
            "        34.9091, 15.8887,  3.5710, 23.6858,  8.3795, 12.7253, 20.5730, 21.3227,\n",
            "        13.2732,  3.5422, 13.3566, 28.4853, 22.7382, 11.2956, 21.5260, 11.7210,\n",
            "        19.3839, 24.1661, 29.9473, 24.4648, 20.6694, 15.5223, 21.2715, 22.0784,\n",
            "         5.3610, 10.0503,  7.8696, 22.6517,  6.3768, 16.2437,  5.6467, 11.4595,\n",
            "         7.4964, 20.9441, 34.0858,  7.9569, 22.0284, 21.4687, 24.9662, 24.6641,\n",
            "         5.9846,  4.4484, 18.3474, 14.7186, 29.3777, 12.6552, 23.4808, 24.6360,\n",
            "        23.9231, 23.7090, 12.3967, 17.6921, 23.3148, 22.8310, 10.3444, 26.2759,\n",
            "        24.9158,  9.9077, 20.3760, 13.9335, 32.1860,  8.0344, 12.5438,  5.7731,\n",
            "        13.5727, 18.4176,  6.1823, 21.3708, 16.1124, 20.7627,  6.1778, 34.4500,\n",
            "        16.1667, 13.0208,  6.9672, 11.9823, 32.6792, 13.0198, 10.2786, 16.2992,\n",
            "        11.5275, 13.9393, 20.1633,  9.7569, 16.2309,  4.5582],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([28.6023, 23.9115,  7.9747,  6.7016, 19.4592, 27.4634, 17.5987, 19.4010,\n",
            "        16.2214,  9.2012, 13.0704, 13.7224, 13.3208, 20.6442, 21.7878, 22.1965,\n",
            "        10.7616,  5.6315,  8.2609, 20.9514, 17.2200,  4.2700, 18.6037, 21.7100,\n",
            "        10.8215, 28.6885, 13.2229, 12.6138,  7.1010, 16.8010, 16.4075, 19.6202,\n",
            "        25.4290,  7.5698,  5.9249, 14.3739,  9.7305, 11.5051, 18.3226,  9.8713,\n",
            "         6.0344, 13.5870, 14.8276, 25.6969, 11.8827, 17.2109, 23.7378, 19.5712,\n",
            "        32.0161, 16.7586, 21.9444, 14.0398,  4.2411,  4.1165, 30.0670, 28.5991,\n",
            "        13.4865, 40.0833, 22.6690, 14.1510, 23.4348,  6.9672, 20.3744,  9.7996,\n",
            "        16.4475, 11.4635, 33.8672, 12.3650, 22.3315,  5.8917,  9.5292, 20.4707,\n",
            "        22.3144, 10.5463, 28.0427, 10.2048, 24.0582, 26.1624, 23.0299, 33.0460,\n",
            "        33.6615, 17.3591,  5.6182, 11.2208,  8.8633, 13.0631, 25.1133, 26.0279,\n",
            "        17.6020, 12.5347,  9.5396,  8.2031, 23.8535,  8.7596, 27.5510,  9.7082,\n",
            "        10.4350,  4.8105, 27.0473,  7.9873,  9.4027, 23.4949, 23.6161, 15.7759,\n",
            "        33.4135, 11.4987, 21.3639,  8.8863, 12.8613, 19.8565, 28.0660, 15.9629,\n",
            "        10.9001, 14.8727, 25.3122, 22.5453, 24.9999,  8.2869, 17.0628,  9.2297,\n",
            "         5.8424,  2.3387, 11.2184, 15.7807,  9.7464, 23.7242, 16.0194,  7.8824,\n",
            "        22.0198, 25.9997, 16.5541, 12.5824, 18.2288, 18.0294, 12.2727, 16.6666,\n",
            "        26.3507, 13.6179, 13.6745, 12.8462,  8.7217,  9.5381, 10.5865, 24.1562,\n",
            "        20.2325, 16.4095, 25.3534, 15.4370, 20.8610, 11.4865,  7.1608, 13.8787,\n",
            "        20.2788, 14.7871, 24.0858, 15.6250,  8.6930,  6.2320,  5.8053, 24.1920,\n",
            "        26.1853, 23.0754, 17.9593, 23.7793, 18.5847, 18.8625, 21.5122, 13.8385,\n",
            "         9.1305,  9.9165,  3.3854,  5.2206, 10.0399, 21.7506,  8.3654, 25.2984,\n",
            "         8.5313, 19.5478, 25.9673, 12.4330,  6.2374, 23.0805, 22.0374, 12.6981,\n",
            "        37.0889, 16.1866,  3.3760, 23.6692,  7.7073, 13.2033, 20.4839, 20.9574,\n",
            "        13.1169,  3.9971, 13.2436, 27.9032, 22.6914, 10.0882, 22.2808, 10.6852,\n",
            "        19.2292, 23.7816, 30.5629, 25.4924, 20.4538, 16.8269, 21.6922, 21.9498,\n",
            "         6.1056, 10.3077,  7.5074, 23.1234,  6.1922, 13.7531,  6.5000, 11.2189,\n",
            "         7.2581, 21.4369, 37.6466,  8.4532, 23.4489, 21.1850, 24.6207, 24.3197,\n",
            "         5.0395,  4.0833, 20.0467, 15.3726, 30.3057, 12.0164, 23.9938, 23.9575,\n",
            "        23.7719, 24.9990, 12.8613, 17.6570, 24.9138, 22.6914, 10.2122, 28.6013,\n",
            "        24.7070, 10.6815, 20.4198, 13.6788, 35.0674,  7.4468, 12.0735,  5.6577,\n",
            "        13.2218, 17.8309,  6.3316, 22.6237, 16.8718, 21.7207,  6.1396, 34.2969,\n",
            "        13.6355, 13.8308,  6.4554, 11.3733, 34.7197, 12.7916,  8.9286, 16.0288,\n",
            "        10.4885, 14.4196, 19.8214,  8.9425, 16.1333,  3.8084])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.1092e-05,  3.4752e-06, -7.7636e-06,  ...,  1.4026e-05,\n",
            "          1.2396e-05,  3.6483e-05],\n",
            "        [-7.7321e-05,  3.8298e-05,  5.2056e-05,  ...,  3.8825e-04,\n",
            "         -1.1689e-04, -3.6510e-04],\n",
            "        [-6.6914e-05, -8.3946e-05,  2.8926e-05,  ...,  3.9366e-02,\n",
            "          2.6581e-04, -2.1491e-03],\n",
            "        ...,\n",
            "        [ 4.4295e-06, -1.3253e-05,  1.3302e-05,  ...,  2.7362e-05,\n",
            "          4.7543e-06, -1.3067e-05],\n",
            "        [-1.6200e-05, -1.5521e-06, -4.5265e-06,  ..., -1.1078e-05,\n",
            "          3.6450e-06,  9.0162e-06],\n",
            "        [-3.9254e-05, -7.4274e-06, -4.5413e-06,  ..., -8.8411e-06,\n",
            "         -2.6107e-05,  1.5290e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.2205e-06,  4.2427e-01,  3.6250e-02, -1.0987e-06,  1.1146e-06,\n",
            "         1.0401e-05, -1.9862e-06,  1.0889e-05,  1.5782e+00,  2.1882e-05,\n",
            "        -4.3518e-05,  7.0737e-06, -1.4055e-05,  7.0414e-06,  1.1750e-05,\n",
            "        -8.3390e-06, -8.0933e-06,  1.3730e-05,  5.8645e-06,  3.7995e-06,\n",
            "         2.2628e-06,  9.6853e-08,  2.0536e-05, -3.8491e-06,  1.7303e-05,\n",
            "        -1.3956e-05, -2.2566e-05,  1.3412e-01,  2.9857e-05, -5.5689e-07,\n",
            "        -1.9953e-05, -1.2331e-05, -1.6851e-06,  2.8691e-01,  1.1534e-05,\n",
            "        -3.4580e-06,  4.4323e-06, -1.0891e-05, -6.0408e-06,  2.4737e-06,\n",
            "         1.4364e-05,  1.1514e-05, -1.9544e-05,  2.8486e-05, -1.3613e-05,\n",
            "         1.9629e-05,  9.6566e-06, -1.5065e-05, -1.3733e-05, -2.4363e-04,\n",
            "         3.6501e-06,  5.5538e-06,  1.2633e-05, -5.3065e-06,  2.7033e-05,\n",
            "        -8.9032e-06,  1.2178e-04, -5.5845e-06,  1.5508e-05, -1.9700e-05,\n",
            "        -4.9863e-06,  8.3244e-06,  1.2419e-05, -7.7759e-06, -1.9712e-05,\n",
            "        -1.9263e-05,  1.5271e-05,  1.7871e-05, -1.3172e-05,  9.3109e-02,\n",
            "        -1.3055e-05, -9.1311e-06,  3.3630e-06,  5.4188e-07, -7.7742e-06,\n",
            "        -2.3445e-05, -1.1385e-07,  1.6618e-05, -1.0119e-05, -2.4293e-03,\n",
            "         5.4729e-06, -3.1909e-05,  6.7827e-06,  6.0338e-07,  7.7275e-06,\n",
            "         2.6491e-05,  1.6757e-05, -1.9306e-05,  1.4637e-05,  2.5699e-05,\n",
            "         9.9627e-06,  7.9165e-06, -4.9664e-06, -1.8955e-06, -1.2637e-05,\n",
            "         3.2173e-07, -1.0357e-05, -1.1643e-05, -1.9051e-05,  3.5526e-06,\n",
            "         6.1012e-05, -3.0734e-06,  4.5720e-06, -1.6783e-05,  3.8451e-05,\n",
            "         1.9643e-05, -1.8186e-05,  6.8771e-06, -3.5718e-06,  1.6937e-05,\n",
            "        -1.2487e-05, -3.7351e-05, -3.5237e-06, -4.1798e-07,  1.3620e-05,\n",
            "        -3.7197e-07,  1.8332e-05,  8.8341e-06,  1.2962e-05,  3.0037e-07,\n",
            "         1.2608e+00,  6.4219e-06,  1.6649e-06, -2.6259e-05, -1.6892e-05,\n",
            "         4.9431e-07, -1.7300e-05,  2.4782e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.6157e-05, -1.0003e-04, -1.8672e-04,  ..., -4.4554e-06,\n",
            "         -1.3420e-05,  1.8054e-05],\n",
            "        [-2.2530e-06,  2.8233e-05, -2.0060e-05,  ..., -1.8322e-05,\n",
            "          8.6100e-06, -1.1148e-05],\n",
            "        [-1.8351e-05,  2.6331e-05,  5.5262e-06,  ...,  3.4702e-06,\n",
            "         -1.8989e-05,  8.1446e-06],\n",
            "        ...,\n",
            "        [ 6.7781e-06, -5.7771e-06, -4.5844e-06,  ...,  4.4323e-06,\n",
            "         -6.2075e-06, -2.5301e-05],\n",
            "        [ 4.9988e-06, -6.6134e-05, -7.5545e-05,  ...,  5.1534e-06,\n",
            "         -1.9819e-06, -1.2723e-05],\n",
            "        [ 1.6583e-05, -7.5625e-05, -7.7913e-05,  ..., -4.7140e-06,\n",
            "          7.4133e-07,  6.6101e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3794e-02,  5.8316e-06, -3.7909e-06,  1.3275e-05,  3.0185e-05,\n",
            "        -3.1397e-06, -1.2540e-05,  5.0004e-06,  7.3611e-06, -1.8583e-05,\n",
            "        -2.4391e-06,  7.7887e-06, -6.0454e-06, -5.1466e-06, -8.4790e-07,\n",
            "        -2.7674e-05,  3.1081e-06, -4.8888e-07, -1.3162e-05, -2.6817e-05,\n",
            "         3.7398e-06,  1.4070e-05, -3.7217e-06, -5.7682e-06, -4.1214e-05,\n",
            "        -1.4035e-05,  1.4325e-05, -2.7544e-05, -6.0216e-06,  2.9759e-05,\n",
            "         1.0683e-06,  3.2942e-06,  2.2738e-09, -9.9487e-06, -1.9509e-05,\n",
            "        -5.6195e-06, -1.0918e-05,  1.1902e-05,  1.6417e-05, -2.7510e-05,\n",
            "        -5.9428e-06,  6.1542e-07, -4.2986e-06, -9.6533e-06, -6.9207e-06,\n",
            "        -1.1112e-05, -4.7333e-06, -9.9703e-06,  1.0001e-05,  2.1467e-05,\n",
            "        -1.7754e-05,  1.0833e+00,  1.1594e-05,  3.7568e-06,  7.6488e-06,\n",
            "         8.8710e-02, -1.0208e-05,  1.2523e-06,  3.9159e-06, -1.7885e-05,\n",
            "        -2.3630e-06,  1.2494e-05,  2.5960e-01, -4.8062e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3452e-01, -1.5205e-05, -2.4455e-06, -1.0588e-05, -5.3661e-06,\n",
            "          2.6015e-06,  1.4514e-05, -2.7359e-05,  2.1782e-06,  1.1299e-06,\n",
            "          1.8588e-05, -4.9622e-06,  1.2179e-05, -9.7315e-06, -6.3187e-06,\n",
            "          5.4775e-06,  2.6156e-06,  2.0241e-05,  4.2184e-06,  7.8630e-06,\n",
            "          8.1586e-06, -7.7631e-06, -2.3571e-06, -4.2872e-06,  5.4719e-01,\n",
            "          1.8865e-05,  8.5533e-06,  4.8616e-06, -1.4437e-05,  1.1435e-05,\n",
            "         -1.2567e-05, -1.4131e-05, -1.2202e-05,  3.9169e-06, -1.4773e-05,\n",
            "         -1.9812e-06,  2.6365e-07,  6.5157e-06, -1.6024e-05, -1.8386e-05,\n",
            "         -1.1427e-05, -8.1788e-07,  5.9859e-06,  4.8597e-05,  1.8141e-06,\n",
            "          3.8523e-06, -1.6274e-05, -2.9528e-05, -3.2997e-05, -1.5787e-05,\n",
            "         -1.7117e-05,  3.2313e+00,  4.6399e-06, -3.4134e-06,  1.4931e-05,\n",
            "          7.8384e-01, -6.7230e-06,  1.1773e-05, -2.2563e-06,  1.2521e-06,\n",
            "         -1.7220e-05, -2.9218e-05,  1.0860e+00,  2.4034e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3095], requires_grad=True)\n",
            "l1_reg is: 30.26274871826172\n",
            "total_loss 1.2575122117996216\n",
            "pred: tensor([ 8.4368,  4.7555, 25.6731, 23.6695, 15.6781, 30.0780, 27.8392, 10.1241,\n",
            "        23.7742, 21.5403, 24.4040, 10.7675, 16.1384, 34.9708, 12.8090, 25.9626,\n",
            "        10.5653, 23.5153, 14.7607, 25.2704, 27.9440, 25.4853, 33.4503,  2.9061,\n",
            "        16.7958, 12.0207, 27.3288,  6.1383, 25.0477, 14.2117, 25.9183, 22.0478,\n",
            "        16.1607, 22.5936, 13.0700, 26.5731, 17.7114, 11.5677, 21.7050,  8.2916,\n",
            "        19.8917,  5.0341, 10.6806, 27.6389,  7.9898, 24.1701, 14.1214,  6.5139,\n",
            "        24.8629, 25.6071, 18.1454,  5.7110, 15.7022, 28.8629, 13.0594, 26.1119,\n",
            "        21.6209, 10.1583, 13.7360,  9.5628, 10.0514, 10.8080, 12.5344,  9.2522,\n",
            "        15.7195,  6.5798, 25.0023,  4.2439,  3.3502, 15.2313,  8.8697, 23.6068,\n",
            "         9.9463, 14.5372,  9.4755, 12.8641, 22.0935, 24.2803,  6.0586,  6.2628,\n",
            "        16.1569, 20.7748, 25.6288, 11.0364, 14.3566, 11.3193, 16.0552, 14.1189,\n",
            "        15.4750, 15.2767, 20.5261,  9.9839, 16.6768, 21.5820,  6.2979, 24.2664,\n",
            "        21.6049, 35.1333, 24.3963, 11.2777,  3.8337, 23.0069, 23.1841, 27.7002,\n",
            "        24.3483, 22.5307, 10.0858, 12.5500, 20.6038, 12.8024, 20.6324, 22.1548,\n",
            "        12.9682, 24.4875,  9.8702, 19.3484, 15.4152, 13.8807,  5.5998, 16.2024,\n",
            "        21.0256, 13.1785,  5.7704,  7.8715, 19.2768, 24.2237, 18.9610, 25.0294,\n",
            "        17.0839,  7.0812, 23.1560, 16.3183, 14.7655, 15.5459,  9.4813, 25.3264,\n",
            "        22.4102, 24.9097, 10.5654, 24.7330, 26.1574,  4.8273, 25.6497,  6.7703,\n",
            "        22.2613,  8.2723, 27.1690, 21.1986, 27.1814,  6.3031, 17.8497, 21.6075,\n",
            "        11.4960, 28.4040, 11.6053, 13.1706,  5.9761, 15.1022, 14.1417,  6.0039,\n",
            "         9.2274, 20.9191,  5.4798, 10.9918, 12.3098, 27.1425, 19.5644, 26.8795,\n",
            "         4.7758,  9.5241, 20.5156, 16.3378, 17.1264, 15.4442, 14.1217, 17.4717,\n",
            "        35.0136, 24.8045,  9.4195,  8.5505,  3.0043, 15.4765, 23.9207, 12.7755,\n",
            "        13.3020,  5.8336, 19.0993, 10.7526, 24.5192, 19.2318, 10.2259, 13.2562,\n",
            "        22.3603,  7.8153, 25.2485, 18.2783, 14.0147, 25.1199, 17.4393, 22.8533,\n",
            "        15.3118,  5.3891, 26.9502, 24.2656,  3.0107,  9.8320, 15.9130, 10.5167,\n",
            "        34.8704,  8.9242,  5.9820, 14.5515, 12.4780, 10.0365, 20.4334, 33.3393,\n",
            "         8.2968, 21.9586, 18.3964,  8.6814, 21.0059, 24.9302,  5.0394, 16.4390,\n",
            "        15.6627, 19.2866,  8.8831, 18.7698, 25.5910, 15.7845, 27.0723, 17.2310,\n",
            "        21.9219, 21.7901, 25.5420, 10.0926, 16.3158, 11.9242,  9.6158, 28.4419,\n",
            "        18.2020, 11.5173, 22.7209, 29.0238, 25.3256, 22.7894, 16.7234, 17.5442,\n",
            "         9.3336, 18.6756, 25.4046, 12.7371, 11.2439, 21.7268, 17.9210, 10.9026,\n",
            "        23.5259, 22.5864, 16.1141,  7.9446, 23.5436,  9.8257, 20.4304, 12.3848,\n",
            "        16.8087, 11.7883, 11.7025,  8.9567, 25.0896,  7.8014],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([ 7.6252,  4.7149, 27.0956, 24.7881, 15.4052, 31.3393, 29.6129, 10.8617,\n",
            "        27.3101, 21.5129, 24.7660, 11.5024, 16.4249, 36.0293, 10.5796, 24.3048,\n",
            "         9.5732, 24.3694, 13.1081, 25.2529, 27.1687, 25.0174, 34.8000,  2.5944,\n",
            "        17.5676, 11.2031, 26.9940,  6.5972, 26.8806, 15.3727, 25.2827, 24.8666,\n",
            "        15.7272, 23.5116, 14.0473, 27.6397, 16.3352, 12.5000, 22.8089,  8.3335,\n",
            "        19.3274,  4.5205, 11.1280, 26.2064,  9.1036, 23.4127, 14.4799,  6.0440,\n",
            "        24.4880, 25.3007, 18.5246,  5.8000, 14.8496, 29.6456, 13.5258, 25.0120,\n",
            "        22.0167, 10.2267, 15.2404,  9.6956, 10.2500, 10.7634, 12.9823, 10.0694,\n",
            "        15.1120,  6.6911, 24.6943,  3.4038,  2.9763, 15.4041,  9.7152, 24.1173,\n",
            "         9.7137, 14.0640,  8.5330, 11.9753, 21.0874, 24.5546,  6.5705,  6.2891,\n",
            "        15.3303, 20.5062, 25.8443, 11.0691, 13.2216, 11.6667, 16.6193, 13.9888,\n",
            "        14.2655, 13.7427, 21.4650, 10.2986, 17.2241, 21.5721,  6.4091, 24.0313,\n",
            "        22.2456, 36.0309, 25.6379, 11.5597,  4.2308, 23.2506, 24.2602, 28.1975,\n",
            "        24.4639, 21.5261,  9.2018, 12.6134, 21.1832, 12.5976, 21.1748, 22.7441,\n",
            "        12.6252, 25.7845,  9.6395, 19.1647, 15.0278, 13.2884,  5.7545, 15.9076,\n",
            "        21.8326, 13.5729,  5.4434,  7.2917, 19.6629, 24.3212, 20.8937, 26.1508,\n",
            "        19.9541,  6.6393, 23.0878, 18.0296, 14.6286, 15.0293,  8.4420, 25.3483,\n",
            "        22.6358, 24.0300,  9.8279, 27.2477, 25.0707,  4.6487, 25.0113,  7.1183,\n",
            "        22.7719,  8.2237, 29.0526, 21.6329, 28.0782,  6.8539, 16.0704, 22.8746,\n",
            "        10.6081, 28.4408, 12.0991, 12.7806,  5.6481, 15.3425, 13.1483,  5.7801,\n",
            "         8.8788, 21.5107,  5.0426, 11.7030, 12.3930, 25.5266, 20.7734, 27.2539,\n",
            "         4.3307,  8.7321, 20.3720, 17.3651, 16.6770, 14.2097, 13.9712, 19.6378,\n",
            "        36.1679, 24.8764,  9.7469,  7.8224,  3.1293, 16.1949, 25.9174, 11.5326,\n",
            "        14.4196,  6.6741, 20.0117, 10.4645, 25.6022, 19.7808,  9.8086, 12.8757,\n",
            "        25.6530,  7.2944, 25.4932, 18.8559, 13.2863, 25.0745, 20.1595, 21.9457,\n",
            "        14.3155,  5.1470, 26.5894, 24.4635,  2.5369, 10.2096, 15.8179, 11.7508,\n",
            "        35.6195,  9.0231,  5.7276, 13.8809, 12.4759, 10.0000, 20.3443, 33.4507,\n",
            "         7.7878, 22.1881, 18.2678,  8.3162, 19.6073, 21.9030,  4.7562, 17.6767,\n",
            "        15.0254, 18.1318,  9.1936, 19.6914, 27.0030, 17.6947, 26.1066, 16.0614,\n",
            "        21.5773, 20.3049, 25.2300, 10.2887, 15.8154, 11.8317,  9.6741, 27.3711,\n",
            "        19.0480, 10.8720, 23.6040, 29.6748, 25.5912, 24.4763, 18.8368, 15.6017,\n",
            "         9.3103, 18.8760, 25.0184, 12.8270, 10.6810, 21.2901, 16.1643,  9.6923,\n",
            "        24.0335, 22.2177, 16.4330,  7.5672, 23.2051,  9.6626, 21.1667, 13.0252,\n",
            "        16.5865, 11.7910, 12.2077,  8.2558, 25.2241,  7.0093])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.3189e-06, -1.7288e-05, -1.2804e-05,  ...,  1.8129e-05,\n",
            "         -3.2869e-06,  2.0155e-05],\n",
            "        [-8.2042e-05,  7.0421e-05,  4.6571e-05,  ...,  5.1683e-04,\n",
            "         -7.7280e-05, -5.5903e-04],\n",
            "        [-6.2335e-05, -2.7462e-05,  4.4456e-06,  ...,  3.9496e-02,\n",
            "          1.2662e-04, -2.6287e-03],\n",
            "        ...,\n",
            "        [-1.8183e-05,  2.3639e-06,  7.8600e-06,  ...,  1.5786e-05,\n",
            "          9.7408e-07,  1.1623e-06],\n",
            "        [-1.4014e-05, -8.2447e-07, -1.2296e-05,  ...,  4.5819e-06,\n",
            "         -5.0816e-06,  4.9638e-07],\n",
            "        [-4.5037e-05, -9.0678e-06,  1.8254e-05,  ..., -6.9212e-06,\n",
            "         -1.4124e-05,  1.3129e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 2.3336e-06,  4.2428e-01,  3.6450e-02,  6.8558e-06, -1.8177e-08,\n",
            "         1.0397e-06, -2.1354e-07,  1.6480e-05,  1.5789e+00,  9.9187e-06,\n",
            "        -3.6396e-05, -9.8721e-06, -5.9090e-06,  3.3901e-06,  1.8148e-05,\n",
            "         7.3445e-06,  4.7254e-06,  2.2418e-05, -5.6322e-06, -1.3638e-05,\n",
            "         6.3072e-06, -1.3407e-05,  7.1587e-06,  1.1800e-05,  1.1020e-05,\n",
            "        -2.0013e-05, -1.8444e-05,  1.3414e-01,  2.8126e-05,  5.6687e-07,\n",
            "        -1.4212e-05, -6.0516e-06,  1.4297e-05,  2.8711e-01, -4.1385e-06,\n",
            "        -1.5686e-07, -1.2892e-05,  4.8261e-06, -1.0115e-05,  5.4937e-06,\n",
            "         2.3058e-05,  1.1955e-05, -1.5017e-05,  2.7591e-05,  8.6120e-07,\n",
            "         1.7490e-05, -3.0533e-06, -8.7840e-06, -1.7833e-06, -3.1224e-04,\n",
            "         6.7452e-06,  4.9939e-06,  7.1734e-06,  1.0361e-05,  1.5053e-05,\n",
            "         9.4124e-07, -2.3338e-05,  3.8994e-06,  1.9752e-05, -1.6018e-07,\n",
            "         1.7492e-06,  1.1807e-05,  4.7772e-07,  7.9108e-06, -2.8871e-05,\n",
            "        -1.6565e-05,  1.1940e-06,  4.1778e-06,  7.6010e-06,  9.3036e-02,\n",
            "         1.3950e-06, -9.8481e-06,  4.8318e-06, -8.6554e-06, -1.2923e-05,\n",
            "        -1.8752e-05,  3.4993e-06,  4.6688e-06, -3.8438e-06, -2.1767e-03,\n",
            "         5.9205e-06, -2.1332e-05, -3.7183e-06, -7.7515e-06, -7.9606e-06,\n",
            "         2.5580e-05,  1.7738e-05, -1.7151e-05,  2.4495e-05,  2.4809e-05,\n",
            "         9.3789e-06, -4.8100e-06,  1.5805e-05, -1.1459e-07,  7.8448e-06,\n",
            "        -8.6517e-06,  4.1601e-06,  3.6156e-06, -1.4514e-05,  1.1321e-05,\n",
            "         1.3752e-04, -2.5161e-06, -1.8050e-05, -1.0469e-05,  3.1031e-05,\n",
            "        -5.1102e-06, -4.4969e-06,  6.2857e-06,  1.2101e-05,  1.0655e-05,\n",
            "        -9.4736e-06, -2.1080e-05,  9.5954e-06,  7.4283e-07,  1.8309e-05,\n",
            "         2.2014e-05,  1.6166e-05,  2.2181e-06,  1.7047e-05, -5.9034e-06,\n",
            "         1.2611e+00, -3.5757e-06, -1.4752e-05, -2.4098e-05, -1.0570e-05,\n",
            "        -2.9542e-06, -3.0584e-06,  1.3961e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.3326e-05, -5.2944e-05, -1.0653e-04,  ..., -6.4132e-07,\n",
            "         -1.5495e-05,  1.3090e-05],\n",
            "        [ 4.2066e-06,  1.7608e-05, -1.7892e-05,  ..., -1.2017e-05,\n",
            "         -1.2156e-05,  1.0642e-06],\n",
            "        [-2.7040e-05,  1.5503e-05, -3.1831e-06,  ...,  6.6524e-06,\n",
            "         -1.2929e-05, -7.5292e-06],\n",
            "        ...,\n",
            "        [-4.9559e-06,  1.1789e-05, -4.5506e-08,  ...,  3.1184e-06,\n",
            "         -2.5117e-06, -1.3339e-05],\n",
            "        [-1.5045e-06,  1.0620e-05,  6.1838e-05,  ...,  5.7502e-06,\n",
            "          1.9619e-06,  2.7543e-06],\n",
            "        [ 1.1453e-05, -6.2899e-05, -6.8871e-05,  ...,  1.7907e-05,\n",
            "         -6.1471e-06, -5.0761e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3798e-02, -3.6776e-06,  1.8819e-05, -7.4883e-06,  3.2038e-05,\n",
            "         9.4133e-06, -1.4607e-05,  8.2077e-06,  8.0533e-06, -2.8679e-05,\n",
            "         4.2545e-06,  1.1906e-05, -1.8809e-06,  1.7463e-05,  2.8651e-07,\n",
            "        -2.6740e-05,  1.0708e-05,  2.9639e-06, -1.5302e-05, -1.4856e-05,\n",
            "        -4.9638e-06,  7.7675e-06,  8.1629e-06, -3.9694e-06, -4.5314e-05,\n",
            "        -8.7336e-06,  5.8080e-06, -2.5744e-05,  2.1000e-05,  2.9226e-05,\n",
            "         5.1841e-07, -1.6244e-07, -1.5715e-05,  4.9984e-07, -1.3207e-05,\n",
            "        -6.1829e-06, -1.7302e-05,  1.7496e-05,  1.1439e-05, -1.0014e-05,\n",
            "        -1.4636e-05, -1.7058e-05,  1.1928e-05, -1.0939e-05,  1.5380e-05,\n",
            "        -1.6703e-05, -3.2001e-07, -1.5553e-05, -1.0756e-05,  2.0026e-06,\n",
            "        -2.3910e-05,  1.0839e+00,  1.4012e-05,  6.7882e-06,  1.1887e-06,\n",
            "         8.8762e-02, -1.2201e-05, -5.6400e-06, -1.8878e-05, -2.6575e-05,\n",
            "        -6.4721e-06, -1.3258e-05,  2.5972e-01, -4.2699e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3441e-01, -2.3857e-05,  1.9254e-06,  1.5132e-05,  6.8601e-06,\n",
            "         -1.6257e-06,  6.4011e-06, -1.6569e-05,  1.1589e-06, -1.7781e-05,\n",
            "          3.1732e-05,  2.0775e-05,  5.9151e-06,  5.9516e-06,  5.2031e-06,\n",
            "         -2.5104e-05, -7.8684e-06, -4.5083e-06, -3.0597e-06, -7.2980e-07,\n",
            "          5.7220e-06,  1.3023e-05,  9.6002e-06,  1.3274e-05,  5.4709e-01,\n",
            "          2.6116e-05, -1.7216e-05, -1.1278e-05, -1.8536e-05, -3.0168e-06,\n",
            "          1.3168e-05, -6.0341e-06, -9.1987e-06,  5.3282e-06, -6.9196e-06,\n",
            "          2.4613e-06, -2.1033e-05,  2.0274e-07, -2.1947e-05, -2.5403e-05,\n",
            "         -8.3351e-06,  9.6648e-06, -6.1232e-06,  4.3790e-05, -1.3811e-05,\n",
            "         -1.8925e-05, -2.6364e-05, -2.8993e-05, -3.2381e-05, -2.5928e-05,\n",
            "         -1.4275e-05,  3.2321e+00,  1.3943e-07,  1.7366e-05,  1.9026e-05,\n",
            "          7.8376e-01,  2.5341e-06,  1.5860e-05,  1.1969e-06, -5.6469e-06,\n",
            "         -2.3503e-05, -2.8691e-05,  1.0861e+00,  2.4024e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3096], requires_grad=True)\n",
            "l1_reg is: 30.248035430908203\n",
            "total_loss 1.1777535676956177\n",
            "pred: tensor([28.0220, 25.1373, 18.2648,  2.9909, 12.1970, 27.1289, 22.4405,  5.2983,\n",
            "         9.6021, 13.8122,  7.8405,  5.5910, 12.0514,  3.7071, 23.2574, 28.1114,\n",
            "        15.2821, 20.7026, 12.6452, 11.5484,  5.1133,  3.2587, 11.6893, 12.3843,\n",
            "        16.7973, 11.3721, 21.2676, 23.2433, 20.3630, 16.8534, 21.9469, 26.9526,\n",
            "        13.4015, 22.3389, 22.0318, 11.6347,  7.5243, 23.0755, 12.1948, 38.0623,\n",
            "        14.2292,  8.9973, 24.5618, 19.8996, 26.5538, 24.9176, 10.1880, 20.9193,\n",
            "        17.0434, 27.7039,  3.2264, 18.6088,  4.8343, 16.2658, 22.2180, 11.2795,\n",
            "         5.6621,  9.2289, 12.8360, 16.3990,  6.8013, 25.6199, 33.4589, 23.2430,\n",
            "        25.7056,  6.2226, 23.9273, 20.4702, 26.0439,  9.0882, 12.9973, 14.0001,\n",
            "         4.8594, 13.3181, 27.3128, 17.3600,  9.9041, 17.3504, 22.2461, 24.6774,\n",
            "        13.0607, 21.7308, 22.7478, 21.6260, 27.0057, 13.8103, 23.4349, 13.2361,\n",
            "        16.0392,  3.5863, 20.6508,  8.7704, 20.7074, 24.6462, 10.5086, 11.4836,\n",
            "        13.0193, 12.0480, 24.5832,  9.7829, 20.7729, 13.7074, 15.8745,  9.3052,\n",
            "        25.3911, 13.7521, 23.6482,  5.9880,  5.9509,  9.3988, 30.7457, 27.2629,\n",
            "        20.1378, 33.1705, 17.5525, 31.4847, 24.9094, 12.8727, 28.6179, 18.3517,\n",
            "        23.1583, 24.0200, 20.4525, 24.1301, 19.2452,  9.1162, 26.5065,  9.8930,\n",
            "        28.2904, 24.2195,  3.6155, 26.0611, 28.2366, 21.9236,  5.9751,  9.6063,\n",
            "        24.5280, 15.2169, 24.0055, 15.4317,  8.1510, 14.7646, 18.1423, 19.8360,\n",
            "        12.4897, 28.0849, 10.3452, 12.3940, 16.3577, 10.5603, 11.4922, 25.2941,\n",
            "         6.6024, 12.8239, 27.0024,  3.6364, 14.3782,  8.0317, 24.7983, 27.9909,\n",
            "        12.2863, 11.1574, 13.2590, 35.2311, 13.0893, 23.2346, 10.7772, 10.6369,\n",
            "        27.3429,  6.8914, 27.4940, 14.4061,  6.4985, 12.5882,  9.2445,  6.6355,\n",
            "        15.3914, 26.1732, 10.9853, 14.1601, 21.7163, 11.5688, 12.2000, 21.4358,\n",
            "        18.1271,  6.6700, 26.4379,  9.1193, 24.2592, 22.1103, 13.6990, 20.2494,\n",
            "         5.2686, 27.2583, 10.5022,  6.0177, 10.4152, 10.6119,  3.8974, 11.7244,\n",
            "        13.3711, 17.3840, 15.3800, 13.2748,  4.5931, 13.8453,  8.6699, 19.6819,\n",
            "        15.7995, 22.3983, 31.1532, 23.3553, 11.1465, 19.3516, 18.7172, 15.7113,\n",
            "         5.8524, 14.1182, 10.6727, 22.9424, 27.2941, 17.0861, 10.2109, 35.4153,\n",
            "        25.4813, 10.1363, 19.8023, 20.2435, 11.0636, 13.6955, 12.1281, 15.9098,\n",
            "         8.7426, 10.3755, 18.6748, 14.8608,  8.6053, 24.5621, 15.9330, 11.3363,\n",
            "         5.2801, 25.3149, 15.3508, 24.8104, 16.4753,  4.0070, 21.9718, 25.6781,\n",
            "        18.2671,  2.9171, 14.9824, 12.0140, 10.0021, 13.0566,  5.4179, 15.2627,\n",
            "        29.5190, 20.7136, 20.4548,  8.8953, 15.4934, 13.1195, 19.7881, 13.3456,\n",
            "         5.2630, 11.2248, 22.8573,  6.0154, 19.1277, 13.7375],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([28.5029, 25.7512, 17.2766,  2.3983, 11.6320, 28.0444, 22.0358,  5.2390,\n",
            "        10.5894, 13.4441,  8.8367,  6.2500, 12.0438,  2.8868, 21.8545, 27.5793,\n",
            "        14.8438, 20.4992, 12.7119, 10.7930,  5.6349,  3.3879, 12.2191, 12.8408,\n",
            "        16.5146, 10.4878, 20.4319, 21.0167, 19.3636, 17.6392, 23.5169, 27.2146,\n",
            "        12.8787, 22.3483, 21.1755, 11.3705,  7.7273, 22.8468, 11.1549, 40.9595,\n",
            "        14.5307,  9.0140, 24.7221, 19.9049, 27.2260, 24.1835, 10.7407, 21.1477,\n",
            "        17.7502, 25.8522,  3.3958, 18.3333,  4.7112, 16.7840, 21.6788, 12.8317,\n",
            "         6.5000,  9.3750, 13.4758, 15.3364,  6.8519, 28.4034, 32.7656, 23.2647,\n",
            "        24.4949,  7.0930, 24.7277, 20.4546, 25.1279,  9.6307, 12.3256, 15.0574,\n",
            "         5.6575, 13.4434, 30.2764, 18.7081, 10.1481, 19.9454, 22.0323, 22.4143,\n",
            "        13.1442, 21.9368, 22.9166, 20.7602, 26.7613, 14.7092, 22.7710, 14.1771,\n",
            "        16.9941,  3.5509, 19.5975,  9.2253, 20.7442, 23.3247, 11.2250, 10.9867,\n",
            "        13.4036, 12.1100, 24.0851, 10.1734, 20.2321, 14.8246, 16.6146,  9.4689,\n",
            "        26.3721, 13.8732, 22.6834,  5.0388,  5.3168,  9.1595, 31.1275, 26.6282,\n",
            "        19.5858, 34.0910, 15.5175, 29.8007, 24.6491, 12.5806, 28.4644, 16.5888,\n",
            "        23.2997, 24.5591, 21.0106, 23.5130, 20.2719,  9.2930, 27.2424,  9.7813,\n",
            "        27.8580, 23.9563,  3.7538, 25.8747, 27.9216, 22.5258,  4.5049,  9.5000,\n",
            "        25.9200, 15.9004, 23.1896, 16.1538,  9.9713, 15.6983, 16.8981, 20.9750,\n",
            "        12.0579, 28.3915, 10.4300, 11.8373, 14.5522, 11.3391, 11.0437, 25.0859,\n",
            "         6.1462, 12.8758, 26.1767,  3.7462, 14.2534,  8.3295, 24.5346, 27.3353,\n",
            "        11.4345, 10.9893, 13.4633, 33.4256, 12.5437, 24.2598, 10.5968, 11.0542,\n",
            "        27.4537,  6.8346, 26.9071, 18.2203,  5.7522, 12.0716,  8.1115,  6.2667,\n",
            "        14.7459, 24.5410, 11.4865, 13.6488, 21.2334, 12.0504, 11.9697, 20.8235,\n",
            "        18.3941,  7.2207, 26.5567,  9.5536, 24.7204, 22.0434, 13.0504, 19.6534,\n",
            "         5.6016, 27.8016, 10.8191,  6.3984,  9.5795,  8.6269,  4.3103, 11.8495,\n",
            "        13.3827, 18.0751, 14.9064, 13.1141,  4.9550, 14.8241,  7.6426, 19.9219,\n",
            "        15.9647, 20.8926, 32.6551, 23.2959, 11.3787, 19.5906, 16.1303, 15.5823,\n",
            "         6.3338, 11.6007, 10.1527, 22.5898, 26.1253, 18.3399, 10.9200, 35.9483,\n",
            "        26.7589,  9.8110, 20.1652, 20.9799,  9.8086, 13.8511, 10.9756, 16.1891,\n",
            "         8.6667, 10.0000, 20.3412, 15.1599,  9.4238, 25.6826, 16.8852, 12.0117,\n",
            "         5.2738, 24.8711, 15.5292, 26.2859, 17.4081,  4.2636, 22.3133, 25.9811,\n",
            "        18.2353,  3.2286, 14.5089, 13.4940, 10.4222, 13.5650,  5.5773, 15.7708,\n",
            "        28.5692, 21.4626, 21.9697,  9.2040, 16.6666, 13.3983, 19.9588, 11.6033,\n",
            "         4.9688, 11.1299, 23.0122,  5.4820, 18.1222, 14.2810])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.7477e-05, -2.5975e-05, -7.3404e-06,  ...,  1.1822e-05,\n",
            "         -7.4012e-06, -4.5405e-06],\n",
            "        [-4.7787e-05,  8.9324e-05,  1.7870e-05,  ...,  4.9244e-04,\n",
            "         -1.1137e-04, -6.4341e-04],\n",
            "        [-2.9573e-05,  4.9564e-05, -2.7587e-05,  ...,  3.9388e-02,\n",
            "         -1.1637e-04, -2.8138e-03],\n",
            "        ...,\n",
            "        [-2.8536e-05,  6.4186e-06, -7.0375e-06,  ..., -4.6271e-06,\n",
            "         -1.2427e-05,  3.9658e-06],\n",
            "        [-2.0470e-06,  9.8303e-06, -9.2895e-06,  ...,  8.6740e-06,\n",
            "         -2.9363e-06, -1.7172e-05],\n",
            "        [-4.0243e-05, -5.4391e-07,  2.8769e-05,  ...,  4.7983e-06,\n",
            "          6.6591e-06,  1.1978e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.8317e-06,  4.2439e-01,  3.7013e-02,  4.0159e-06,  8.9518e-06,\n",
            "        -1.7385e-05,  1.1381e-05,  1.1508e-05,  1.5803e+00, -1.0843e-05,\n",
            "        -1.9985e-05, -1.5123e-05,  1.1421e-05, -9.9087e-06,  1.3910e-05,\n",
            "         1.1455e-05,  6.2555e-06,  2.0233e-05, -5.9796e-06, -1.9334e-05,\n",
            "        -6.0414e-08, -1.5562e-05, -1.4879e-05,  1.5884e-05, -4.6293e-06,\n",
            "        -1.5459e-05, -4.7164e-06,  1.3426e-01,  1.6567e-05, -8.4210e-06,\n",
            "         9.7164e-07,  9.6011e-06,  1.8681e-05,  2.8744e-01, -8.2387e-06,\n",
            "         1.2813e-05, -1.8482e-05,  8.9747e-06, -3.7755e-06, -1.7901e-06,\n",
            "         2.0882e-05,  2.3416e-06, -9.4198e-07,  1.6788e-05,  3.8872e-06,\n",
            "         5.5577e-06, -4.4885e-06,  6.8573e-06,  1.8959e-05, -3.3607e-04,\n",
            "        -4.6930e-07, -5.5072e-06, -7.7316e-06,  1.4465e-05, -5.7362e-06,\n",
            "        -1.9623e-07, -1.4222e-04,  2.4338e-06,  1.3576e-05,  2.7433e-05,\n",
            "        -2.1896e-06,  4.9619e-06, -2.0264e-05,  1.2023e-05, -2.7102e-05,\n",
            "        -4.1397e-06, -2.1481e-05, -1.8136e-05,  1.6297e-05,  9.3032e-02,\n",
            "         4.3915e-06, -4.8636e-07, -3.8476e-06, -6.9200e-06, -7.5657e-06,\n",
            "        -4.5272e-06, -3.2436e-06, -1.6076e-05,  1.1800e-05, -1.7774e-03,\n",
            "        -3.6807e-06, -1.8076e-06, -3.1703e-06, -5.2707e-06, -1.2089e-05,\n",
            "         1.4761e-05,  8.6157e-06, -5.2108e-06,  2.3359e-05,  1.4007e-05,\n",
            "        -1.1461e-06, -6.2734e-06,  2.4501e-05,  1.1487e-05,  1.6281e-05,\n",
            "        -6.7229e-06,  7.2172e-06,  7.3528e-06, -4.3047e-07,  8.3022e-06,\n",
            "         3.2981e-04,  7.9912e-06, -2.8428e-05,  5.2145e-06,  1.4354e-05,\n",
            "        -1.7391e-05,  1.7827e-05, -4.2586e-06,  1.6197e-05, -5.0004e-06,\n",
            "         3.2385e-06,  3.5645e-06,  1.1413e-05, -8.2115e-06,  1.2531e-05,\n",
            "         3.2163e-05,  4.2190e-06, -1.3738e-05,  1.0714e-05, -1.4897e-06,\n",
            "         1.2619e+00, -2.5754e-06, -1.9526e-05, -1.2151e-05,  5.1322e-06,\n",
            "         3.9307e-06,  1.9761e-05, -5.7674e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-7.7648e-07,  8.3189e-05,  7.0885e-05,  ...,  1.2813e-05,\n",
            "         -7.3519e-06, -1.3680e-06],\n",
            "        [ 2.0255e-08, -1.9593e-06, -5.9446e-06,  ...,  3.6564e-06,\n",
            "         -2.0845e-05,  2.0556e-06],\n",
            "        [-2.4860e-05, -4.2422e-06, -1.0214e-06,  ..., -4.8357e-07,\n",
            "          2.5257e-06, -1.1636e-05],\n",
            "        ...,\n",
            "        [-5.5165e-06,  1.7593e-05,  1.4034e-05,  ..., -8.0641e-06,\n",
            "          1.0814e-05,  7.4262e-06],\n",
            "        [ 2.6465e-06,  2.3992e-04,  3.6904e-04,  ..., -3.6691e-06,\n",
            "         -4.4678e-06,  6.7034e-06],\n",
            "        [-3.1623e-06, -3.7913e-06, -7.9171e-06,  ...,  2.8276e-05,\n",
            "         -2.3420e-06, -5.5894e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3886e-02, -2.2402e-06,  2.9168e-05, -1.6176e-05,  2.3707e-05,\n",
            "         1.0711e-05, -6.4663e-06,  1.0952e-06, -1.3236e-06, -2.7767e-05,\n",
            "         2.7872e-07,  5.6104e-06,  1.1868e-05,  2.7812e-05, -8.6916e-06,\n",
            "        -1.5905e-05,  7.5462e-06, -3.9295e-06, -7.2276e-06,  5.9087e-06,\n",
            "        -2.7973e-06, -7.9014e-06,  8.8612e-06,  7.6496e-06, -3.9004e-05,\n",
            "         6.0378e-06, -1.1857e-05, -1.4126e-05,  3.5317e-05,  1.8747e-05,\n",
            "        -9.9765e-06,  6.7270e-06, -1.9861e-05, -9.6671e-08,  2.4638e-06,\n",
            "         3.3100e-06, -1.3052e-05,  1.2531e-05, -3.0451e-06,  1.5732e-05,\n",
            "        -1.2459e-05, -2.2964e-05,  1.6531e-05, -2.0985e-06,  2.5449e-05,\n",
            "        -1.1734e-05,  1.3646e-05, -1.0581e-05, -1.9437e-05, -2.5516e-05,\n",
            "        -1.9452e-05,  1.0849e+00,  6.1884e-06, -4.8037e-07, -1.4622e-05,\n",
            "         8.8939e-02, -3.9943e-06, -1.8436e-06, -2.9393e-05, -2.4395e-05,\n",
            "        -1.7214e-07, -2.6440e-05,  2.6000e-01,  1.4877e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3431e-01, -2.1626e-05, -4.1408e-06,  2.8281e-05,  7.8648e-06,\n",
            "          4.5792e-06, -1.0876e-05,  3.1414e-06, -9.7606e-06, -2.4800e-05,\n",
            "          3.3562e-05,  3.3938e-05, -9.7111e-06,  1.0067e-05,  5.5895e-06,\n",
            "         -4.2624e-05, -7.2951e-06, -1.6780e-05,  3.9681e-07,  1.5367e-06,\n",
            "         -6.4723e-06,  2.1750e-05,  1.0373e-05,  1.9079e-05,  5.4699e-01,\n",
            "          2.2642e-05, -3.0408e-05, -1.5794e-05, -1.2223e-05, -6.0048e-06,\n",
            "          2.6330e-05,  1.1252e-05,  3.5037e-06, -3.4028e-06,  1.0149e-05,\n",
            "         -3.5408e-06, -3.0193e-05, -1.5464e-05, -1.7276e-05, -2.1719e-05,\n",
            "          4.4469e-06,  9.0993e-06, -7.0201e-06,  2.9462e-05, -1.7872e-05,\n",
            "         -2.9424e-05, -2.5440e-05, -1.8510e-05, -2.1827e-05, -2.5055e-05,\n",
            "         -1.7149e-06,  3.2344e+00, -1.3899e-05,  2.6092e-05,  1.2720e-05,\n",
            "          7.8373e-01,  8.7997e-07,  9.5381e-06, -5.6951e-06, -1.8560e-06,\n",
            "         -1.9157e-05, -1.8212e-05,  1.0863e+00,  2.4014e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3099], requires_grad=True)\n",
            "l1_reg is: 30.218168258666992\n",
            "total_loss 1.0997023582458496\n",
            "pred: tensor([14.7023, 26.0076,  7.8716, 10.6551, 13.6077, 16.7325, 10.6689,  8.8883,\n",
            "        12.7304, 13.6530, 25.7649, 17.9999, 17.4328, 21.3411, 26.2140, 18.0105,\n",
            "        11.0238,  9.2034, 18.1314, 24.3234, 20.7212, 26.4683, 16.6022, 25.8771,\n",
            "        20.8420, 16.4744,  9.1840, 17.8528, 25.8991, 11.2710,  9.9500,  8.8285,\n",
            "        24.4651, 21.1422, 12.8295,  5.0443,  2.7059,  7.1913, 20.7514, 12.5598,\n",
            "        10.7479, 19.6001, 21.1641, 11.0460, 27.1352, 25.3406, 27.7025,  2.6848,\n",
            "        14.3855, 11.7109, 26.6310, 24.4835, 17.1834, 31.5518, 17.1586, 19.8704,\n",
            "        11.5103,  5.5502, 16.5330, 31.0601,  9.2368, 24.5386, 13.1340, 11.8947,\n",
            "        12.9563, 26.0246, 23.6411, 12.7407, 24.9100, 13.8603, 14.8393, 25.1756,\n",
            "        12.4736, 24.1672, 10.1725,  9.7263, 18.7807, 17.8479,  9.5097, 22.9488,\n",
            "        24.2263, 34.5335, 12.8219, 25.6773, 14.8820, 19.9727, 12.8876,  4.0062,\n",
            "        12.2879, 13.5551, 12.0487,  8.7811, 28.8705, 11.0239,  8.4647, 18.3432,\n",
            "        15.1404, 26.0210, 22.9036,  3.6742,  5.6941,  7.4065,  8.3818, 29.4567,\n",
            "         7.2806, 21.0898, 24.9478,  8.9116,  4.8246, 19.5485, 18.9574, 14.9624,\n",
            "         5.0096,  5.2476, 10.8669, 19.4333, 14.7374,  8.4581, 22.7039, 25.3333,\n",
            "         4.3158, 21.1544, 12.9121, 25.8643, 27.8955, 12.0965, 28.6782, 22.1829,\n",
            "        16.1287, 26.2126, 22.1245, 10.2907,  5.9396, 26.0882,  3.1249, 22.6933,\n",
            "        16.8111, 10.9885, 13.3864,  4.7971,  5.0042, 19.7600, 11.3379, 15.6081,\n",
            "        23.8556, 24.5072, 28.3879, 15.1014,  5.0591, 12.0877,  8.9731, 12.3748,\n",
            "        23.7498, 19.9638, 25.0985, 20.6461, 26.2407,  5.7655, 18.7384, 26.8247,\n",
            "        27.0258, 20.4803, 26.0901, 19.2821,  9.1174,  5.0139, 10.9609, 12.4736,\n",
            "        26.0232, 15.0960, 25.6776, 11.9197, 14.4360, 20.5208, 19.1219,  4.2157,\n",
            "        24.7818, 21.6572,  7.7765, 16.3226, 18.5157, 10.2089,  6.2085,  8.8493,\n",
            "        19.9714,  3.9248,  2.7676, 18.0554, 24.4562, 14.2843, 20.3236,  9.7517,\n",
            "         8.6847,  9.4876, 13.3635, 20.4040, 17.0210, 24.1800, 13.4874, 24.1442,\n",
            "        13.1388, 19.2550, 17.4435, 11.4997, 14.3396, 11.5504, 16.3617, 25.3997,\n",
            "        22.4964, 20.0327,  5.3892, 21.0857, 11.8300, 13.5090, 21.2801,  9.7506,\n",
            "        34.8724, 10.1680,  9.9696, 22.2182, 18.7241, 15.8786, 15.0491, 21.3237,\n",
            "        23.5984, 21.3957, 25.8605, 10.4340, 13.4485, 17.0355, 18.7358, 27.0618,\n",
            "        13.1421, 19.3490, 19.8075,  9.7563, 16.3683,  9.9110, 27.1612, 11.9814,\n",
            "        16.3217, 37.0825,  7.4298, 15.0393, 19.5686,  3.9862, 27.7742, 24.0950,\n",
            "        13.9789, 25.2072,  3.3498, 15.7268,  9.5191, 16.6451, 14.9460, 23.4184,\n",
            "        22.2715, 25.9232, 10.2274, 15.4755,  6.6666, 12.7170, 17.8694,  5.0712,\n",
            "        24.9153,  6.3155, 18.5547, 12.1145, 24.9617, 26.7667],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([14.3903, 24.3040,  8.4217, 10.3342, 15.1781, 15.7477, 10.5912,  8.9197,\n",
            "        12.0640, 12.7754, 28.4593, 18.6427, 15.6183, 21.5825, 27.4696, 15.9091,\n",
            "        11.5176,  8.6887, 18.8259, 25.1940, 21.1803, 26.5958, 18.0060, 24.8489,\n",
            "        19.9266, 15.0229,  9.4027, 17.5004, 24.4345, 11.8880,  8.9709,  9.9190,\n",
            "        23.4528, 23.0469, 13.2050,  5.5058,  2.3693,  7.6659, 20.5772, 11.2336,\n",
            "        10.2113, 19.3611, 19.7479, 11.4877, 27.5952, 25.3434, 27.9089,  2.7559,\n",
            "        14.6009, 12.5002, 25.9839, 23.6905, 15.3061, 30.6338, 18.1604, 18.8784,\n",
            "        10.2519,  5.3134, 15.9392, 27.8942,  9.5906, 22.4621, 12.3327, 11.8772,\n",
            "        12.7005, 26.6361, 23.9238, 13.7851, 25.2111, 13.4760, 14.3872, 26.0153,\n",
            "        12.1094, 23.1402, 10.5945,  8.6810, 18.2170, 17.3588,  8.9391, 22.6680,\n",
            "        23.7807, 34.9496, 12.2535, 24.9691, 14.3836, 19.5946, 12.2253,  4.3599,\n",
            "        14.1373, 14.3080, 13.5715,  9.3175, 27.0758, 10.5224,  7.5893, 17.3118,\n",
            "        15.1062, 25.8158, 21.4348,  4.4081,  6.0261,  7.8195,  9.5607, 29.8231,\n",
            "         6.4413, 21.8819, 24.4258,  8.9440,  4.0730, 20.9402, 18.5195, 14.0370,\n",
            "         4.9038,  5.0875, 11.5220, 19.0292, 15.4278,  8.9577, 24.4056, 24.9055,\n",
            "         4.7692, 20.5967, 14.4013, 25.9815, 28.4202, 11.2255, 27.6146, 20.6155,\n",
            "        15.2778, 24.6701, 21.5638, 10.7596,  4.7445, 24.9680,  2.9864, 21.6878,\n",
            "        16.1602, 10.2976, 13.3394,  4.9312,  4.6879, 19.5518, 11.3839, 15.6797,\n",
            "        25.9556, 23.7257, 28.4531, 17.0101,  5.1222, 12.3069,  9.0616, 13.2615,\n",
            "        24.1852, 19.5808, 24.2466, 21.2262, 25.3228,  5.8333, 18.6484, 28.9574,\n",
            "        26.0619, 20.1553, 24.8022, 18.8388, 10.3821,  5.4569, 10.7669, 13.7664,\n",
            "        25.1255, 16.0435, 24.0979, 11.6762, 14.5338, 20.2940, 18.5585,  5.4192,\n",
            "        25.3099, 20.9893,  8.7156, 14.4366, 18.7356, 10.3589,  6.6406,  8.8057,\n",
            "        20.0732,  3.3824,  2.8186, 19.6625, 23.9407, 11.3954, 19.2678,  9.5855,\n",
            "         8.4282,  9.1758, 13.9880, 20.5065, 16.8294, 24.2843, 13.5708, 24.7383,\n",
            "        13.3486, 19.2308, 16.3948, 12.3080, 14.6181, 12.6457, 17.0052, 25.8410,\n",
            "        22.3770, 18.9845,  4.8006, 19.3209, 11.8084, 13.2241, 19.6756, 11.5385,\n",
            "        33.9546, 10.0948,  9.9684, 23.3380, 19.9756, 13.8672, 13.5161, 19.8781,\n",
            "        24.1090, 22.4324, 23.3949,  9.6549, 13.4342, 15.4452, 19.1964, 25.0308,\n",
            "        13.5099, 19.2695, 19.2588, 10.0293, 14.8657,  8.5957, 29.4108, 11.1559,\n",
            "        15.2333, 36.7231,  6.9575, 15.0504, 18.8843,  4.1837, 25.5027, 24.2404,\n",
            "        13.0036, 24.9036,  3.4606, 15.8023,  9.1349, 17.0751, 15.6164, 21.3319,\n",
            "        22.3817, 25.0882, 11.2572, 15.4191,  6.9527, 12.6688, 18.4037,  5.3960,\n",
            "        24.4339,  7.1078, 17.1342, 13.1617, 26.7301, 25.7246])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.4393e-05, -2.3793e-05,  7.5769e-06,  ..., -3.8543e-06,\n",
            "         -1.1052e-06, -1.6767e-05],\n",
            "        [-5.1086e-06,  1.1307e-04, -9.6372e-06,  ...,  4.0494e-04,\n",
            "         -2.8287e-04, -7.8500e-04],\n",
            "        [ 2.9822e-05,  1.4566e-04, -4.6416e-05,  ...,  3.9250e-02,\n",
            "         -7.1434e-04, -3.0606e-03],\n",
            "        ...,\n",
            "        [-2.7854e-05,  6.7015e-08, -1.0445e-05,  ..., -1.2998e-05,\n",
            "         -1.4486e-05, -3.5104e-06],\n",
            "        [ 1.8724e-05,  9.4203e-06,  3.4165e-06,  ...,  2.3564e-06,\n",
            "          8.9907e-06, -2.3075e-05],\n",
            "        [-2.5928e-05,  1.7129e-05,  2.8233e-05,  ...,  5.3454e-06,\n",
            "          1.5354e-05, -1.9544e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.6205e-06,  4.2450e-01,  3.7533e-02, -8.5384e-06,  7.0246e-06,\n",
            "        -2.3970e-05,  1.1814e-05, -2.9696e-06,  1.5816e+00, -1.9528e-05,\n",
            "         4.7879e-06, -9.8488e-06,  1.7018e-05, -1.1867e-05,  9.2463e-08,\n",
            "         5.1521e-06, -2.3679e-06,  8.2685e-06,  3.7101e-06, -1.4461e-05,\n",
            "         4.2105e-06, -7.5004e-06, -2.4718e-05,  9.5573e-06, -8.7110e-06,\n",
            "        -1.3602e-06,  1.7653e-05,  1.3436e-01, -3.8365e-06, -6.5113e-06,\n",
            "         4.6357e-06,  1.3689e-05,  1.2627e-05,  2.8775e-01, -1.9283e-06,\n",
            "         1.4487e-05, -1.3520e-05,  2.7094e-06,  1.1929e-05,  1.6423e-06,\n",
            "         8.9253e-06, -1.6310e-05,  2.1725e-05, -2.9411e-06, -3.3913e-06,\n",
            "        -1.5185e-05,  4.2200e-06,  1.0937e-05,  2.7627e-05, -3.6636e-04,\n",
            "         3.0364e-06, -4.9573e-06, -1.1142e-05,  8.1529e-06, -1.4447e-05,\n",
            "         8.7800e-06, -4.0242e-04, -8.8892e-06, -1.9751e-06,  4.2264e-05,\n",
            "         4.2647e-06, -1.1195e-05, -2.8931e-05,  5.7248e-06, -1.5515e-05,\n",
            "         1.7043e-05, -3.1886e-05, -2.8229e-05,  1.4129e-05,  9.3019e-02,\n",
            "        -2.9093e-06,  1.7938e-05, -1.6572e-06,  4.6379e-06,  7.2522e-06,\n",
            "         1.8274e-05,  6.8767e-07, -2.4734e-05,  1.5880e-05, -1.5418e-03,\n",
            "        -2.3217e-06,  2.5764e-05,  7.3239e-06,  6.9634e-06, -5.8048e-06,\n",
            "        -4.9711e-06, -9.5938e-06,  1.5536e-05,  1.2336e-05, -5.7240e-06,\n",
            "        -6.1853e-07,  2.4039e-06,  2.2338e-05,  1.1930e-05,  1.3874e-05,\n",
            "         5.0081e-06, -3.0777e-08,  7.1661e-07,  2.2246e-05, -4.4125e-06,\n",
            "         4.5093e-04,  7.4524e-06, -2.7767e-05,  9.3328e-06, -1.0659e-05,\n",
            "        -1.8443e-05,  2.7918e-05, -3.7504e-06,  9.8833e-06, -9.0941e-06,\n",
            "         4.6785e-06,  1.5743e-05,  3.0432e-06, -6.2712e-06, -2.6691e-06,\n",
            "         3.1297e-05, -1.6537e-05, -1.8094e-05, -4.9850e-06,  1.2483e-05,\n",
            "         1.2627e+00,  8.3247e-06, -1.3823e-05,  8.6016e-06,  9.2644e-06,\n",
            "         1.2768e-07,  3.0301e-05, -1.3526e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.0519e-05,  1.9458e-04,  1.9994e-04,  ...,  1.4923e-05,\n",
            "          9.9834e-06, -4.3820e-06],\n",
            "        [-1.3747e-05, -9.5699e-06,  1.4808e-05,  ...,  7.7628e-06,\n",
            "         -1.8665e-05, -7.0522e-06],\n",
            "        [-1.2898e-05, -1.2013e-05,  1.0924e-05,  ...,  3.0940e-06,\n",
            "          6.4346e-06, -5.3314e-06],\n",
            "        ...,\n",
            "        [ 3.9790e-06,  1.2818e-05,  1.6707e-05,  ..., -8.1284e-06,\n",
            "          1.2808e-05,  1.6115e-05],\n",
            "        [-3.6160e-06,  4.3399e-04,  5.9361e-04,  ..., -2.1439e-06,\n",
            "         -2.4056e-07,  2.5402e-07],\n",
            "        [-6.3160e-06,  5.8898e-05,  4.7674e-05,  ...,  2.7608e-05,\n",
            "          1.1086e-05,  3.9478e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3977e-02,  9.0517e-06,  2.8482e-05, -1.3995e-05,  6.2103e-06,\n",
            "         1.8783e-06,  1.0860e-05, -1.5306e-05,  2.3716e-07, -1.6945e-05,\n",
            "        -1.3296e-05, -1.0055e-05,  1.4242e-05,  2.7128e-05, -6.7714e-06,\n",
            "         3.8436e-06, -5.2992e-06, -1.3318e-07,  1.0039e-05,  1.4597e-05,\n",
            "         9.1523e-06, -1.2002e-05, -5.1095e-07,  8.1070e-06, -2.3325e-05,\n",
            "         9.3329e-06, -1.7755e-05,  6.3301e-06,  3.8202e-05, -6.8544e-07,\n",
            "        -9.4218e-06,  2.9277e-06, -1.3592e-05,  9.3664e-06,  6.5672e-06,\n",
            "         1.8536e-06,  7.7245e-07, -1.9376e-06, -6.0800e-06,  2.8901e-05,\n",
            "        -5.0016e-07, -1.8280e-05,  1.0674e-05,  1.5858e-05,  2.4511e-05,\n",
            "         2.7388e-06,  1.6212e-05,  3.8930e-06, -1.7251e-05, -4.0282e-05,\n",
            "        -5.4406e-06,  1.0860e+00, -1.0854e-05,  2.9789e-06, -1.8851e-05,\n",
            "         8.9118e-02,  1.3392e-05,  1.1574e-05, -2.8857e-05, -1.2434e-05,\n",
            "         1.5497e-05, -2.8304e-05,  2.6028e-01,  6.5994e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3422e-01, -9.6153e-06,  4.0086e-07,  3.0115e-05, -1.2292e-06,\n",
            "          1.6374e-07, -1.6427e-05,  1.0881e-05, -9.5881e-06, -2.1118e-05,\n",
            "          2.5210e-05,  3.5785e-05, -1.3774e-05,  3.7733e-06, -4.0596e-06,\n",
            "         -4.8389e-05,  3.2191e-06, -1.7825e-05, -6.4924e-06, -6.4235e-06,\n",
            "         -7.4479e-06,  1.9605e-05,  1.0639e-06,  1.4304e-05,  5.4689e-01,\n",
            "          9.5175e-06, -3.2281e-05, -9.8581e-06,  3.4561e-06,  1.3077e-06,\n",
            "          2.8176e-05,  1.6809e-05,  4.9359e-06, -1.2602e-06,  1.5511e-05,\n",
            "          1.0570e-06, -2.8438e-05, -1.9563e-05, -3.0723e-06, -8.3968e-06,\n",
            "          5.9526e-06, -1.4098e-06,  2.1739e-06,  6.5678e-06, -1.1526e-05,\n",
            "         -2.8874e-05, -1.4605e-05,  9.2412e-07, -2.3278e-06, -1.4269e-05,\n",
            "          1.9589e-05,  3.2364e+00, -1.6531e-05,  2.3942e-05, -2.9529e-06,\n",
            "          7.8370e-01, -1.0609e-05, -6.1516e-06, -1.8978e-06,  1.1555e-05,\n",
            "         -5.2434e-06,  1.2187e-06,  1.0865e+00,  2.4004e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3101], requires_grad=True)\n",
            "l1_reg is: 30.25792121887207\n",
            "total_loss 1.2145040035247803\n",
            "pred: tensor([ 3.3688, 13.4991,  7.1289, 21.5018,  6.6658, 20.2463, 19.3203, 11.9542,\n",
            "        23.2153,  6.4513, 24.6147, 22.0593, 14.2521, 14.5031,  8.9221, 15.7129,\n",
            "        24.4807,  7.6705,  8.9707,  5.1994, 15.5887,  8.4287,  6.2088, 24.8881,\n",
            "        16.7773, 11.3871,  2.7861,  9.1221, 16.6091, 15.8020, 26.1790, 13.3983,\n",
            "        12.1599, 30.0339,  5.4990,  3.3680, 13.8300, 26.9414, 15.0155, 21.9215,\n",
            "        12.5445, 14.4856, 10.9224, 22.7713, 23.9272,  8.2694,  9.3049, 13.8238,\n",
            "        10.7022, 27.3070,  7.3389, 25.9130, 20.8068,  7.9607, 18.0399, 10.5204,\n",
            "        12.9890, 26.0837, 24.3746, 16.0875,  9.4322, 20.4465, 13.6967, 10.9115,\n",
            "        20.4306, 22.9502,  9.8572, 27.1065, 17.0785, 15.2456, 27.2214, 24.7000,\n",
            "        10.4463, 24.0940,  5.4348,  9.1662,  6.5448, 18.8988,  7.0383, 23.2828,\n",
            "         3.0227,  9.8506,  3.6637, 25.8917, 18.4334,  6.4436, 21.9169, 19.8096,\n",
            "        11.7471, 25.1223,  2.9977,  6.1599, 13.5088, 21.7063, 20.2372, 12.5810,\n",
            "        13.5779, 25.3898, 26.8120, 25.1683, 15.8750, 21.5382, 22.7267, 11.9005,\n",
            "        16.4262, 16.4052, 13.4694, 21.9932, 20.5195,  3.0895, 23.5911, 14.4997,\n",
            "        12.6759, 18.8342, 22.7084,  7.5104,  7.3585, 14.0528, 31.3534,  4.0384,\n",
            "         8.1855, 19.8085,  2.9939, 16.0434,  4.6669, 15.4607, 24.9233,  8.3815,\n",
            "        16.4305, 26.8704,  6.1862, 23.5927, 13.3948, 25.8317,  9.6694, 12.7842,\n",
            "         6.2969,  7.3396, 15.9159, 26.7419, 19.0001, 10.0339, 23.0483, 21.0005,\n",
            "         7.7223, 22.0828, 25.3294, 10.1403, 22.6308, 12.3505, 21.5972, 10.8744,\n",
            "        12.7370, 11.1556,  9.5295, 30.7505, 26.8269, 17.3484, 21.0248,  6.4925,\n",
            "        18.3203,  4.2628, 27.8423, 10.1015, 10.6127, 19.9369, 23.8321, 12.4783,\n",
            "        10.9257, 13.5379, 14.9422, 11.1397, 25.7990,  5.7343, 16.8124,  5.3287,\n",
            "        31.3335, 34.7980, 17.2419,  7.9881, 19.8095, 25.8263, 14.0901,  9.1409,\n",
            "         6.9238, 22.3302, 10.0878, 28.9145, 12.5662,  3.7611, 25.3426,  9.6692,\n",
            "        26.0584, 23.6972, 17.8635, 12.1780,  5.7734, 12.5486, 22.3560, 13.3250,\n",
            "        12.6883, 23.8047,  5.3094, 20.6633, 18.8058, 19.7230, 17.2285, 27.6396,\n",
            "        13.5302, 10.7812, 29.1366,  5.5721, 27.3235,  7.7885, 10.2683, 12.7871,\n",
            "        25.3174, 24.1291,  9.5829,  6.9396, 13.1788, 23.8565,  9.9103, 12.6761,\n",
            "        12.1416, 17.6292, 24.9946, 21.1087,  3.2593,  8.7924,  4.8837,  9.0540,\n",
            "        18.2756, 31.2928, 20.3208,  5.1404, 17.1234, 14.4452, 26.4061, 16.1479,\n",
            "        21.3262, 26.4824, 21.5554,  8.7716, 11.5852, 27.1632, 16.6123, 12.1287,\n",
            "         8.4558, 27.7740,  5.6232, 20.8135,  9.9548, 13.3958, 11.1905, 20.4360,\n",
            "        18.7895, 11.1108, 14.2088, 36.4861, 17.3728,  2.7164, 16.6559, 26.5209,\n",
            "         8.5641, 18.1340, 29.2976,  5.3661, 25.2053, 16.7614],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([ 2.7879, 14.9485,  6.8889, 22.1484,  6.1372, 20.8847, 18.7337, 11.8580,\n",
            "        23.4524,  7.5861, 24.0307, 23.7777, 15.7830, 14.8030,  8.7883, 14.7400,\n",
            "        25.8186,  7.5309,  8.8574,  5.6280, 15.9655,  8.3333,  6.6757, 23.0245,\n",
            "        17.1327, 12.5390,  2.7578,  8.9869, 17.2330, 15.7150, 24.7987, 13.4445,\n",
            "        12.5605, 29.6610,  5.4799,  3.6318, 13.6426, 25.6844, 15.4301, 21.7220,\n",
            "        12.8571, 14.1325, 10.4752, 23.2301, 24.1348,  9.0476, 10.0308, 13.2633,\n",
            "        11.6045, 27.6089,  7.7907, 26.2010, 21.1793,  8.1948, 19.6065,  8.9404,\n",
            "        11.9179, 26.6844, 22.8612, 15.1712,  9.5583, 21.4280, 13.4101, 11.0834,\n",
            "        16.5860, 24.1517, 11.1971, 26.0680, 15.3266, 13.7928, 26.5838, 25.1929,\n",
            "        11.8498, 24.1904,  5.9698,  9.3660,  6.0484, 18.6713,  6.9288, 23.7068,\n",
            "         2.6391, 10.0550,  3.8793, 22.6075, 17.9984,  6.1916, 22.1074, 15.5303,\n",
            "        11.5707, 24.6225,  2.9360,  5.6287, 13.1363, 21.5185, 19.9225, 13.0259,\n",
            "        12.5295, 25.9682, 25.1932, 24.6485, 15.0994, 21.2428, 22.6469, 11.7231,\n",
            "        15.4962, 15.3179, 14.3454, 22.0329, 20.2477,  2.9352, 24.4875, 16.1818,\n",
            "        12.7256, 17.5585, 22.7183,  7.9269,  6.7536, 10.8209, 30.7632,  3.8066,\n",
            "         8.7530, 19.8536,  3.3051, 16.7753,  5.3297, 16.4813, 25.2709,  7.4477,\n",
            "        16.3600, 26.3172,  7.0304, 22.9592, 13.5415, 25.3183,  9.4427, 11.8230,\n",
            "         6.6014,  5.9441, 14.6409, 26.3140, 18.9118,  9.4371, 24.0158, 21.5556,\n",
            "         9.0463, 21.3608, 25.0183, 10.3358, 21.3269, 12.0725, 22.3171, 11.1391,\n",
            "        13.3920, 11.3396,  9.7919, 30.5375, 26.5404, 18.2323, 20.3187,  7.1181,\n",
            "        18.2666,  4.5723, 24.9986,  9.1693, 10.2318, 20.3410, 22.0525, 10.7577,\n",
            "        11.1362, 14.4099, 14.2462, 11.7894, 26.5690,  6.3559, 17.3588,  5.1471,\n",
            "        31.9832, 33.7301, 14.9121,  9.1015, 20.3797, 24.1689, 13.9387,  8.6658,\n",
            "         6.6964, 22.5318,  9.9701, 28.8653, 11.1608,  3.3276, 24.3948,  9.3623,\n",
            "        25.5347, 23.7640, 16.7125, 12.0462,  6.0052, 12.1004, 22.4144, 13.9191,\n",
            "        12.1835, 24.2089,  5.3072, 20.9184, 20.0433, 18.9278, 18.8468, 27.9312,\n",
            "        13.9587, 11.9047, 25.2593,  5.2606, 23.7784,  7.8005, 10.4907, 13.0728,\n",
            "        23.7457, 22.2416, 10.3949,  5.6818, 12.9458, 25.2080, 10.5809, 13.2304,\n",
            "        13.0026, 16.9475, 25.7940, 19.8605,  3.0383,  9.2650,  5.3867,  8.8821,\n",
            "        18.1217, 26.6320, 19.6751,  5.9224, 17.0786, 14.7196, 26.2702, 16.2624,\n",
            "        21.0684, 25.8740, 22.0973,  8.7828, 12.1160, 26.4274, 18.5327, 11.3941,\n",
            "         8.9872, 27.0749,  5.3610, 22.1461,  9.3224, 12.6670, 13.1338, 20.1714,\n",
            "        20.6139, 12.4807, 13.9843, 35.1006, 17.3858,  2.7512, 15.5819, 25.8174,\n",
            "         8.2796, 17.7139, 29.4770,  5.8161, 25.2360, 15.4295])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.0618e-05, -1.1829e-05,  1.1002e-05,  ..., -7.9645e-06,\n",
            "          1.4559e-05, -1.7771e-05],\n",
            "        [ 2.8888e-05,  1.0588e-04, -2.3835e-05,  ...,  4.1519e-04,\n",
            "         -2.7382e-04, -8.7113e-04],\n",
            "        [ 1.7239e-05,  1.7581e-04, -5.3362e-05,  ...,  3.9098e-02,\n",
            "         -1.2203e-03, -3.3994e-03],\n",
            "        ...,\n",
            "        [-1.7241e-05, -1.5649e-05, -3.5122e-06,  ..., -1.0529e-05,\n",
            "         -6.3355e-06, -2.3800e-07],\n",
            "        [ 2.7416e-05, -9.4943e-07,  4.8520e-06,  ..., -1.3330e-05,\n",
            "          9.7274e-06, -1.8388e-05],\n",
            "        [-3.0435e-06,  2.3034e-05,  1.7751e-05,  ..., -4.1588e-06,\n",
            "          1.3186e-05, -2.8208e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.0248e-06,  4.2441e-01,  3.7543e-02, -9.8425e-06, -4.7138e-06,\n",
            "        -1.9900e-05,  2.2044e-06, -6.0001e-06,  1.5816e+00, -1.7343e-05,\n",
            "         1.7087e-05,  4.8983e-06,  1.2050e-05, -3.6220e-06, -2.2343e-05,\n",
            "        -1.0506e-05, -1.4626e-07, -1.2504e-05,  2.4324e-06, -7.3859e-08,\n",
            "        -1.9536e-06,  9.7546e-06, -2.3574e-05, -6.1329e-06, -2.3834e-06,\n",
            "         2.1326e-05,  2.7785e-05,  1.3423e-01, -1.2201e-05,  5.2064e-06,\n",
            "        -2.0646e-06,  7.3442e-06, -2.8174e-06,  2.8775e-01,  1.3750e-05,\n",
            "         5.9949e-06,  9.6666e-07, -1.2924e-05,  1.6053e-05, -5.2488e-06,\n",
            "        -1.1836e-05, -2.3097e-05,  3.2127e-05, -1.0702e-05,  5.7718e-08,\n",
            "        -2.3857e-05,  2.0551e-06,  4.6086e-06,  2.5423e-05, -3.8811e-04,\n",
            "        -3.7965e-06,  5.5651e-06, -4.2096e-06, -7.5191e-06, -1.2288e-05,\n",
            "         6.8552e-06, -5.1536e-04, -9.0718e-06, -5.9865e-06,  4.5588e-05,\n",
            "         5.7041e-08, -1.5749e-05, -2.6730e-05, -9.9424e-06,  4.9076e-06,\n",
            "         2.6104e-05, -3.1250e-05, -2.7321e-05,  2.1894e-06,  9.2888e-02,\n",
            "         5.2098e-07,  2.4525e-05,  1.0311e-05,  5.0423e-06,  1.0594e-05,\n",
            "         2.8798e-05, -5.7704e-06, -2.2529e-05,  9.5489e-06, -1.5384e-03,\n",
            "         8.8996e-06,  4.0576e-05,  6.7709e-06,  7.9741e-06,  9.8528e-06,\n",
            "        -1.2736e-05, -1.5983e-05,  2.4210e-05, -7.5860e-06, -1.3524e-05,\n",
            "         9.8567e-06,  2.2102e-07,  1.0376e-05,  2.3277e-06,  1.7258e-06,\n",
            "         5.5637e-06,  3.4332e-06, -1.5254e-05,  3.2653e-05, -5.8628e-06,\n",
            "         3.9430e-04, -3.0325e-06, -1.7169e-05,  3.0403e-06, -2.3170e-05,\n",
            "        -9.3883e-06,  2.7004e-05,  6.7050e-06, -5.8030e-06, -2.7743e-06,\n",
            "        -4.0253e-06,  1.6701e-05, -1.4489e-05,  5.4756e-06, -6.3487e-06,\n",
            "         2.0516e-05, -2.5208e-05, -1.2014e-05, -9.1172e-06,  1.5050e-05,\n",
            "         1.2626e+00,  8.1314e-06,  1.3140e-06,  1.7267e-05,  3.0027e-06,\n",
            "        -1.3298e-05,  2.9780e-05, -1.0513e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.9668e-05,  1.7479e-04,  1.9321e-04,  ...,  6.8119e-06,\n",
            "          1.5569e-05,  2.8988e-06],\n",
            "        [-1.6138e-05, -6.4195e-06,  2.3486e-05,  ...,  1.4586e-06,\n",
            "         -6.7030e-06, -5.2492e-06],\n",
            "        [ 7.8674e-06, -9.0066e-06,  1.1675e-05,  ..., -3.6861e-06,\n",
            "         -4.7274e-08,  1.0342e-05],\n",
            "        ...,\n",
            "        [ 2.5249e-06, -1.4797e-06,  9.1126e-06,  ...,  1.8138e-06,\n",
            "          4.6022e-06,  1.3935e-05],\n",
            "        [ 7.1284e-07,  3.7486e-04,  5.5615e-04,  ...,  9.2089e-06,\n",
            "          1.3531e-05, -1.5564e-05],\n",
            "        [ 8.3794e-07,  5.5875e-05,  3.6988e-05,  ...,  1.7003e-05,\n",
            "          1.3163e-05,  2.5283e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3891e-02,  9.2145e-06,  1.7865e-05, -2.0399e-06, -1.9537e-05,\n",
            "        -1.6071e-05,  1.6459e-05, -2.0067e-05, -8.3581e-06,  2.7964e-06,\n",
            "        -1.5516e-05, -1.4155e-05,  6.3786e-06,  1.6510e-05,  4.9572e-06,\n",
            "         1.1618e-05, -6.8600e-06,  1.3286e-05,  1.5579e-05,  1.2417e-05,\n",
            "         9.9091e-06, -5.6969e-06,  1.0538e-06, -1.4814e-06,  7.8615e-07,\n",
            "         2.2958e-06, -1.3051e-05,  1.4740e-05,  3.0797e-05, -8.1743e-06,\n",
            "         1.0704e-06, -1.0493e-05,  2.0500e-06,  7.8831e-06,  2.6035e-07,\n",
            "        -9.4570e-06,  3.2182e-06, -4.9527e-06,  1.1893e-06,  3.0756e-05,\n",
            "         2.0261e-05, -4.0637e-06, -4.5980e-06,  2.2020e-05,  1.3670e-05,\n",
            "         5.7728e-06,  8.5266e-06,  6.9200e-06, -5.2824e-06, -4.3572e-05,\n",
            "         1.7169e-05,  1.0859e+00, -1.6192e-05, -3.9144e-06, -1.2657e-05,\n",
            "         8.9038e-02,  1.9039e-05,  1.3651e-05, -1.8373e-05,  8.3282e-06,\n",
            "         1.9601e-05, -1.9981e-05,  2.6021e-01,  3.1187e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3411e-01,  1.1194e-05, -5.5137e-06,  2.1758e-05,  5.8154e-07,\n",
            "         -1.3810e-05, -1.1430e-05,  7.8468e-06,  5.6709e-07, -7.8091e-06,\n",
            "          7.6919e-06,  2.7447e-05, -7.4306e-06, -1.1900e-05, -2.7443e-06,\n",
            "         -4.3578e-05,  2.6817e-06, -8.7660e-06, -2.6927e-06, -3.5873e-06,\n",
            "          1.6673e-06,  7.6711e-06, -1.7324e-05,  6.0221e-09,  5.4679e-01,\n",
            "         -1.2328e-05, -2.3978e-05,  5.4843e-06,  7.5517e-06, -2.1110e-06,\n",
            "          1.9836e-05,  1.1806e-05, -3.7752e-06,  1.0669e-05,  1.0337e-05,\n",
            "         -4.8045e-06, -1.6861e-05, -1.3255e-05,  1.9707e-05,  1.3567e-05,\n",
            "         -2.7014e-06, -8.7514e-07,  4.4813e-07, -2.4037e-05,  4.1739e-06,\n",
            "         -1.8393e-05,  5.1372e-06,  8.4151e-06,  2.5216e-05,  5.4381e-06,\n",
            "          2.8763e-05,  3.2361e+00, -8.8992e-06,  1.1994e-05, -7.0588e-06,\n",
            "          7.8360e-01, -1.0947e-05, -1.0285e-05,  1.1500e-05,  1.3616e-05,\n",
            "          1.7263e-05,  8.7059e-06,  1.0864e+00,  2.3994e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3100], requires_grad=True)\n",
            "l1_reg is: 30.247411727905273\n",
            "total_loss 1.3094393014907837\n",
            "pred: tensor([12.9394, 26.3049,  9.8715, 24.7007, 20.9207, 19.6284, 15.4802, 21.8631,\n",
            "        12.3511, 16.6146, 23.9350, 16.9403, 13.4700, 14.7580,  7.9895, 26.0191,\n",
            "        10.9090,  6.7191, 12.8583, 20.2291, 14.5314,  5.3995, 13.3930, 11.3950,\n",
            "        16.3489, 21.9095,  3.7366,  8.7078, 33.1261, 22.4715, 21.3984, 12.2316,\n",
            "         5.1664, 18.9984, 11.5941, 16.7411, 12.0961, 26.2721, 12.9055,  6.9383,\n",
            "        20.3822, 16.0467, 10.8488, 11.3585, 13.2800,  5.6229, 24.4318, 11.4991,\n",
            "         9.9319, 13.3124,  7.1505,  8.7580,  9.7354, 24.4244, 17.6465, 24.0161,\n",
            "         3.8172, 30.0715, 10.6313, 13.7959, 26.6793, 20.1311,  9.4443, 22.3253,\n",
            "         9.5540, 16.5729, 27.2400, 24.2220, 14.4504, 15.9261, 10.1883, 15.3978,\n",
            "        13.6919, 20.2374, 18.1372, 18.6977,  8.1527, 18.1090, 32.9268, 10.6513,\n",
            "        13.6094, 21.9429, 20.6477,  8.0205, 13.2037, 25.9732,  3.1898, 28.4813,\n",
            "        23.7779,  5.8710, 24.8286,  9.4842, 13.9946,  8.3407, 29.5248, 19.3569,\n",
            "        16.0737, 15.2848, 11.8433, 13.7713, 13.6602, 11.5035,  9.3632, 21.8615,\n",
            "        24.2974,  9.3070, 22.1634, 20.5561,  7.3026, 12.5285, 12.2299, 21.3072,\n",
            "        20.0841,  5.1160, 18.4664, 26.5708,  9.1660, 12.8013, 25.8848, 13.2012,\n",
            "        21.5793, 15.5006, 29.8597, 20.9241, 11.0685, 13.4099, 15.3219, 23.8442,\n",
            "        14.9106,  5.5821, 16.5720,  6.7545, 11.0423, 15.2043, 25.6949,  8.1642,\n",
            "        12.6936,  9.5451,  4.8202, 26.2305, 20.7774, 12.7718, 23.3627, 19.8116,\n",
            "        17.5068, 10.1757, 32.9093,  9.3917,  6.0027,  2.9818,  5.9902, 31.0700,\n",
            "        29.1362, 20.6439, 19.5194, 23.2299, 20.2778, 22.2321, 25.3239, 16.5131,\n",
            "        24.9585, 25.1221, 17.8923, 24.2286, 15.7059,  8.9380, 21.1590, 10.8804,\n",
            "        16.7448, 14.5405,  7.1850, 21.2936, 21.0172, 22.7562, 13.3404, 13.9492,\n",
            "         2.8690, 28.2297, 20.2444, 25.3511, 21.3851, 25.4887, 13.3689,  6.9861,\n",
            "        20.1206,  9.7294, 25.7515, 15.7660, 24.1567, 20.6261, 13.6603, 23.1335,\n",
            "         5.3803, 24.1537,  5.4057, 10.2842, 24.8573, 10.5010, 23.2394, 27.6961,\n",
            "        21.4651, 15.6833, 13.3589, 28.0564,  8.3302,  3.6870,  6.4579, 18.6334,\n",
            "        15.4469, 13.6729, 26.0927, 24.0372,  7.3599, 25.2284,  6.0827, 15.6803,\n",
            "         7.2680, 32.9998, 11.5686, 13.8165,  9.4824, 11.8056,  7.5527, 19.3883,\n",
            "        10.0565, 15.6816, 12.3293, 21.5671, 29.3259, 25.3396, 20.7889, 19.7481,\n",
            "        13.4554, 23.0489, 12.7571, 10.6542, 12.5107, 13.6789,  6.7778, 22.0082,\n",
            "        23.8276,  3.1384, 24.8134,  4.4385, 11.1071, 24.9796, 27.3949, 16.8647,\n",
            "        19.7557, 21.6358,  8.4368, 17.1785,  8.9310, 27.5799, 10.7314, 15.0339,\n",
            "        25.7309, 12.3360, 13.0511,  9.4131, 26.3041, 31.8460, 16.9950,  7.7467,\n",
            "         2.8849, 13.7986,  7.1771, 15.8099, 33.5757, 34.6397],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([13.3160, 25.4348,  9.9276, 25.4691, 18.3412, 19.0391, 16.4102, 22.4990,\n",
            "        10.0535, 16.9849, 23.6816, 18.5775, 14.1129, 16.3921,  8.5520, 25.9019,\n",
            "        10.9784,  6.3559, 11.8335, 21.1737, 13.9031,  5.5369, 13.1820, 12.0150,\n",
            "        16.0910, 22.7647,  4.7581,  7.5058, 33.9020, 21.5116, 21.9697, 11.6519,\n",
            "         5.6160, 19.3056, 11.0963, 17.1899, 12.2768, 26.3706, 13.1766,  6.9034,\n",
            "        21.3147, 17.0447, 10.3015, 11.8142, 13.0089,  5.0197, 24.3549, 11.1512,\n",
            "         9.7607, 15.5242,  7.5682,  9.3464, 11.0962, 24.4311, 17.4472, 25.3326,\n",
            "         3.1969, 29.0246, 10.2621, 14.2595, 24.9590, 20.6560,  9.4932, 22.2169,\n",
            "        10.5634, 17.3989, 27.2075, 25.8145, 15.0729, 17.5345, 10.0148, 15.2284,\n",
            "        12.5427, 20.5263, 16.5177, 18.5266,  8.1708, 18.6717, 30.6897, 10.8994,\n",
            "        13.4557, 22.6352, 20.2473,  8.5251, 11.6972, 25.9189,  2.9032, 29.6881,\n",
            "        24.0977,  7.2487, 24.9279,  9.8565, 13.9722,  7.4995, 30.0807, 18.5950,\n",
            "        15.7567, 15.3680, 11.9079, 15.1367, 14.0291, 11.6967,  9.5773, 21.9080,\n",
            "        24.5242,  9.8642, 20.0336, 20.1877,  5.9859, 12.4772, 13.3624, 20.4727,\n",
            "        19.7417,  5.7261, 18.4029, 27.3015,  9.0185, 13.0247, 26.1270, 12.9086,\n",
            "        21.5198, 15.7985, 29.1736, 21.7023, 10.8934, 13.9302, 15.8711, 23.9214,\n",
            "        15.1882,  6.0089, 16.0898,  7.3566, 11.3383, 14.6036, 25.5564,  7.3750,\n",
            "        12.9687,  8.7021,  4.7945, 25.8165, 20.1811, 12.7826, 23.8618, 20.5191,\n",
            "        19.0511,  9.5076, 35.8095,  9.4792,  5.4318,  2.4374,  5.8006, 29.7360,\n",
            "        29.9533, 18.7199, 19.0364, 25.3044, 18.4755, 22.0620, 27.0168, 16.6667,\n",
            "        24.5022, 25.8577, 17.1996, 24.4859, 16.0401,  8.7413, 21.1683, 10.6579,\n",
            "        15.3333, 14.6175,  6.7568, 23.3032, 19.6574, 21.4063, 13.5933, 13.0953,\n",
            "         3.2285, 29.0553, 19.9239, 25.3752, 20.1764, 25.7795, 12.3529,  6.1983,\n",
            "        19.4142, 10.3742, 25.6052, 16.1682, 25.2021, 21.0445, 14.8030, 23.1116,\n",
            "         5.8940, 23.2718,  5.7059,  9.2334, 24.2957, 11.0325, 22.8251, 26.6905,\n",
            "        19.9257, 17.1809, 13.8869, 29.3294,  7.6803,  3.8390,  6.0086, 18.5107,\n",
            "        16.0182, 14.5650, 25.5729, 23.6043,  6.9896, 25.7552,  6.1239, 16.1270,\n",
            "         7.1256, 33.6783, 12.6669, 12.1542, 10.0034, 11.8489,  7.9767, 17.3852,\n",
            "        10.5818, 15.1990, 13.0363, 22.3123, 27.6612, 26.7724, 19.7423, 18.9801,\n",
            "        13.9020, 22.6298, 12.3064, 10.2741, 13.1175, 13.4997,  6.9184, 23.4177,\n",
            "        24.2925,  3.2051, 24.7865,  3.2394, 10.8996, 24.4827, 25.9028, 15.9357,\n",
            "        20.6294, 21.9609,  8.2677, 17.7887,  9.7285, 26.7766, 10.1237, 15.8497,\n",
            "        25.7552, 11.6684, 12.0427, 10.7143, 27.0808, 32.4405, 19.2529,  7.1776,\n",
            "         2.6932, 14.0352,  7.5116, 17.5000, 32.6948, 33.9005])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 7.2178e-06,  8.9363e-06,  4.0859e-06,  ..., -1.6648e-06,\n",
            "          1.8666e-05, -8.6724e-06],\n",
            "        [ 4.3106e-06,  4.0760e-05, -2.1292e-05,  ...,  4.5226e-04,\n",
            "          1.3419e-05, -9.0178e-04],\n",
            "        [-1.2529e-04,  7.3225e-05, -4.9613e-05,  ...,  3.8905e-02,\n",
            "         -1.1240e-03, -3.7302e-03],\n",
            "        ...,\n",
            "        [ 2.3116e-06, -1.9794e-05,  1.2728e-05,  ...,  1.6920e-06,\n",
            "          1.1003e-05,  1.2704e-05],\n",
            "        [ 2.5239e-05, -2.8323e-07, -3.8559e-06,  ..., -1.7448e-05,\n",
            "          3.9473e-07, -4.1698e-06],\n",
            "        [ 2.7556e-05,  1.8351e-05, -1.6840e-06,  ..., -2.7133e-06,\n",
            "          1.2228e-06, -2.6014e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 2.5046e-06,  4.2417e-01,  3.6877e-02, -1.0165e-06, -5.2836e-06,\n",
            "        -6.2402e-06, -1.6445e-05,  1.2733e-06,  1.5805e+00, -5.3817e-06,\n",
            "         1.8165e-05,  8.1718e-06, -2.4243e-06,  1.3799e-05, -3.2546e-05,\n",
            "        -1.4597e-05,  1.1839e-05, -2.1211e-05, -8.7159e-06,  2.2870e-05,\n",
            "         2.4922e-06,  1.5283e-05, -1.2529e-05, -1.0253e-05,  1.3317e-05,\n",
            "         3.1743e-05,  2.6903e-05,  1.3392e-01, -9.7299e-06,  5.7525e-06,\n",
            "         1.9067e-06, -8.3737e-06, -6.7105e-06,  2.8742e-01,  1.7860e-05,\n",
            "        -1.1648e-05,  3.9945e-06, -1.6990e-05,  9.7779e-06, -1.4529e-06,\n",
            "        -2.0517e-05, -1.9205e-05,  3.1490e-05, -7.6861e-06, -6.8399e-06,\n",
            "        -2.1673e-05, -9.8937e-06, -1.1082e-05,  1.3439e-05, -4.0744e-04,\n",
            "         6.2066e-08,  5.0520e-06,  1.2026e-05, -1.1622e-05, -3.4224e-07,\n",
            "        -4.8956e-06, -4.9924e-04,  7.5782e-07,  3.9811e-07,  3.8559e-05,\n",
            "        -1.3730e-05, -9.8449e-06, -1.4750e-05, -1.4043e-05,  1.3284e-05,\n",
            "         2.4255e-05, -2.0678e-05, -1.6514e-05, -1.8556e-05,  9.2658e-02,\n",
            "        -6.3939e-06,  2.0467e-05,  1.1078e-05, -4.5921e-06,  3.6024e-06,\n",
            "         2.8268e-05, -1.5785e-06, -1.0535e-05, -6.1507e-06, -1.7966e-03,\n",
            "         8.9991e-06,  4.3907e-05, -3.7168e-06, -1.1101e-06,  1.3940e-05,\n",
            "        -9.7187e-06, -1.1732e-05,  2.2016e-05, -1.5513e-05, -1.0565e-05,\n",
            "         9.2780e-06, -1.1747e-05, -1.0376e-05, -1.6315e-05, -1.9203e-05,\n",
            "        -3.9345e-06, -3.4642e-06, -1.9628e-05,  3.2020e-05,  2.8242e-06,\n",
            "         1.3291e-04, -2.4700e-06,  2.3743e-06, -1.2632e-05, -2.4431e-05,\n",
            "         8.7615e-06,  1.6183e-05,  6.1147e-06, -9.9203e-06,  1.2913e-05,\n",
            "        -1.8540e-06,  7.5595e-06, -2.0267e-05,  6.0533e-06,  3.3785e-07,\n",
            "         8.0690e-07, -2.3012e-05,  3.4552e-06, -2.8351e-06,  7.3589e-06,\n",
            "         1.2619e+00, -2.0419e-06,  4.9282e-06,  1.5051e-05, -1.2601e-05,\n",
            "        -1.5375e-05,  1.9307e-05,  2.2118e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.7884e-05,  2.6550e-05,  2.7027e-05,  ..., -1.0486e-05,\n",
            "          1.0576e-05, -5.6086e-07],\n",
            "        [-8.2902e-06,  6.4157e-06,  2.1295e-05,  ..., -1.4215e-05,\n",
            "          1.4063e-05,  6.3735e-06],\n",
            "        [ 1.6556e-05,  3.7004e-06,  2.3524e-06,  ...,  2.1173e-07,\n",
            "          4.1190e-06,  1.4449e-05],\n",
            "        ...,\n",
            "        [-8.7837e-06, -4.3478e-06, -7.7229e-06,  ...,  7.6174e-07,\n",
            "         -1.2783e-05,  1.9737e-06],\n",
            "        [-5.4267e-06,  6.6671e-05,  2.0706e-04,  ...,  9.4299e-06,\n",
            "          1.5885e-05, -1.9825e-05],\n",
            "        [-2.7313e-06, -1.0954e-05, -5.0073e-05,  ..., -2.5411e-06,\n",
            "          5.0241e-06, -8.7548e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3658e-02, -6.3934e-07, -1.6895e-06,  1.8711e-05, -3.2709e-05,\n",
            "        -2.2225e-05,  1.1497e-05, -1.4354e-05, -6.0939e-06,  1.0566e-05,\n",
            "        -7.5132e-06, -7.8459e-06, -1.0699e-05, -3.0421e-06,  5.5129e-06,\n",
            "         8.6120e-06,  1.7352e-06,  1.5363e-05,  1.0565e-05,  4.5409e-07,\n",
            "         5.9024e-07,  9.9785e-06, -7.5332e-06, -1.1106e-07,  4.8130e-05,\n",
            "        -1.4034e-05,  1.1897e-06,  1.2310e-05,  1.4132e-05, -4.9143e-06,\n",
            "         5.0861e-07, -1.2574e-05,  6.1293e-06, -3.4543e-06, -1.5415e-05,\n",
            "        -9.6366e-06, -4.5806e-06,  2.3336e-06, -2.2739e-06,  2.2421e-05,\n",
            "         2.8948e-05,  1.8731e-05, -8.3426e-06,  1.7569e-05, -6.0884e-06,\n",
            "        -1.4928e-06, -8.3920e-06, -3.5558e-07,  1.5487e-05, -3.6532e-05,\n",
            "         2.7511e-05,  1.0850e+00, -1.0997e-05, -1.2048e-07,  2.9171e-06,\n",
            "         8.8743e-02,  1.4121e-05,  5.5233e-06,  1.0590e-06,  1.7010e-05,\n",
            "         1.3292e-05, -2.4903e-06,  2.5984e-01, -7.4619e-05],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3400e-01,  1.9923e-05, -8.4191e-07,  4.2259e-06, -7.7888e-06,\n",
            "         -1.6387e-05,  3.0671e-06, -4.8909e-06, -2.9321e-07,  1.4165e-05,\n",
            "         -1.8074e-05,  9.9427e-06,  8.2784e-06, -1.6026e-05,  8.4395e-06,\n",
            "         -2.9248e-05, -7.8020e-06,  9.3882e-06,  1.0727e-05,  8.9655e-06,\n",
            "         -1.2832e-07, -1.3069e-05, -2.3888e-05, -2.2862e-05,  5.4669e-01,\n",
            "         -2.2013e-05, -6.5240e-06,  9.2929e-06,  1.2378e-06,  4.8122e-06,\n",
            "          2.3269e-06, -2.7109e-06, -1.6249e-06,  1.1402e-05, -4.3186e-06,\n",
            "         -7.9751e-08,  3.5575e-06,  2.4213e-06,  3.0197e-05,  2.3302e-05,\n",
            "         -4.9997e-07,  9.5833e-06, -1.1103e-05, -4.1584e-05,  8.2783e-06,\n",
            "          1.0368e-06,  1.2894e-05,  5.1571e-06,  4.0004e-05,  1.3174e-05,\n",
            "          2.7006e-05,  3.2337e+00,  7.9693e-06, -8.7593e-06, -7.5409e-07,\n",
            "          7.8343e-01, -1.2489e-06, -4.0330e-06,  1.3534e-05,  5.4473e-06,\n",
            "          2.7519e-05,  5.4444e-06,  1.0860e+00,  2.3984e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3097], requires_grad=True)\n",
            "l1_reg is: 30.167531967163086\n",
            "total_loss 1.0261590480804443\n",
            "pred: tensor([19.3922, 14.5050, 16.4820, 16.6656, 18.8976, 20.5432, 22.6934,  5.1393,\n",
            "         8.6056,  6.2647,  7.9901,  5.4315, 13.6114, 17.5810,  7.1335,  6.5491,\n",
            "         6.0325,  7.2706,  8.1715, 12.7589, 13.2460, 14.6380, 12.2268, 21.8897,\n",
            "        15.8881, 20.3972, 25.0114,  7.6059,  6.1734,  6.8130,  6.0780,  5.9270,\n",
            "         7.8140,  8.0479,  6.5676,  5.3113,  7.4134,  8.2146,  9.8580, 18.3893,\n",
            "        20.8244,  3.6660,  3.4722,  4.1398,  5.2707,  6.6443,  9.0810,  9.9976,\n",
            "         9.6926,  9.5646,  9.3088, 11.7406,  9.9816, 13.3015, 14.0795, 14.6796,\n",
            "        11.6426, 13.5549, 12.6064, 14.0052, 15.3102, 17.2888, 14.9002, 24.9790,\n",
            "        24.8233, 32.3159, 31.9450,  9.1190,  9.7146, 10.6736, 10.6759, 14.2321,\n",
            "        20.3543, 25.1640,  8.3955,  9.2210,  9.7323, 14.3293, 18.1855, 22.7733,\n",
            "        26.1978, 15.9880, 17.3129, 15.4350, 20.8285, 23.1110, 33.5310, 35.9431,\n",
            "        10.5205, 15.4634, 16.3164, 16.6091, 27.0709, 31.9784,  6.0302,  9.1386,\n",
            "         6.2479,  9.7338,  9.6488, 13.5492, 15.7716, 15.4141, 11.7127, 12.6144,\n",
            "        17.9431, 16.9401, 17.9750, 19.7607,  4.4407,  5.7021,  5.3644,  6.0790,\n",
            "         7.4304,  8.8252,  2.9356,  2.8639,  3.2621,  3.8933,  3.2735,  5.0726,\n",
            "         6.4621,  4.8001,  7.0710,  9.7169,  9.1525, 12.1432, 20.0924, 21.4136,\n",
            "         7.1364,  8.9114, 10.5994, 13.9576, 15.3935, 23.3758, 24.8045, 25.2032,\n",
            "        23.6907, 25.4973, 29.8166, 34.2730, 31.3664, 28.5279, 22.7180, 23.9970,\n",
            "        22.8954, 26.0869, 24.4193, 19.8360, 24.5643, 25.3237, 23.5703, 23.2022,\n",
            "        22.5111, 24.6036, 17.8591, 23.4956, 26.9338, 25.6980, 24.9607, 25.3779,\n",
            "        21.3982, 21.0477, 12.2550, 14.7094, 15.6706, 13.1509, 15.8310, 13.7616,\n",
            "        18.6539, 17.2698, 17.3942, 14.5352, 17.1272, 15.4947, 14.7494,  7.6992,\n",
            "         8.9965, 10.3525, 11.5546, 13.3396, 14.6646, 13.3516, 13.1656, 14.1072,\n",
            "        18.1838, 17.9673, 20.5658, 21.0419, 21.2095, 22.3171, 25.0483, 25.9073,\n",
            "        23.6584, 26.0088, 25.8027, 20.6022, 22.6830, 26.8765, 27.8284, 29.2002,\n",
            "        33.3447, 27.4181, 10.4331, 11.2864, 11.3221, 13.0159, 13.5139, 13.1186,\n",
            "        10.0810, 18.5741, 23.1330, 23.7597, 26.0230, 25.0868, 24.6851, 21.7931,\n",
            "        14.2750, 15.2340, 16.0050, 10.7387, 12.9290, 10.0221,  9.8129, 12.1387,\n",
            "        17.9277, 19.5488, 20.7654, 24.8751, 24.7937, 19.0240, 20.3526, 21.8756,\n",
            "        22.3949, 24.9613, 27.8225, 24.8957, 26.5622, 22.4059, 25.6694, 23.1319,\n",
            "        27.0693, 29.7207, 19.8158, 12.0233, 15.4290, 16.7811, 21.0375, 19.5069,\n",
            "        24.1324, 21.6459, 10.4419, 11.8552, 12.6571, 12.0967, 12.1307, 11.8238,\n",
            "         9.9560, 16.3856, 15.7946, 18.3338, 20.4192, 23.5693, 21.8382, 16.6264,\n",
            "        21.4321, 19.4674, 18.4300, 14.0906, 15.9607, 15.1609])\n",
            "target: tensor([20.7049, 14.7807, 15.6246, 16.3530, 21.1403, 20.8325, 24.9998,  3.5714,\n",
            "         8.6364,  5.7692,  8.6777,  2.8689, 13.1818, 16.1972,  6.8915,  6.3984,\n",
            "         5.9165,  7.7938,  7.7073, 12.3563, 12.7403, 14.3317, 11.1861, 21.9149,\n",
            "        15.7216, 20.2072, 25.5939,  7.4021,  6.4085,  6.0283,  5.9251,  5.5663,\n",
            "         7.7832,  7.3929,  6.8333,  4.4167,  8.1111,  8.1560, 10.5540, 19.6793,\n",
            "        19.3069,  3.7081,  3.7349,  3.5714,  5.3172,  7.1256,  9.6074,  9.9155,\n",
            "         9.7659,  9.7680,  9.4623, 12.0087, 10.4674, 14.1234, 13.6284, 16.2547,\n",
            "        12.1887, 13.4219, 11.4552, 13.7278, 14.9270, 16.9451, 13.5416, 24.6665,\n",
            "        25.5589, 31.2903, 33.9516,  8.7232,  9.4743, 10.4471, 10.4545, 13.6004,\n",
            "        21.5362, 24.7947,  8.0300, 10.0231, 10.1980, 13.5331, 17.4769, 24.8762,\n",
            "        26.2595, 15.9436, 16.9328, 17.6547, 20.6308, 22.7727, 35.3088, 36.3085,\n",
            "         9.6535, 14.2492, 17.8857, 18.5279, 27.2095, 34.6939,  5.5838,  8.7310,\n",
            "         5.3524, 10.9467, 10.6357, 15.4454, 17.5906, 15.9164, 12.1667, 11.6864,\n",
            "        18.8136, 16.1972, 20.7895, 19.6934,  3.4328,  5.3623,  6.6978,  4.7965,\n",
            "         7.0447,  7.5002,  2.7955,  2.6699,  2.9236,  4.3846,  2.8400,  4.2266,\n",
            "         6.3151,  3.5552,  5.7635,  9.5210,  7.8600, 11.7246, 21.8559, 21.3177,\n",
            "         8.4688,  9.5714, 10.6358, 13.0657, 15.2333, 25.8462, 23.3341, 26.2862,\n",
            "        24.1377, 25.5078, 32.0859, 34.6538, 32.1228, 27.8052, 21.7863, 24.6114,\n",
            "        23.7782, 25.3970, 25.9979, 19.5248, 25.9552, 25.1661, 25.5945, 22.8514,\n",
            "        21.9144, 24.1784, 18.4365, 21.6929, 25.4017, 24.9391, 25.2821, 27.2217,\n",
            "        21.4053, 18.9927, 11.9544, 13.8410, 14.0538, 13.6969, 15.8808, 13.5315,\n",
            "        19.8848, 16.4687, 18.2368, 13.7259, 17.7635, 15.5539, 14.0926,  6.9774,\n",
            "         8.3083,  9.6499, 11.0942, 12.5183, 13.5763, 12.8692, 12.9802, 13.9286,\n",
            "        18.6407, 18.1189, 20.1045, 20.9195, 20.7997, 23.7527, 24.5305, 26.1734,\n",
            "        24.5663, 26.8204, 25.4401, 20.5535, 22.1942, 26.6685, 28.8944, 28.5828,\n",
            "        35.6474, 26.9797,  9.8705, 11.2216,  9.6731, 13.3239, 12.5317, 12.5703,\n",
            "         8.2829, 19.1983, 22.5969, 23.5935, 25.9001, 24.6988, 25.2553, 21.3563,\n",
            "        12.1133, 16.9385, 17.0957,  8.9584, 13.6514,  9.6829, 10.1373, 10.3420,\n",
            "        17.6791, 20.2152, 20.7517, 25.9487, 24.4629, 20.1631, 20.3369, 21.6015,\n",
            "        23.2329, 24.6127, 28.6281, 25.0085, 27.3285, 22.5122, 25.8700, 23.2383,\n",
            "        27.3183, 31.4549, 20.4373, 12.4127, 15.8738, 17.5510, 21.0565, 19.5545,\n",
            "        24.4510, 22.1006,  9.8401, 10.0151, 11.3076, 11.8321, 10.3945, 11.5500,\n",
            "         9.4237, 16.0550, 16.3664, 19.7704, 20.4319, 23.6292, 21.6321, 16.5551,\n",
            "        21.9787, 20.1007, 18.6773, 12.9403, 17.1829, 13.6446])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.4842e-05,  1.7625e-05, -1.2139e-05,  ...,  1.4006e-05,\n",
            "          1.2363e-05,  9.5165e-06],\n",
            "        [-2.0302e-05, -4.0492e-05, -9.6202e-06,  ...,  4.1844e-04,\n",
            "          2.7259e-04, -8.7094e-04],\n",
            "        [-2.3159e-04, -3.4725e-05, -3.6239e-05,  ...,  3.8743e-02,\n",
            "         -9.3579e-04, -3.8140e-03],\n",
            "        ...,\n",
            "        [ 9.9086e-06, -1.3526e-05,  1.7345e-05,  ...,  2.6872e-06,\n",
            "          1.6615e-05,  1.4359e-05],\n",
            "        [ 1.3280e-05,  1.0316e-05, -1.6930e-06,  ..., -1.1154e-05,\n",
            "         -1.8005e-05,  1.8627e-05],\n",
            "        [ 4.5095e-05,  4.1383e-06, -9.1749e-06,  ...,  8.5919e-06,\n",
            "         -1.9539e-05, -1.4039e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.9807e-06,  4.2397e-01,  3.6174e-02,  1.6927e-05,  4.2038e-06,\n",
            "         1.6051e-05, -2.3229e-05, -2.1786e-06,  1.5797e+00,  1.5384e-05,\n",
            "         9.1346e-06,  1.1196e-06, -5.4533e-06,  1.9478e-05, -3.1732e-05,\n",
            "        -8.2800e-06,  1.2627e-05, -1.9046e-05, -8.7494e-06,  3.3521e-05,\n",
            "        -3.5064e-06,  1.0258e-05,  7.4175e-06, -3.9601e-06,  1.7450e-05,\n",
            "         3.1121e-05,  1.6109e-05,  1.3365e-01,  2.4939e-06, -3.7561e-06,\n",
            "        -4.5208e-06, -1.2519e-05, -2.1320e-07,  2.8720e-01,  1.1560e-05,\n",
            "        -1.7525e-05, -3.2816e-06, -1.0649e-05, -5.8725e-06,  1.1964e-05,\n",
            "        -1.8332e-05, -5.7004e-06,  2.0917e-05,  5.0281e-06, -3.0476e-06,\n",
            "        -9.7115e-06, -1.0645e-05, -1.5202e-05, -7.3456e-06, -4.2990e-04,\n",
            "        -6.4659e-06, -5.4138e-06,  1.6636e-05, -5.3137e-06,  2.0410e-05,\n",
            "        -5.4683e-06, -5.7408e-04, -3.9544e-07, -3.8561e-06,  2.2233e-05,\n",
            "        -1.6134e-05,  5.4669e-06,  6.0360e-06, -7.7356e-06,  1.0824e-05,\n",
            "         1.2591e-05, -1.1673e-06,  3.2117e-06, -2.7226e-05,  9.2459e-02,\n",
            "        -2.6184e-06,  6.8133e-06,  1.7734e-06, -3.2625e-06, -1.2689e-05,\n",
            "         1.7791e-05,  1.2194e-05,  1.0261e-05, -1.0282e-05, -2.0726e-03,\n",
            "        -9.1157e-07,  3.6903e-05, -3.1569e-06,  7.1463e-07,  7.6195e-06,\n",
            "         2.9968e-06,  2.0949e-06,  1.0041e-05, -1.2648e-05,  2.0975e-06,\n",
            "        -1.2431e-06, -1.2517e-05, -1.9047e-05, -2.3089e-05, -2.8038e-05,\n",
            "        -2.4831e-06,  3.3635e-07, -1.3566e-05,  2.1451e-05,  6.4242e-07,\n",
            "        -6.7510e-05,  8.0315e-06,  9.9607e-06, -1.6738e-05, -1.5568e-05,\n",
            "         1.5096e-05, -3.5568e-06, -4.4148e-06, -3.6290e-06,  1.7035e-05,\n",
            "         1.0101e-05, -1.0668e-05, -1.5469e-05, -3.4312e-06, -3.6442e-06,\n",
            "        -2.6930e-05, -1.1034e-05,  7.3753e-06,  1.2816e-05, -9.5624e-06,\n",
            "         1.2613e+00, -1.1977e-06, -1.8206e-06,  3.0576e-06, -1.6644e-05,\n",
            "        -7.2344e-06, -1.1770e-07,  3.6680e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.6280e-05, -1.0815e-04, -1.4813e-04,  ..., -1.6053e-05,\n",
            "         -3.9149e-06,  6.3285e-06],\n",
            "        [ 8.7731e-06,  7.9677e-06,  9.3229e-06,  ..., -1.8322e-05,\n",
            "          2.2752e-05,  6.8339e-06],\n",
            "        [ 1.4377e-05,  5.1366e-06, -1.6038e-05,  ..., -6.2802e-06,\n",
            "         -2.1314e-06,  8.1446e-06],\n",
            "        ...,\n",
            "        [-8.9615e-06,  3.0710e-06, -1.2875e-05,  ..., -1.0185e-05,\n",
            "         -1.8430e-05, -1.8792e-05],\n",
            "        [-9.5009e-07, -2.0296e-04, -1.4882e-04,  ..., -3.6830e-07,\n",
            "          8.0082e-06, -1.3654e-05],\n",
            "        [ 4.0566e-06, -5.8051e-05, -1.2543e-04,  ..., -1.0130e-05,\n",
            "         -1.2300e-05, -8.9074e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3467e-02,  4.9332e-07, -9.2885e-06,  2.7388e-05, -3.4564e-05,\n",
            "        -1.7764e-05, -2.9680e-06,  7.8693e-07,  5.9438e-06,  7.5590e-06,\n",
            "         9.6883e-06,  7.8329e-06, -1.6068e-05, -1.0640e-05, -3.9871e-06,\n",
            "        -4.0941e-06, -5.2920e-07,  7.2321e-06, -3.9481e-06, -2.0312e-05,\n",
            "        -1.7797e-05,  1.4086e-05, -5.2615e-06,  1.1121e-05,  9.6254e-05,\n",
            "        -1.8730e-05,  4.0058e-06,  1.2271e-07, -1.0866e-05,  8.0199e-06,\n",
            "        -9.9971e-06, -4.4476e-06, -1.9948e-07, -3.6575e-06, -1.9523e-05,\n",
            "         2.0172e-07, -1.5996e-06, -1.1088e-06,  4.6111e-06,  4.9209e-06,\n",
            "         2.6765e-05,  2.9247e-05, -1.7125e-06,  3.5593e-06, -1.3870e-05,\n",
            "         1.9681e-06, -1.3619e-05,  3.0964e-06,  2.4182e-05, -2.0197e-05,\n",
            "         2.6820e-05,  1.0844e+00,  3.6790e-06,  1.3294e-05,  6.9340e-06,\n",
            "         8.8510e-02, -3.0456e-07, -1.1792e-05,  8.5484e-06,  1.4825e-05,\n",
            "        -2.3861e-06,  2.3251e-05,  2.5956e-01, -1.4959e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3390e-01,  1.7778e-05,  1.3363e-05, -2.1550e-05, -5.3221e-06,\n",
            "         -8.7058e-06,  6.1147e-06, -6.3543e-06,  8.9331e-06,  2.3942e-05,\n",
            "         -3.1263e-05, -1.5811e-05,  1.2417e-05, -9.7395e-06,  8.5049e-06,\n",
            "         -6.3507e-06, -7.2372e-06,  1.5727e-05,  1.2805e-05,  1.0263e-05,\n",
            "          8.2557e-06, -2.1735e-05, -1.9795e-05, -3.3441e-05,  5.4659e-01,\n",
            "         -2.0730e-05,  1.9186e-05,  2.7217e-06, -1.4441e-05,  1.0430e-06,\n",
            "         -2.3431e-05, -5.7759e-06,  1.0311e-05,  2.0645e-06, -7.5079e-06,\n",
            "          1.4172e-05,  1.1935e-05,  6.5302e-06,  2.9640e-05,  2.2066e-05,\n",
            "          1.1483e-05,  8.9981e-06, -1.1499e-05, -4.7375e-05,  1.9729e-06,\n",
            "          8.5234e-06,  9.8742e-06, -7.7751e-06,  4.3314e-05,  1.0137e-05,\n",
            "          1.5429e-05,  3.2317e+00,  1.3151e-05, -1.7437e-05,  1.4920e-05,\n",
            "          7.8327e-01,  1.7481e-05,  1.1596e-05,  5.3657e-06, -1.1902e-05,\n",
            "          2.6748e-05, -7.4900e-06,  1.0856e+00,  2.3974e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3094], requires_grad=True)\n",
            "l1_reg is: 30.177757263183594\n",
            "total_loss 1.1922802925109863\n",
            "pred: tensor([24.0868, 24.0038, 12.5436,  9.7021, 23.5724, 26.3370, 26.8475, 14.4952,\n",
            "        11.3063, 16.5404, 24.9416, 20.4575, 24.5425, 18.5939,  8.6968, 17.3107,\n",
            "         8.9143, 23.9444,  9.3273,  6.6930, 11.9575, 19.9030, 10.4752, 25.3376,\n",
            "         7.0912, 18.6574,  5.4757, 12.6413, 12.2358, 25.4971,  8.3666, 15.2655,\n",
            "        11.4139, 13.1968, 16.6083, 25.3042,  7.3704, 22.0428, 15.0092, 24.4054,\n",
            "        21.5024, 26.9396,  4.6834, 20.3138, 24.6305,  6.3226, 20.9015, 23.7621,\n",
            "         5.9791, 14.0904,  7.0279, 12.4797, 10.2661, 21.8997, 13.7657, 18.9479,\n",
            "         6.5001,  7.5369, 24.8710,  8.0558,  6.3527, 21.4054,  4.2301, 16.7072,\n",
            "         4.5114, 11.7383,  3.5303, 14.0102,  7.9735, 24.4202, 22.6425, 14.5413,\n",
            "         7.6140, 20.2786, 14.6518, 12.4489, 14.6960,  4.9641, 10.6576, 25.6586,\n",
            "        28.7854,  3.7355, 16.9342, 19.0458,  5.0544, 21.7294,  6.7026, 12.9729,\n",
            "        25.2924, 22.1147,  6.4155, 14.6548, 17.5574, 11.3552, 19.1463, 14.1011,\n",
            "        27.2120, 13.4550,  8.3605,  2.8228, 13.2341, 21.4730, 24.6164, 25.9931,\n",
            "        11.7095, 14.4867,  9.5555, 17.9099,  3.3809, 25.3825, 34.5940, 25.1599,\n",
            "        21.0029, 10.3047,  4.8344, 13.9845, 26.0301, 15.1004, 16.6618, 29.1288,\n",
            "         9.2877, 20.1907, 24.9469, 26.4679, 24.0557, 24.6029, 23.8424, 16.1427,\n",
            "        15.7249, 12.5029, 26.0851, 14.2750, 26.0556, 16.0501, 25.6106, 14.0025,\n",
            "         3.0649, 13.6889, 13.7855, 18.8907, 21.5116, 21.7627,  6.5239,  8.9287,\n",
            "        10.7676, 27.1594,  9.7779,  7.8320, 25.2582, 16.3231, 21.5851,  6.4247,\n",
            "        17.6579, 22.3270,  8.9590, 19.0741, 16.1195,  8.2319, 24.6778,  5.1208,\n",
            "        24.1798, 18.6062, 19.3541, 12.8727, 13.3881,  4.4104, 27.6066, 16.0321,\n",
            "        24.8398, 18.0553, 11.5509,  7.5097, 21.1689, 15.6101,  2.9164, 26.3178,\n",
            "        24.7318, 24.5713, 15.1482, 13.1825, 23.6881, 11.0114, 15.1705, 12.3702,\n",
            "        25.4278, 20.2002, 15.9274, 13.5685, 22.4690,  3.9991,  9.4718, 19.0571,\n",
            "        19.4323, 22.7425, 24.7218, 10.7912, 15.5959, 16.0319, 26.3505, 16.2578,\n",
            "         6.8568, 28.7489, 13.8431, 23.3789,  5.7871, 24.9607, 15.4002, 26.9765,\n",
            "        14.9771, 22.7859, 24.5160,  7.2905, 11.8784, 16.2776, 15.6285, 14.3406,\n",
            "         8.7758, 15.7192,  8.4969,  5.7863, 24.2223, 21.6420, 18.4131, 19.0154,\n",
            "        10.6317,  8.2987, 20.4766, 18.4291, 12.0709, 12.6531, 20.0441, 33.2130,\n",
            "         2.9660, 25.7060, 13.0242, 13.3296,  9.4466, 26.8794, 15.7395, 26.6492,\n",
            "        20.7634, 32.9205, 11.2485,  8.8483, 14.7616, 14.9834, 19.4355, 10.9474,\n",
            "        24.1914, 16.6473, 20.7176,  9.9153, 20.7071, 11.7922,  6.0752,  6.0791,\n",
            "        26.4991, 25.9627, 11.0566, 16.9685, 24.2247, 20.4556, 12.2648, 24.9643,\n",
            "        14.0014, 15.0927, 14.4042,  8.1553,  9.4082,  8.2138],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([25.9556, 24.1904, 12.0164,  9.7305, 23.4956, 27.3015, 26.0619, 15.7759,\n",
            "        11.5176, 16.2624, 27.0168, 20.1229, 25.6022, 17.5585,  8.6533, 16.3352,\n",
            "         8.2558, 23.7640,  8.4282,  6.7016, 10.9914, 19.9239, 11.4987, 24.6717,\n",
            "         5.9441, 20.0433,  5.4569, 13.1460, 13.4940, 25.8443,  8.3335, 16.4075,\n",
            "        10.4885, 13.5933, 18.5775, 25.6291,  7.2547, 22.2449, 13.7785, 21.7978,\n",
            "        20.9893, 28.0660,  4.9550, 19.8605, 24.6307,  6.3095, 20.0587, 25.2080,\n",
            "         5.8333, 14.5754,  6.5972, 13.3752, 10.3589, 21.7506, 13.4441, 18.5585,\n",
            "         5.9271,  6.9575, 24.6943,  8.8462,  5.2365, 21.9697,  3.7834, 17.0786,\n",
            "         3.9589, 11.2198,  2.9763, 14.1325,  7.5893, 24.2957, 21.4348, 14.6181,\n",
            "         6.9034, 20.2477, 14.9789, 13.2615, 13.1081,  4.6487, 10.7616, 25.8136,\n",
            "        29.6748,  3.7572, 16.9422, 18.9134,  4.9716, 21.9080,  6.3057, 13.0854,\n",
            "        28.4034, 22.6469,  5.4820, 13.7928, 18.6427, 12.5000, 19.9219, 13.4557,\n",
            "        26.9071, 14.5243,  9.0476,  2.4920, 13.1820, 21.5198, 26.8806, 26.2702,\n",
            "        10.9001, 15.6198,  8.1115, 17.4884,  3.0333, 25.3752, 35.9269, 25.2681,\n",
            "        20.4727, 11.3391,  4.7692, 12.5806, 26.7078, 14.9064, 15.6183, 28.4617,\n",
            "         9.8060, 19.6202, 25.2241, 28.5991, 22.8793, 25.4691, 26.6413, 17.5345,\n",
            "        16.9725, 12.0735, 26.5567, 15.2496, 26.6844, 15.0994, 25.7552, 15.3727,\n",
            "         2.8180, 13.0953, 13.8732, 20.8937, 21.5427, 22.7714,  5.7299,  8.9577,\n",
            "        10.9720, 25.7110, 10.6815,  8.2031, 23.7378, 16.6661, 22.6237,  6.2031,\n",
            "        17.9593, 20.4707,  9.4725, 18.5950, 15.3233,  8.2237, 25.3183,  4.5714,\n",
            "        25.2021, 18.3333, 19.2588, 12.1706, 12.9086,  4.2636, 27.4623, 16.4330,\n",
            "        25.4778, 20.2325, 11.9352,  7.9269, 21.8640, 14.6409,  2.5701, 26.1767,\n",
            "        24.8246, 24.8489, 15.7150, 12.3529, 23.9214, 10.6641, 15.0182, 14.4013,\n",
            "        24.4949, 20.1714, 17.2330, 12.7005, 22.5318,  3.0594, 10.0034, 19.2308,\n",
            "        18.7735, 22.4451, 21.9030, 10.0148, 15.8894, 16.1333, 26.2982, 16.4352,\n",
            "         5.6818, 30.0542, 14.5650, 22.9409,  5.8000, 25.0859, 15.0293, 25.2176,\n",
            "        15.7830, 23.6343, 24.0858,  5.9859, 11.1512, 14.5425, 16.2214, 15.0574,\n",
            "         7.5058, 15.7130,  7.0442,  5.9224, 24.0313, 22.5258, 20.3412, 19.6543,\n",
            "        10.3015,  7.9747, 20.4839, 20.2343, 12.3069, 12.6252, 22.1143, 34.7197,\n",
            "         2.7056, 25.1279, 15.1781, 13.2050,  9.1305, 26.6282, 16.9941, 28.9355,\n",
            "        20.7442, 32.6948, 11.6045,  9.0231, 15.7708, 14.7400, 21.3942, 11.7030,\n",
            "        24.3867, 16.4475, 22.4324,  9.6626, 20.4702, 12.0150,  4.5049,  6.5972,\n",
            "        26.7613, 25.0821, 11.0691, 18.0973, 23.9407, 20.5062, 11.6902, 24.0979,\n",
            "        14.7830, 14.7273, 15.6164,  7.0238,  9.3660,  7.7878])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.4842e-05,  1.7625e-05, -1.2139e-05,  ...,  1.4006e-05,\n",
            "          1.2363e-05,  9.5165e-06],\n",
            "        [-2.0302e-05, -4.0492e-05, -9.6202e-06,  ...,  4.1844e-04,\n",
            "          2.7259e-04, -8.7094e-04],\n",
            "        [-2.3159e-04, -3.4725e-05, -3.6239e-05,  ...,  3.8743e-02,\n",
            "         -9.3579e-04, -3.8140e-03],\n",
            "        ...,\n",
            "        [ 9.9086e-06, -1.3526e-05,  1.7345e-05,  ...,  2.6872e-06,\n",
            "          1.6615e-05,  1.4359e-05],\n",
            "        [ 1.3280e-05,  1.0316e-05, -1.6930e-06,  ..., -1.1154e-05,\n",
            "         -1.8005e-05,  1.8627e-05],\n",
            "        [ 4.5095e-05,  4.1383e-06, -9.1749e-06,  ...,  8.5919e-06,\n",
            "         -1.9539e-05, -1.4039e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.9807e-06,  4.2397e-01,  3.6174e-02,  1.6927e-05,  4.2038e-06,\n",
            "         1.6051e-05, -2.3229e-05, -2.1786e-06,  1.5797e+00,  1.5384e-05,\n",
            "         9.1346e-06,  1.1196e-06, -5.4533e-06,  1.9478e-05, -3.1732e-05,\n",
            "        -8.2800e-06,  1.2627e-05, -1.9046e-05, -8.7494e-06,  3.3521e-05,\n",
            "        -3.5064e-06,  1.0258e-05,  7.4175e-06, -3.9601e-06,  1.7450e-05,\n",
            "         3.1121e-05,  1.6109e-05,  1.3365e-01,  2.4939e-06, -3.7561e-06,\n",
            "        -4.5208e-06, -1.2519e-05, -2.1320e-07,  2.8720e-01,  1.1560e-05,\n",
            "        -1.7525e-05, -3.2816e-06, -1.0649e-05, -5.8725e-06,  1.1964e-05,\n",
            "        -1.8332e-05, -5.7004e-06,  2.0917e-05,  5.0281e-06, -3.0476e-06,\n",
            "        -9.7115e-06, -1.0645e-05, -1.5202e-05, -7.3456e-06, -4.2990e-04,\n",
            "        -6.4659e-06, -5.4138e-06,  1.6636e-05, -5.3137e-06,  2.0410e-05,\n",
            "        -5.4683e-06, -5.7408e-04, -3.9544e-07, -3.8561e-06,  2.2233e-05,\n",
            "        -1.6134e-05,  5.4669e-06,  6.0360e-06, -7.7356e-06,  1.0824e-05,\n",
            "         1.2591e-05, -1.1673e-06,  3.2117e-06, -2.7226e-05,  9.2459e-02,\n",
            "        -2.6184e-06,  6.8133e-06,  1.7734e-06, -3.2625e-06, -1.2689e-05,\n",
            "         1.7791e-05,  1.2194e-05,  1.0261e-05, -1.0282e-05, -2.0726e-03,\n",
            "        -9.1157e-07,  3.6903e-05, -3.1569e-06,  7.1463e-07,  7.6195e-06,\n",
            "         2.9968e-06,  2.0949e-06,  1.0041e-05, -1.2648e-05,  2.0975e-06,\n",
            "        -1.2431e-06, -1.2517e-05, -1.9047e-05, -2.3089e-05, -2.8038e-05,\n",
            "        -2.4831e-06,  3.3635e-07, -1.3566e-05,  2.1451e-05,  6.4242e-07,\n",
            "        -6.7510e-05,  8.0315e-06,  9.9607e-06, -1.6738e-05, -1.5568e-05,\n",
            "         1.5096e-05, -3.5568e-06, -4.4148e-06, -3.6290e-06,  1.7035e-05,\n",
            "         1.0101e-05, -1.0668e-05, -1.5469e-05, -3.4312e-06, -3.6442e-06,\n",
            "        -2.6930e-05, -1.1034e-05,  7.3753e-06,  1.2816e-05, -9.5624e-06,\n",
            "         1.2613e+00, -1.1977e-06, -1.8206e-06,  3.0576e-06, -1.6644e-05,\n",
            "        -7.2344e-06, -1.1770e-07,  3.6680e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.6280e-05, -1.0815e-04, -1.4813e-04,  ..., -1.6053e-05,\n",
            "         -3.9149e-06,  6.3285e-06],\n",
            "        [ 8.7731e-06,  7.9677e-06,  9.3229e-06,  ..., -1.8322e-05,\n",
            "          2.2752e-05,  6.8339e-06],\n",
            "        [ 1.4377e-05,  5.1366e-06, -1.6038e-05,  ..., -6.2802e-06,\n",
            "         -2.1314e-06,  8.1446e-06],\n",
            "        ...,\n",
            "        [-8.9615e-06,  3.0710e-06, -1.2875e-05,  ..., -1.0185e-05,\n",
            "         -1.8430e-05, -1.8792e-05],\n",
            "        [-9.5009e-07, -2.0296e-04, -1.4882e-04,  ..., -3.6830e-07,\n",
            "          8.0082e-06, -1.3654e-05],\n",
            "        [ 4.0566e-06, -5.8051e-05, -1.2543e-04,  ..., -1.0130e-05,\n",
            "         -1.2300e-05, -8.9074e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3467e-02,  4.9332e-07, -9.2885e-06,  2.7388e-05, -3.4564e-05,\n",
            "        -1.7764e-05, -2.9680e-06,  7.8693e-07,  5.9438e-06,  7.5590e-06,\n",
            "         9.6883e-06,  7.8329e-06, -1.6068e-05, -1.0640e-05, -3.9871e-06,\n",
            "        -4.0941e-06, -5.2920e-07,  7.2321e-06, -3.9481e-06, -2.0312e-05,\n",
            "        -1.7797e-05,  1.4086e-05, -5.2615e-06,  1.1121e-05,  9.6254e-05,\n",
            "        -1.8730e-05,  4.0058e-06,  1.2271e-07, -1.0866e-05,  8.0199e-06,\n",
            "        -9.9971e-06, -4.4476e-06, -1.9948e-07, -3.6575e-06, -1.9523e-05,\n",
            "         2.0172e-07, -1.5996e-06, -1.1088e-06,  4.6111e-06,  4.9209e-06,\n",
            "         2.6765e-05,  2.9247e-05, -1.7125e-06,  3.5593e-06, -1.3870e-05,\n",
            "         1.9681e-06, -1.3619e-05,  3.0964e-06,  2.4182e-05, -2.0197e-05,\n",
            "         2.6820e-05,  1.0844e+00,  3.6790e-06,  1.3294e-05,  6.9340e-06,\n",
            "         8.8510e-02, -3.0456e-07, -1.1792e-05,  8.5484e-06,  1.4825e-05,\n",
            "        -2.3861e-06,  2.3251e-05,  2.5956e-01, -1.4959e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3390e-01,  1.7778e-05,  1.3363e-05, -2.1550e-05, -5.3221e-06,\n",
            "         -8.7058e-06,  6.1147e-06, -6.3543e-06,  8.9331e-06,  2.3942e-05,\n",
            "         -3.1263e-05, -1.5811e-05,  1.2417e-05, -9.7395e-06,  8.5049e-06,\n",
            "         -6.3507e-06, -7.2372e-06,  1.5727e-05,  1.2805e-05,  1.0263e-05,\n",
            "          8.2557e-06, -2.1735e-05, -1.9795e-05, -3.3441e-05,  5.4659e-01,\n",
            "         -2.0730e-05,  1.9186e-05,  2.7217e-06, -1.4441e-05,  1.0430e-06,\n",
            "         -2.3431e-05, -5.7759e-06,  1.0311e-05,  2.0645e-06, -7.5079e-06,\n",
            "          1.4172e-05,  1.1935e-05,  6.5302e-06,  2.9640e-05,  2.2066e-05,\n",
            "          1.1483e-05,  8.9981e-06, -1.1499e-05, -4.7375e-05,  1.9729e-06,\n",
            "          8.5234e-06,  9.8742e-06, -7.7751e-06,  4.3314e-05,  1.0137e-05,\n",
            "          1.5429e-05,  3.2317e+00,  1.3151e-05, -1.7437e-05,  1.4920e-05,\n",
            "          7.8327e-01,  1.7481e-05,  1.1596e-05,  5.3657e-06, -1.1902e-05,\n",
            "          2.6748e-05, -7.4900e-06,  1.0856e+00,  2.3974e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3094], requires_grad=True)\n",
            "l1_reg is: 30.177757263183594\n",
            "total_loss 1.1251589059829712\n",
            "pred: tensor([ 9.3608, 13.6173, 25.2562, 17.2500, 20.3735, 18.3942, 30.1467, 21.2367,\n",
            "        21.8074, 31.1900,  8.3464, 13.1148, 20.8450,  8.5325, 28.9432, 18.9246,\n",
            "         6.0875, 12.6631, 13.0971, 13.4156, 12.3328, 21.4877, 12.4598, 24.6493,\n",
            "        24.2522, 13.5848, 16.9667, 12.2169,  7.7937, 21.4679, 22.3151,  4.3084,\n",
            "        21.6226,  4.6010,  8.2182, 18.2659, 18.7943, 15.5161, 12.0287,  6.4393,\n",
            "         3.0423, 16.4683, 18.7135, 14.9592, 20.1555, 17.9599, 12.7086,  3.1495,\n",
            "        12.6466, 24.3320, 14.4333, 15.7406, 20.2236, 25.4328,  7.0471, 11.2260,\n",
            "        11.9319,  8.7411, 25.5645, 14.1069, 21.9310, 19.4799,  9.3241, 24.2726,\n",
            "        13.8177,  4.1926,  9.9906,  7.0012, 35.0065, 11.7504, 27.5174, 28.2726,\n",
            "         5.5830, 13.5303, 10.4281,  9.7054, 10.0280, 23.6199,  7.1953, 23.0252,\n",
            "        26.3441, 12.7436,  4.8524, 10.8030, 24.9648, 10.6013, 15.9958,  9.0154,\n",
            "        14.4382,  9.0095, 23.5928, 23.4290, 11.1711, 20.2171, 21.1719, 11.5357,\n",
            "        12.3068, 14.7464,  9.7871, 13.8134, 16.3922, 13.5304, 15.1931, 22.4098,\n",
            "        13.7999,  6.1273, 12.0546, 25.4625, 16.5702, 22.9480, 13.0932,  8.7266,\n",
            "        14.5917, 15.8105, 10.6812, 20.7763,  4.5530, 12.5453,  5.6141, 24.5680,\n",
            "        24.6354, 24.5115, 22.2091, 18.5708, 17.7377, 17.3104, 23.5811, 11.0531,\n",
            "        22.0783, 21.7666, 13.7833,  7.2016, 12.5109, 19.9997, 24.0380,  3.1201,\n",
            "        19.9471, 16.1866, 25.2148, 11.6362,  5.1158, 23.9498, 11.2214, 21.9872,\n",
            "        12.4471, 12.5121,  9.0909, 15.3338, 24.2714, 23.5448, 17.7208, 22.1121,\n",
            "         7.5666, 11.1125, 15.6823, 13.4278,  3.0501,  6.0137, 18.9455, 22.0518,\n",
            "        21.9819, 14.4688, 17.6416, 16.0359, 17.6690, 25.3688, 11.8100,  9.8929,\n",
            "        13.1546,  9.8740, 15.8816, 31.0907, 13.4018, 11.3381, 25.3482, 23.8716,\n",
            "         3.2765,  5.4173, 12.4708, 12.9182, 23.3566, 16.8652,  5.7136, 13.8013,\n",
            "        11.4525,  8.8425, 13.4874, 25.9770,  9.3756, 35.5445, 25.4402, 25.5004,\n",
            "        17.5583,  7.0207, 13.5183,  4.3878,  9.9368,  7.0117, 30.7618, 26.9268,\n",
            "         8.6799, 10.8260, 20.7290, 22.6507, 22.9357, 24.5244, 16.1643, 14.5050,\n",
            "        13.0266, 16.1172,  8.0521, 11.1725, 13.2448, 26.6332,  7.2823, 24.9898,\n",
            "        12.9224, 15.6767, 15.6946,  4.6195, 19.6168, 23.5439,  9.2578, 14.1765,\n",
            "        20.3729, 31.1553, 23.2243, 24.4991, 13.0135,  3.4949, 18.8397, 25.0022,\n",
            "        22.4390, 21.1723, 20.2927,  5.4792, 12.4726, 12.2128,  6.1674, 11.9717,\n",
            "         9.8271,  7.9313,  9.2965, 13.7809, 23.9683, 14.0252, 13.9639, 26.4539,\n",
            "        13.0500, 11.6715, 22.0674, 18.4619, 24.3101,  5.1103, 12.0257, 13.2913,\n",
            "        25.4502, 19.2283, 20.1385,  7.0227, 25.3296,  9.4132, 24.2697, 23.5320,\n",
            "        13.6726, 24.9320, 22.7912, 20.4284, 25.1786, 27.3261],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([ 8.7097, 11.3954, 25.5912, 19.6625, 19.7423, 17.9984, 31.1689, 23.0624,\n",
            "        21.4763, 33.0460,  7.5893, 13.8869, 20.5772,  7.8224, 30.0807, 18.9118,\n",
            "         5.6398, 12.0752, 12.7256, 12.9458, 11.2031, 22.1484, 11.4865, 25.2018,\n",
            "        23.7057, 12.1542, 19.9454, 12.0509,  8.8633, 21.9368, 24.4056,  3.8386,\n",
            "        22.7647,  4.4160,  8.1708, 17.1342, 19.2647, 17.0101, 11.8317,  7.5397,\n",
            "         2.4374, 17.2241, 18.4029, 14.3872, 17.7417, 18.5246, 13.0247,  2.7512,\n",
            "        11.3941, 24.7660, 14.0370, 16.8272, 21.3376, 25.0113,  5.9698, 10.6579,\n",
            "        11.9079,  8.8915, 27.0956, 12.7916, 22.2169, 20.9750,  9.2930, 25.8066,\n",
            "        14.8030,  3.3276,  9.7351,  7.3566, 34.3018, 10.5933, 29.2688, 30.1929,\n",
            "         4.8105, 12.8029, 11.5772,  9.8075,  9.1212, 23.6043,  7.5682, 24.0605,\n",
            "        28.9574, 12.6149,  4.7149, 10.3342, 25.7512,  9.4370, 16.4813,  8.6037,\n",
            "        14.1510,  8.2869, 22.3948, 24.3694, 10.5968, 20.2940, 21.6329, 11.2208,\n",
            "        11.6519, 13.9200,  9.7826, 13.2229, 17.6392, 12.5437, 15.0278, 23.5116,\n",
            "        13.1617,  5.6806, 11.3839, 25.3122, 19.2529, 23.9115, 11.8335,  8.7828,\n",
            "        14.1956, 15.8179,  8.7596, 21.1477,  3.3824, 10.7577,  5.6160, 25.7845,\n",
            "        24.6491, 26.8413, 22.1074, 20.4918, 19.0480, 18.5855, 24.1188, 11.8561,\n",
            "        23.3834, 22.8089, 13.2884,  7.1181, 12.2535, 19.9495, 24.0851,  3.1293,\n",
            "        18.9845, 16.0910, 26.7589, 11.3705,  4.2692, 24.2843, 11.1029, 22.5453,\n",
            "        12.0289, 13.5357,  8.2031, 16.8269, 25.8410, 23.9563, 18.6717, 20.4129,\n",
            "         6.7536, 10.7930, 15.7240, 12.3762,  3.0583,  5.3072, 20.1040, 23.4949,\n",
            "        22.0434, 13.9587, 19.0511, 17.4081, 17.9615, 27.0473, 11.5707,  9.0505,\n",
            "        12.8757,  9.2012, 15.5819, 32.9856, 13.9020, 10.3828, 25.5347, 25.9174,\n",
            "         2.9887,  5.3960, 13.5350, 11.9545, 24.4616, 19.4611,  5.9091, 12.8266,\n",
            "        10.9200,  9.1015, 12.6670, 25.4253,  8.5313, 36.7231, 25.0734, 24.8955,\n",
            "        17.3118,  6.9527, 13.3486,  4.1866,  9.9495,  6.7507, 30.6338, 26.9206,\n",
            "         8.6165, 10.2096, 20.3947, 21.5702, 21.0167, 24.3183, 16.6667, 13.2845,\n",
            "        11.8880, 15.9245,  7.4477, 10.2976, 13.9302, 27.0749,  6.8519, 25.2360,\n",
            "        13.1169, 14.8727, 16.1866,  3.8084, 21.1322, 24.0977,  7.6426, 14.8318,\n",
            "        22.0973, 28.3824, 22.6834, 25.4924, 13.9719,  3.4974, 19.5906, 25.7552,\n",
            "        23.1913, 21.8819, 19.5975,  4.9038, 13.0252, 12.8861,  5.2326, 11.8772,\n",
            "         9.5000, 12.4000,  7.6077, 13.7875, 23.3247, 13.5099, 13.2633, 27.4537,\n",
            "        12.7806, 11.5220, 21.8748, 19.3151, 22.4143,  3.6290, 11.3733, 13.6672,\n",
            "        25.3011, 19.5946, 20.9200,  6.2374, 25.6052,  8.6887, 25.2803, 24.1602,\n",
            "        14.8030, 25.0422, 22.3694, 21.4650, 25.4932, 27.6146])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-2.4696e-05,  1.5446e-05, -1.6741e-05,  ...,  1.8109e-05,\n",
            "         -3.3097e-06,  1.5887e-05],\n",
            "        [-2.0320e-05, -1.1713e-04, -7.7363e-06,  ...,  2.1156e-04,\n",
            "          3.9083e-04, -6.9291e-04],\n",
            "        [-3.0887e-04, -1.2691e-04, -1.4203e-05,  ...,  3.8433e-02,\n",
            "         -6.8381e-04, -3.6965e-03],\n",
            "        ...,\n",
            "        [ 6.7466e-06,  2.1141e-06,  1.1499e-05,  ..., -6.4221e-06,\n",
            "          1.1664e-05,  5.8602e-06],\n",
            "        [-7.4839e-06,  9.8558e-06,  1.0254e-05,  ...,  4.5099e-06,\n",
            "         -2.4564e-05,  2.9145e-05],\n",
            "        [ 5.0877e-05, -1.8651e-05, -5.9140e-06,  ...,  8.7897e-06,\n",
            "         -2.8206e-05,  6.7267e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.4902e-06,  4.2387e-01,  3.5729e-02,  2.3073e-05,  2.7420e-06,\n",
            "         2.6105e-05, -1.9331e-05,  4.7154e-06,  1.5797e+00,  2.4067e-05,\n",
            "        -8.9926e-06, -1.5229e-05,  1.8126e-06,  1.4592e-05, -2.1005e-05,\n",
            "         7.4046e-06,  3.3348e-06, -7.0980e-06,  1.2211e-06,  3.3106e-05,\n",
            "         1.0950e-06, -4.2680e-06,  1.5332e-05,  1.1705e-05,  1.1171e-05,\n",
            "         2.0561e-05, -3.6152e-06,  1.3357e-01,  3.4954e-06, -2.3159e-06,\n",
            "        -3.0843e-07, -6.2544e-06,  1.5626e-05,  2.8712e-01, -4.1089e-06,\n",
            "        -1.2819e-05,  1.7122e-07,  5.0588e-06, -9.9689e-06,  1.4041e-05,\n",
            "        -6.3537e-06,  1.6453e-05,  1.3985e-06,  6.4763e-06,  1.0365e-05,\n",
            "         1.1053e-05, -1.3279e-06, -8.9100e-06, -1.6051e-05, -4.2796e-04,\n",
            "        -2.3408e-06, -4.8349e-06,  1.0783e-05,  1.0363e-05,  2.9093e-05,\n",
            "         4.0131e-06, -7.4515e-04,  8.5659e-06,  2.3150e-06, -2.4626e-06,\n",
            "        -8.3155e-06,  9.2484e-06,  1.4747e-05,  7.9251e-06, -1.3879e-06,\n",
            "        -7.9184e-06,  2.6388e-05,  1.0965e-05, -2.5030e-05,  9.2359e-02,\n",
            "         1.0779e-05, -1.5464e-05, -1.6601e-05,  7.9309e-06, -1.7350e-05,\n",
            "        -1.6375e-06,  1.4588e-05,  1.8972e-05, -3.9962e-06, -2.1381e-03,\n",
            "         1.6845e-07,  2.0594e-05,  7.3477e-06, -7.6383e-06, -8.0702e-06,\n",
            "         4.4456e-06,  4.5334e-06, -1.0746e-05, -7.7634e-08,  3.4913e-06,\n",
            "        -7.1542e-07, -3.2107e-06, -1.6853e-05, -1.9185e-05, -2.5985e-05,\n",
            "         8.8227e-06, -6.2521e-06,  1.8823e-06,  1.9473e-06, -1.1321e-05,\n",
            "        -1.3676e-04,  7.4798e-06,  6.7926e-06, -1.0428e-05,  2.4071e-06,\n",
            "         1.0808e-05, -1.1311e-05, -3.8752e-06,  1.2023e-05,  1.0744e-05,\n",
            "         1.0857e-05, -1.7073e-05, -1.1488e-06, -1.9705e-06,  2.7688e-06,\n",
            "        -4.1893e-05,  9.7401e-06,  9.0615e-07,  1.6903e-05, -1.4795e-05,\n",
            "         1.2613e+00,  9.5574e-06,  2.1103e-06, -1.7737e-05, -1.0272e-05,\n",
            "         1.0092e-05, -7.6001e-06, -5.0407e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-4.1608e-06, -1.4098e-04, -2.3473e-04,  ..., -1.1069e-05,\n",
            "         -6.9521e-06,  2.5363e-06],\n",
            "        [ 1.4130e-05, -6.3394e-07, -1.1450e-05,  ..., -1.2017e-05,\n",
            "          2.0572e-05, -2.7517e-06],\n",
            "        [ 2.4148e-06, -3.5686e-06, -2.2588e-05,  ..., -2.1229e-06,\n",
            "          2.2433e-06, -7.5292e-06],\n",
            "        ...,\n",
            "        [ 8.7843e-07, -2.5318e-07, -7.5127e-06,  ..., -1.0037e-05,\n",
            "         -1.3512e-05, -2.7481e-05],\n",
            "        [ 1.3086e-05, -2.7622e-04, -3.3500e-04,  ...,  8.0209e-07,\n",
            "         -9.0708e-06,  1.9144e-06],\n",
            "        [ 1.6570e-07, -9.0439e-05, -1.8325e-04,  ..., -6.9607e-06,\n",
            "         -1.7892e-05,  9.5524e-07]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3374e-02, -8.4867e-06, -6.1232e-06,  2.5193e-05, -2.6233e-05,\n",
            "        -3.7480e-06, -5.9856e-06,  4.4128e-06,  6.7793e-06, -5.1436e-06,\n",
            "         1.5168e-05,  1.1941e-05, -1.0897e-05, -7.4777e-06, -2.5381e-06,\n",
            "        -5.5304e-06,  7.4320e-06, -1.0087e-05, -7.0097e-06, -2.8999e-05,\n",
            "        -2.4345e-05,  7.7802e-06,  6.7829e-06,  1.1224e-05,  2.1989e-04,\n",
            "        -1.2957e-05, -3.4606e-06, -2.0845e-05, -2.3366e-05,  9.6608e-06,\n",
            "        -9.4514e-06,  1.2866e-05,  4.1064e-06,  6.1603e-06, -1.3222e-05,\n",
            "        -9.4377e-07,  1.1085e-05,  5.7928e-06,  8.1027e-07, -2.0829e-05,\n",
            "         1.4800e-05,  2.8713e-05,  1.4254e-05, -1.9057e-05, -1.0874e-05,\n",
            "        -4.9176e-06, -8.3228e-06, -3.7984e-06,  2.2014e-05,  4.5064e-06,\n",
            "         1.6199e-05,  1.0843e+00,  6.8905e-06,  1.5366e-05,  5.4894e-07,\n",
            "         8.8420e-02, -3.2847e-06, -1.7376e-05,  5.2885e-06,  2.8553e-06,\n",
            "        -6.4979e-06,  3.6418e-05,  2.5947e-01, -2.0705e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3379e-01,  5.8491e-06,  1.6155e-05, -3.4746e-05,  6.8979e-06,\n",
            "          8.2054e-06, -1.1398e-06,  2.3346e-06,  7.2450e-06,  2.2742e-05,\n",
            "         -3.3134e-05, -2.8972e-05,  6.1469e-06,  5.9196e-06, -1.4370e-06,\n",
            "          2.4260e-05,  3.2759e-06,  1.1431e-05,  4.6755e-06,  1.4351e-06,\n",
            "          5.8014e-06, -1.9536e-05, -6.1120e-06, -3.2950e-05,  5.4649e-01,\n",
            "         -9.5756e-06,  3.2324e-05, -1.3175e-05, -1.8550e-05, -1.2349e-05,\n",
            "         -3.6614e-05,  1.4656e-06,  1.1056e-05, -1.6324e-05, -3.7144e-07,\n",
            "          1.6999e-05,  9.4775e-06,  2.2801e-07,  1.9138e-05,  1.0955e-05,\n",
            "          1.2264e-05, -1.5139e-06, -1.8567e-06, -4.2579e-05, -1.3698e-05,\n",
            "          5.2608e-06, -2.8433e-06, -9.4037e-06,  3.6294e-05, -2.5848e-06,\n",
            "         -4.9946e-06,  3.2312e+00,  7.8204e-06, -1.5248e-05,  1.9026e-05,\n",
            "          7.8316e-01,  2.4358e-05,  1.5662e-05, -1.1986e-05, -1.7502e-05,\n",
            "          1.6055e-05, -9.1187e-06,  1.0855e+00,  2.3963e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3093], requires_grad=True)\n",
            "l1_reg is: 30.168838500976562\n",
            "total_loss 1.3041987419128418\n",
            "pred: tensor([10.2948,  6.0657, 19.9497, 14.1801,  9.5383, 16.1880, 12.5178, 13.8566,\n",
            "        21.6184, 21.9691, 19.6236,  6.8255, 23.9014, 10.5874, 10.6083, 16.7043,\n",
            "         5.7573, 34.0633, 12.2559, 26.1343, 27.1914, 21.7201, 17.8523,  6.2738,\n",
            "        23.1322, 21.9933, 26.4909, 16.2458, 21.5061,  6.4929, 24.5706, 17.0448,\n",
            "        25.5790,  9.9161, 17.1271,  7.4669, 15.0014, 10.9402, 27.9540,  5.7430,\n",
            "        21.7951, 24.3316, 23.5983, 15.8715, 36.5641, 14.1129, 24.8760, 21.7457,\n",
            "        13.1686,  8.7206, 14.5565, 11.9444, 11.1168, 30.7914, 13.6460, 15.2218,\n",
            "        22.2154, 18.3995, 14.9581, 34.7456, 12.8707, 13.9051, 22.8019, 21.8521,\n",
            "         7.2883, 19.0899, 17.8325, 15.1124,  9.5789, 13.6782,  6.6620, 17.7429,\n",
            "        24.2385, 10.9704,  9.4747, 13.9704,  8.4823, 23.7584, 13.6350, 15.0588,\n",
            "         5.2473, 25.2543, 10.3309,  8.4942, 11.8230, 22.6553,  9.5593, 18.7601,\n",
            "        26.5345, 22.4519, 23.2107,  9.6478, 25.6859,  5.9456, 24.8779, 13.0832,\n",
            "        13.7811,  7.7790, 23.0315, 13.2327, 13.3584,  6.0826, 21.4661, 18.3284,\n",
            "         9.7114, 22.0832,  9.1405, 21.1231, 26.9002, 14.4334,  4.5880, 27.9615,\n",
            "         2.7321, 11.9798, 14.8841,  5.5853, 15.2058, 27.0355, 25.5394,  9.6449,\n",
            "         9.9078,  4.9558,  9.3351, 24.6217, 23.1584, 27.0666, 16.2511, 11.5521,\n",
            "        37.9208, 17.4144, 25.4023, 11.2616, 22.0724, 24.7038, 15.0668, 26.1863,\n",
            "        26.7237, 20.3939, 11.9753, 27.9097, 13.3731,  7.1033, 16.2480, 20.1675,\n",
            "         7.8671, 28.5502,  3.4713,  8.7493,  6.6118, 22.0900,  5.6793, 12.3968,\n",
            "        34.2698, 13.1170, 16.4717,  9.7442, 16.5575, 27.3104, 15.6797, 21.4875,\n",
            "         6.5867,  7.1723, 15.7444, 27.7421,  8.0053, 26.6484, 22.0643, 14.5083,\n",
            "        18.6915,  4.3202, 30.6752, 17.3192,  4.9800, 26.4757, 23.1902, 20.1552,\n",
            "        21.4908, 26.0536, 20.1003, 18.4206, 23.2510, 27.6348, 14.6375,  4.5588,\n",
            "        13.3146, 13.6745, 24.1366, 16.4538, 15.3728, 12.4829,  8.1215,  2.8099,\n",
            "        12.1546, 24.8235, 23.9055, 13.6379, 19.8247, 15.6192, 25.9114, 25.3159,\n",
            "         8.4231, 26.1551, 15.2392, 22.2844, 13.8750, 14.1297,  9.5620, 17.2598,\n",
            "        12.7655, 23.8189, 14.1018, 32.2935, 14.1478, 19.7340,  3.9236, 11.0895,\n",
            "        31.1786, 19.9680, 22.0124, 13.0743, 13.5052, 16.0084, 29.6913,  9.3427,\n",
            "        16.1911, 13.9300, 11.3216, 23.5459,  9.8467, 14.1595, 27.2547, 16.0930,\n",
            "         8.9839, 17.9361,  9.5113, 11.7412, 13.2933, 14.3491, 15.2853, 19.7887,\n",
            "        21.4565, 23.9473, 13.2034, 12.5110, 20.1436,  6.2817, 10.3399, 25.4323,\n",
            "         7.6823, 12.2013, 18.2504, 17.7800,  7.2563,  8.4577, 35.1471, 25.2328,\n",
            "        13.0375, 10.0705, 27.3233, 21.6596, 11.6806, 15.0984, 11.3653,  3.1019,\n",
            "        25.1077,  9.5606, 23.8283, 13.7767, 22.3756,  9.1086],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([ 9.2018,  5.8006, 21.1737, 14.4799,  9.5819, 16.1858, 12.0579, 13.0036,\n",
            "        23.7777, 20.8498, 19.4706,  7.7447, 22.8612, 10.4752, 11.0325, 16.3600,\n",
            "         5.4154, 33.6615, 11.9697, 26.3706, 29.3879, 22.1138, 16.6666,  7.0349,\n",
            "        23.1035, 21.3608, 24.9590, 17.5987, 22.2873,  6.0000, 27.2477, 19.9541,\n",
            "        27.0030,  8.9425, 15.4452,  6.1151, 15.0651,  9.9079, 29.3294,  5.2390,\n",
            "        21.2901, 22.2626, 24.5591, 15.1712, 36.4983, 13.5277, 25.2887, 20.9574,\n",
            "        13.5415,  8.9693, 14.6109, 10.9756, 10.4291, 26.6320, 10.8209, 14.8496,\n",
            "        22.4202, 18.5107, 14.6286, 35.6916, 11.5326, 14.4196, 22.5898, 21.5185,\n",
            "         7.5698, 20.2719, 17.1996, 13.7915,  9.4932, 13.3920,  7.9439, 17.6362,\n",
            "        23.6003, 10.5069,  8.5957, 13.6788,  8.3439, 24.2159, 13.4342, 15.9248,\n",
            "         5.3867, 25.0882,  9.8276,  9.3497, 10.8720, 25.6530,  9.5583, 18.6037,\n",
            "        26.5404, 21.6737, 22.7710,  9.7464, 28.4876,  5.8912, 26.0279, 12.8758,\n",
            "        15.1367,  8.4532, 22.8468, 12.7826, 13.0259,  6.4376, 22.0613, 18.7356,\n",
            "        10.0308, 24.8666,  9.4262, 20.1764, 27.8016, 14.7871,  5.4192, 29.6129,\n",
            "         2.3693, 12.1160, 15.4301,  6.0089, 16.2852, 30.2764, 25.1255,  9.7509,\n",
            "         9.1693,  4.8484,  9.3103, 24.5022, 22.8251, 27.2075, 15.0831, 11.8498,\n",
            "        37.7397, 18.2323, 24.7328, 10.4878, 22.6358, 26.2859, 15.8497, 26.8985,\n",
            "        25.9997, 19.8966, 14.1373, 28.0427, 13.1363,  7.8824, 18.0296, 20.3543,\n",
            "         7.5074, 30.3723,  2.7879,  8.3162,  6.5350, 24.0582,  5.6280, 11.5782,\n",
            "        36.0361, 14.1966, 16.7220,  9.4027, 16.1602, 28.4202, 16.0714, 21.8468,\n",
            "         6.6757,  7.1608, 16.8852, 27.1171,  8.8367, 26.4628, 22.6352, 13.8809,\n",
            "        16.2835,  4.0833, 31.3393, 16.0704,  4.3307, 23.5499, 23.2506, 21.9697,\n",
            "        20.9808, 25.2300, 20.3720, 17.8309, 21.8545, 28.3915, 16.3921,  3.2394,\n",
            "        11.6033, 13.4997, 24.3948, 17.6020, 15.4278, 13.0363,  8.5520,  2.9935,\n",
            "        12.0117, 25.1262, 23.7257, 14.2595, 20.1652, 15.5823, 24.6701, 25.6022,\n",
            "         8.2176, 25.0120, 14.6036, 22.4144, 13.2268, 13.6488,  9.1595, 17.3858,\n",
            "        12.3327, 24.7600, 14.2534, 32.3296, 14.0666, 19.0292,  4.7581, 10.5865,\n",
            "        31.4490, 21.2929, 21.9444, 11.6972, 14.1771, 16.7238, 30.6270, 10.2011,\n",
            "        18.5327, 13.8787, 10.9893, 24.2089, 10.0550, 14.3454, 25.5027, 16.6193,\n",
            "         9.6226, 16.1643,  8.7021, 11.8489, 13.2241, 14.3967, 15.8325, 19.3274,\n",
            "        21.8105, 23.4528, 12.6357, 12.1732, 20.6560,  6.0484, 10.5772, 25.9811,\n",
            "         7.1776, 10.5796, 16.7586, 18.1217,  7.5116,  9.2297, 37.0889, 26.5690,\n",
            "        13.3983, 10.4222, 27.7032, 22.2379, 11.8714, 15.3425, 11.4877,  3.2286,\n",
            "        26.3721,  9.0297, 23.1896, 13.4919, 22.0358,  8.8574])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-2.3565e-05,  3.4840e-06, -1.0884e-05,  ...,  1.1803e-05,\n",
            "         -7.4151e-06,  1.1620e-05],\n",
            "        [ 2.3618e-05, -1.5030e-04, -4.0630e-06,  ..., -5.1072e-05,\n",
            "          3.4232e-04, -3.1565e-04],\n",
            "        [-3.0400e-04, -1.6816e-04,  7.9061e-06,  ...,  3.8152e-02,\n",
            "         -3.3550e-04, -3.2187e-03],\n",
            "        ...,\n",
            "        [-6.0992e-06,  6.1904e-06, -3.7626e-06,  ..., -4.6213e-06,\n",
            "         -2.7934e-06, -1.1785e-05],\n",
            "        [-1.6170e-05, -5.5748e-07,  1.1005e-05,  ...,  8.6033e-06,\n",
            "         -2.0476e-05,  2.8617e-05],\n",
            "        [ 4.6078e-05, -2.9164e-05,  7.0208e-06,  ..., -1.0264e-06,\n",
            "         -2.5997e-05,  1.5400e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-7.9139e-06,  4.2387e-01,  3.5985e-02,  1.8608e-05, -8.5736e-06,\n",
            "         2.5150e-05, -5.8243e-06,  9.1368e-07,  1.5804e+00,  2.1865e-05,\n",
            "        -1.5307e-05, -1.9952e-05, -1.6481e-06,  1.9853e-07, -1.3515e-06,\n",
            "         1.1522e-05, -1.5025e-05,  1.3657e-05,  1.9354e-07,  2.2730e-05,\n",
            "        -4.7645e-06, -7.3420e-06,  1.2436e-05,  1.5796e-05, -4.4761e-06,\n",
            "         1.0550e-06, -1.1394e-05,  1.3366e-01, -5.5817e-06,  8.9731e-06,\n",
            "         1.3481e-05,  9.3827e-06,  1.9855e-05,  2.8722e-01, -8.2098e-06,\n",
            "         1.4230e-06, -6.7194e-06,  9.1951e-06, -3.6638e-06,  5.9099e-06,\n",
            "         1.4426e-05,  2.6399e-05, -2.6170e-05, -2.2147e-06,  1.2447e-05,\n",
            "         1.9743e-05,  1.7053e-05,  6.7432e-06, -1.3891e-05, -3.2924e-04,\n",
            "         1.1372e-05,  5.6800e-06, -4.4705e-06,  1.4475e-05,  2.6912e-05,\n",
            "         2.5365e-06, -5.9299e-04,  6.6288e-06, -2.1330e-06, -1.4690e-05,\n",
            "         8.7176e-06,  2.6477e-06,  1.2583e-05,  1.2009e-05, -2.3792e-06,\n",
            "        -1.6407e-05,  4.1191e-05,  7.9308e-06, -1.3053e-05,  9.2327e-02,\n",
            "         1.2836e-05, -2.5490e-05, -2.3140e-05,  8.0051e-06, -1.1559e-05,\n",
            "        -9.1212e-06,  6.7458e-06,  1.6813e-05,  1.1661e-05, -1.9158e-03,\n",
            "        -8.8597e-06, -4.0952e-06,  6.7960e-06, -5.1561e-06, -1.2194e-05,\n",
            "        -4.2485e-06, -3.2764e-06, -1.9460e-05,  2.1198e-05, -5.2520e-06,\n",
            "         9.7636e-06,  1.5156e-05, -4.8798e-06, -5.6806e-06, -1.4149e-05,\n",
            "         8.9997e-06, -2.1799e-06,  5.7857e-06, -2.5607e-05, -1.2083e-05,\n",
            "         4.1964e-05, -3.0168e-06, -6.0723e-06,  5.2513e-06,  8.5808e-06,\n",
            "        -3.0470e-06, -8.2878e-06,  6.6239e-06,  1.6100e-05, -4.8941e-06,\n",
            "         1.5475e-06, -1.2838e-05,  2.1750e-05,  9.3455e-06, -1.4588e-06,\n",
            "        -4.5359e-05,  1.8440e-05, -1.4930e-05,  1.0580e-05, -9.5006e-06,\n",
            "         1.2618e+00,  9.2351e-06, -4.3590e-06, -2.6437e-05,  5.4611e-06,\n",
            "         1.5682e-05, -4.3382e-06, -2.8994e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.2560e-05, -5.0303e-05, -1.7679e-04,  ...,  3.4040e-06,\n",
            "          3.0983e-07, -1.0858e-05],\n",
            "        [ 8.9514e-06,  1.6246e-06, -2.0146e-05,  ...,  3.6564e-06,\n",
            "          8.6100e-06, -1.3787e-06],\n",
            "        [-1.8351e-05, -1.4019e-06, -1.8482e-05,  ...,  1.1619e-05,\n",
            "         -3.8195e-06, -1.1636e-05],\n",
            "        ...,\n",
            "        [-2.6559e-07,  6.7533e-06,  7.3115e-06,  ...,  9.5781e-08,\n",
            "          9.1449e-07, -2.5301e-05],\n",
            "        [ 1.5712e-05, -1.0800e-04, -2.3656e-04,  ..., -8.1718e-06,\n",
            "         -1.4451e-05,  5.9652e-06],\n",
            "        [-1.3336e-05, -1.0959e-04, -2.2528e-04,  ...,  5.8920e-06,\n",
            "         -1.2925e-05, -1.6840e-07]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3359e-02, -6.5688e-06,  6.7280e-06,  1.3229e-05, -8.7357e-06,\n",
            "         1.8868e-05,  1.2983e-06, -2.3239e-06, -2.4680e-06, -6.5758e-06,\n",
            "         1.0095e-05,  5.6343e-06,  3.7580e-06,  5.3684e-06,  8.7659e-06,\n",
            "         3.1794e-06,  4.5977e-06, -1.5672e-05,  2.3622e-07, -2.6818e-05,\n",
            "        -2.0239e-05, -7.8982e-06,  7.6233e-06,  1.3125e-06,  4.0207e-04,\n",
            "         2.2386e-06, -1.8036e-07, -2.9719e-05, -2.4614e-05,  1.1396e-06,\n",
            "         1.0398e-06,  1.8449e-05, -2.0171e-06,  4.9899e-06,  2.4490e-06,\n",
            "         8.0253e-06,  1.2502e-05,  2.0042e-06, -1.2611e-05, -3.4005e-05,\n",
            "        -5.9710e-06,  1.8232e-05,  1.8624e-05, -2.9423e-05,  1.8244e-06,\n",
            "        -1.1150e-06,  6.4435e-06, -5.2897e-09,  1.0069e-05,  1.6739e-05,\n",
            "        -3.3586e-06,  1.0847e+00, -2.1784e-07,  7.2320e-06, -1.5195e-05,\n",
            "         8.8445e-02,  4.0389e-06, -1.2402e-05, -7.6444e-06, -1.7917e-05,\n",
            "        -1.9527e-07,  3.8266e-05,  2.5954e-01, -2.4878e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3369e-01, -1.4887e-05,  8.6693e-06, -3.6624e-05,  7.8960e-06,\n",
            "          1.3428e-05,  2.3502e-06,  1.5467e-07, -4.2767e-06,  1.1662e-05,\n",
            "         -2.4815e-05, -3.0798e-05, -9.4937e-06,  1.0013e-05, -3.8551e-07,\n",
            "          4.1810e-05,  2.7402e-06, -2.4333e-06, -1.2639e-05, -1.6510e-05,\n",
            "         -6.4075e-06, -7.5373e-06,  1.6203e-05, -2.2504e-05,  5.4639e-01,\n",
            "          1.0464e-05,  3.4149e-05, -1.7465e-05, -1.2248e-05, -1.4403e-05,\n",
            "         -3.8478e-05, -2.0181e-06,  1.7241e-06, -2.2867e-05,  1.6058e-05,\n",
            "          9.5438e-06, -2.7257e-06, -1.5438e-05, -3.1336e-07, -9.0462e-06,\n",
            "          2.9673e-06, -9.7018e-07,  1.6819e-05, -2.8250e-05, -1.7803e-05,\n",
            "         -7.6756e-06, -4.2891e-06, -8.4799e-07,  1.9986e-05, -4.0226e-06,\n",
            "         -1.3382e-05,  3.2328e+00, -6.9571e-06, -3.2771e-06,  1.2738e-05,\n",
            "          7.8310e-01,  2.0582e-05,  9.3212e-06, -1.7605e-05, -1.2542e-05,\n",
            "         -3.5611e-06, -5.8446e-07,  1.0856e+00,  2.3953e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3094], requires_grad=True)\n",
            "l1_reg is: 30.134376525878906\n",
            "total_loss 1.26252281665802\n",
            "pred: tensor([24.2082,  9.9862,  6.4876, 25.0738, 21.0599, 14.9897, 27.8038, 26.9919,\n",
            "         5.0519, 13.4312, 27.3576, 12.4919, 18.3308, 15.5120, 22.9588, 19.8097,\n",
            "         9.3711, 18.2219, 20.4028, 17.3378, 14.6038, 16.7602,  9.9478,  5.7816,\n",
            "        10.1701, 24.4864, 11.6253, 11.1606, 20.8985, 27.1742, 18.4988,  8.7965,\n",
            "        14.9463,  9.4525, 10.3402, 26.9199, 19.5326, 10.6034, 24.3060, 25.7911,\n",
            "        14.4616, 23.9216, 24.9427,  3.0962,  9.2641, 28.1710, 27.1124,  5.0604,\n",
            "        25.3112, 26.0372, 13.0037,  5.3235, 12.0037, 15.6879, 10.7238, 33.7125,\n",
            "         5.8443, 11.2451, 12.6985, 11.9635,  6.2067, 19.0509,  4.5676,  5.0485,\n",
            "         5.0886, 24.9438, 16.0225, 21.7635,  6.1541, 25.6258, 14.8768, 13.0937,\n",
            "        24.5026,  6.1412, 24.7588, 10.5325, 13.1690, 27.3819, 25.8660, 36.4001,\n",
            "        19.0481, 14.7518, 30.9603,  6.6372, 25.9086, 22.8124, 15.3402, 21.5661,\n",
            "        11.7569, 28.3609, 19.4676, 16.0944, 10.0734, 13.8523, 25.1829,  4.6268,\n",
            "        19.8368,  7.6343, 16.1049, 31.2015,  3.1380,  5.9302, 15.5897, 23.0618,\n",
            "        17.1739, 26.9365, 19.4625, 19.1136, 24.5936, 23.0678, 26.3263, 11.5197,\n",
            "        11.5539, 25.4911, 24.0932, 25.4391,  5.4543, 10.8686,  7.7295, 16.8888,\n",
            "        23.6973,  9.7314, 26.7387, 22.4739, 20.4446,  8.4517, 14.4770, 24.2571,\n",
            "        13.0628, 21.9359, 10.6487, 12.5463, 16.5232, 24.9695, 21.9581, 17.5323,\n",
            "         8.7083, 17.3734,  9.9603, 13.3338, 22.2552, 16.1541, 17.6860,  2.8441,\n",
            "        25.3442, 27.3361, 29.7696, 14.2719, 11.1225, 14.1152, 12.7738, 15.4045,\n",
            "        28.8563,  7.2529, 13.6855, 23.7472,  7.7385, 10.4094, 35.7366, 15.0747,\n",
            "        10.8399,  8.9406, 27.5481, 22.3348, 24.2028, 12.3675, 13.3755, 11.3328,\n",
            "        11.6508, 28.0833,  9.0690,  5.7458, 33.2218, 17.2733, 24.1408,  7.1667,\n",
            "        16.5433, 18.2131,  6.0506,  2.8124,  9.6086, 26.6211, 25.3331, 16.1329,\n",
            "        10.7131, 23.4124, 11.0204, 20.6740, 16.1667, 25.6347,  6.9893,  9.6203,\n",
            "         7.5857, 12.9320, 23.4857, 34.8777, 17.0587, 18.4741, 26.6966, 27.0150,\n",
            "         8.3631, 21.5273, 26.9681, 11.3497, 20.2889,  2.6854,  9.2063, 14.0959,\n",
            "        17.3160,  9.1640, 14.9176, 23.4545, 40.5640, 12.9084,  9.7808,  3.6492,\n",
            "        13.9909, 25.6449, 22.4241, 20.5382, 15.5571, 31.7035, 18.3762, 17.6512,\n",
            "        17.8402,  9.0835, 10.4211, 21.0517, 10.0846, 13.9015, 16.5306,  2.9929,\n",
            "         7.5357,  9.3971, 21.7318,  8.1889, 17.8716, 20.4077, 25.0305,  9.9725,\n",
            "        14.0336, 16.4349,  8.8245, 14.9953,  7.1888, 25.6031, 13.9225, 25.0796,\n",
            "        15.7118,  6.4980, 10.0569, 16.0438, 19.2776, 14.4774, 21.0416,  3.5571,\n",
            "         8.6475, 14.9078, 22.9494, 31.9320, 13.9154, 21.7250, 10.7391, 26.6369,\n",
            "        22.5050, 13.8637,  9.1411, 33.7008, 19.1690,  8.7969],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([24.6835,  9.9684,  6.6393, 24.6041, 21.1748, 15.6772, 28.6885, 26.4615,\n",
            "         4.5205, 12.8787, 28.0782, 12.0725, 18.8559, 13.7427, 24.1517, 19.8214,\n",
            "         9.2548, 16.8981, 20.3443, 17.6570, 14.6175, 13.7531,  9.5381,  5.6481,\n",
            "        10.5208, 23.0245, 11.9273, 11.5024, 21.0445, 26.1253, 18.6484,  8.7883,\n",
            "        14.3155,  8.4304, 11.0542, 25.9151, 18.8388, 10.8934, 23.4127, 26.2010,\n",
            "        18.2203, 24.1348, 25.2111,  3.2051,  9.5773, 27.1687, 25.0308,  5.7059,\n",
            "        23.7457, 24.9680, 13.5947,  5.9271, 11.8088, 13.3208, 10.4350, 32.7656,\n",
            "         6.3338, 11.6967, 14.3835, 12.6981,  5.9249, 22.1965,  5.5891,  5.5058,\n",
            "         5.6577, 23.7816, 16.1891, 22.0167,  5.7317, 25.9815, 15.0254, 13.4758,\n",
            "        24.4002,  6.6406, 24.2194, 11.3787, 13.0089, 28.0444, 25.8158, 36.0293,\n",
            "        17.5696, 15.3904, 30.0670,  7.2034, 26.6461, 23.0122, 15.4052, 21.4369,\n",
            "        12.8784, 27.8580, 19.0364, 15.4793, 10.3077, 13.9880, 25.8577,  4.7112,\n",
            "        20.1903,  8.4529, 15.1120, 29.7360,  2.9864,  5.4318, 19.1049, 22.7719,\n",
            "        16.3948, 27.5952, 19.8536, 17.9237, 24.5242, 24.1536, 27.0808, 11.6439,\n",
            "        11.7910, 25.4995, 24.7277, 22.6075,  5.5773, 10.4645,  7.0025, 16.8294,\n",
            "        25.1746,  9.6956, 26.3140, 21.3269, 21.3147,  7.4995, 15.0729, 24.2404,\n",
            "        13.7270, 22.3144,  9.8279, 11.2336, 16.1458, 25.7940, 24.7259, 17.7887,\n",
            "         9.4538, 18.7081, 11.7508, 13.3394, 20.9747, 17.0052, 17.2109,  3.2285,\n",
            "        24.6225, 26.6688, 28.9013, 13.7214, 10.9784, 13.9888, 12.8408, 15.3285,\n",
            "        28.5535,  7.6659, 13.7023, 22.6914,  9.1024, 10.2239, 36.1161, 15.1577,\n",
            "        11.1362,  9.7051, 27.9312, 23.5169, 22.4621, 11.4345, 13.4434, 11.5051,\n",
            "        12.6276, 27.5793,  9.0185,  6.0440, 35.8095, 16.5230, 23.1402,  7.1256,\n",
            "        17.6301, 19.6065,  6.1239,  3.5024,  8.6810, 26.7881, 25.9682, 14.8657,\n",
            "        10.5463, 23.0878, 10.6852, 18.7199, 17.5000, 25.2012,  6.8889,  9.4634,\n",
            "         8.1662, 13.1111, 21.9457, 33.9005, 16.5146, 20.6139, 26.7285, 26.3991,\n",
            "         8.0456, 21.9609, 28.2931, 11.2653, 21.1832,  2.7559,  9.6741, 13.2863,\n",
            "        17.4472,  8.1231, 15.0697, 23.8618, 40.0833, 12.4763,  9.7303,  3.7662,\n",
            "        13.4865, 25.3007, 21.6788, 20.4992, 15.6797, 29.8007, 16.5177, 15.5175,\n",
            "        16.6666,  8.6658, 11.2250, 19.6756,  9.8001, 13.5445, 14.5522,  2.4964,\n",
            "         8.2609, 10.5634, 22.3171,  8.2677, 18.8259, 19.9225, 22.4271,  9.5906,\n",
            "        12.5427, 16.6770,  8.8821, 15.6983,  7.4115, 24.4827, 14.8241, 24.4258,\n",
            "        16.4102,  7.2207,  8.9286, 16.4249, 19.3560, 14.1756, 22.2998,  3.7462,\n",
            "         8.3654, 14.7196, 23.2249, 32.4405, 13.5145, 21.8326, 10.8127, 25.9839,\n",
            "        23.3532, 14.4099,  8.9869, 33.4135, 19.2292,  8.8057])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.2546e-05, -1.7282e-05,  4.3886e-06,  ..., -3.8733e-06,\n",
            "         -1.1109e-06, -2.2206e-06],\n",
            "        [ 8.4302e-05, -1.8250e-04,  8.5626e-06,  ..., -3.5855e-04,\n",
            "          2.3250e-04,  6.9550e-05],\n",
            "        [-2.6867e-04, -2.1351e-04,  1.7804e-05,  ...,  3.7871e-02,\n",
            "         -4.0027e-06, -2.5982e-03],\n",
            "        ...,\n",
            "        [-7.6603e-06, -1.3961e-07, -7.4984e-06,  ...,  7.0061e-06,\n",
            "         -5.8084e-06, -1.7678e-05],\n",
            "        [-1.3985e-05,  6.8579e-08,  1.6823e-06,  ...,  2.2775e-06,\n",
            "         -6.8048e-06,  1.8133e-05],\n",
            "        [ 3.1759e-05, -2.8626e-05,  8.6622e-06,  ...,  1.3905e-07,\n",
            "         -1.4008e-05,  1.3206e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 2.6065e-06,  4.2392e-01,  3.6508e-02,  4.5939e-06, -8.7574e-06,\n",
            "         1.4290e-05,  1.6335e-05, -1.2512e-05,  1.5815e+00,  9.8761e-06,\n",
            "        -1.0991e-05, -1.4201e-05,  5.2369e-06, -2.2756e-05,  2.6335e-05,\n",
            "         5.2299e-06, -2.1549e-05,  2.2338e-05, -1.0731e-05,  3.3912e-06,\n",
            "        -4.1173e-08, -1.0772e-07, -1.6662e-07,  9.4727e-06, -8.5592e-06,\n",
            "        -2.6508e-05, -8.4146e-06,  1.3383e-01, -3.7445e-06,  9.1334e-06,\n",
            "         1.5893e-05,  1.3458e-05,  1.3659e-05,  2.8749e-01, -1.9002e-06,\n",
            "         4.2498e-06, -2.9224e-06,  2.9173e-06,  1.2016e-05, -1.1410e-05,\n",
            "         2.3130e-05,  2.5351e-05, -4.0983e-05, -4.1694e-08,  4.3250e-06,\n",
            "         1.7560e-05,  2.3596e-05,  1.0829e-05, -1.9461e-06, -2.1707e-04,\n",
            "         1.3712e-05,  5.1585e-06, -8.1930e-06,  8.1747e-06,  1.4948e-05,\n",
            "        -8.7925e-06, -3.7856e-04, -5.1146e-06,  3.8674e-06, -1.5699e-05,\n",
            "         1.4046e-05, -1.3292e-05,  6.3472e-07,  5.6836e-06,  6.7287e-06,\n",
            "        -1.4075e-05,  4.4521e-05, -4.7947e-06,  7.7260e-06,  9.2325e-02,\n",
            "         4.6866e-06, -2.4505e-05, -1.9027e-05, -1.9285e-06,  3.6378e-06,\n",
            "        -5.8454e-06, -1.0302e-05,  4.8771e-06,  1.5759e-05, -1.5499e-03,\n",
            "        -6.9900e-06, -1.6315e-05, -3.6978e-06,  7.0740e-06, -5.9046e-06,\n",
            "        -2.0784e-06, -3.0551e-07, -1.7300e-05,  3.0338e-05, -3.1252e-06,\n",
            "         9.1958e-06,  2.1683e-05,  1.5900e-05,  1.6473e-05,  6.5035e-06,\n",
            "        -8.3999e-07,  1.1482e-05, -6.9854e-07, -4.0417e-05, -2.7679e-06,\n",
            "         3.1191e-04, -2.4717e-06, -7.6713e-06,  9.3625e-06,  4.1468e-06,\n",
            "        -5.5164e-06,  4.4264e-06,  6.0710e-06,  9.7693e-06, -8.9613e-06,\n",
            "        -1.6820e-05,  9.6722e-07,  3.2360e-05,  9.5365e-06,  4.7362e-06,\n",
            "        -3.8478e-05,  1.6270e-05, -1.9183e-05, -5.1026e-06,  5.2648e-06,\n",
            "         1.2624e+00, -1.0575e-06, -1.8899e-07, -2.4278e-05,  9.6207e-06,\n",
            "         1.0715e-05,  8.6053e-06,  9.0281e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.0119e-05,  1.0164e-04, -4.8176e-05,  ...,  6.4239e-06,\n",
            "         -3.1512e-06, -1.2905e-05],\n",
            "        [-5.7094e-06, -6.3427e-06, -1.7972e-05,  ...,  7.7628e-06,\n",
            "         -1.2156e-05,  9.8569e-06],\n",
            "        [-2.7040e-05,  1.0549e-05, -4.7865e-06,  ...,  1.3986e-05,\n",
            "          7.2404e-07, -5.3314e-06],\n",
            "        ...,\n",
            "        [ 8.7048e-06,  3.0591e-06,  1.0653e-05,  ..., -7.8447e-07,\n",
            "          3.8981e-06, -1.3339e-05],\n",
            "        [ 8.0772e-06,  1.7613e-04, -2.7578e-06,  ..., -6.2593e-06,\n",
            "         -9.2872e-06, -3.7547e-07],\n",
            "        [-1.5488e-05, -1.1682e-04, -2.5312e-04,  ...,  7.4594e-06,\n",
            "          1.5451e-06,  8.8203e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3401e-02,  5.1574e-06,  8.2949e-06, -7.5361e-06,  1.7013e-05,\n",
            "         2.9224e-05, -2.1459e-06,  1.6130e-06, -7.9053e-07,  2.1368e-06,\n",
            "        -4.4733e-06, -1.0046e-05,  6.9474e-06,  6.9299e-06,  8.9395e-06,\n",
            "         1.0208e-06, -7.9532e-06, -1.0698e-05, -3.2440e-06, -1.4855e-05,\n",
            "        -6.5436e-06, -1.2010e-05, -1.6206e-06, -1.7611e-05,  6.2242e-04,\n",
            "         5.9145e-06,  1.2772e-05, -2.7706e-05, -1.5738e-05, -1.6530e-05,\n",
            "         4.7810e-07,  1.3473e-05,  2.4718e-06, -6.0640e-06,  6.5554e-06,\n",
            "         6.0986e-06,  3.7775e-06, -1.1407e-05, -1.4690e-05, -3.5862e-05,\n",
            "        -1.4665e-05, -1.2004e-06,  1.2558e-05, -2.8754e-05,  3.2527e-06,\n",
            "         1.2307e-05,  9.7331e-06,  1.3408e-05, -1.0679e-05,  1.7748e-05,\n",
            "        -1.0960e-05,  1.0855e+00,  3.3838e-06, -1.0089e-05, -1.9362e-05,\n",
            "         8.8553e-02,  6.3320e-07,  2.0742e-06, -9.2842e-06, -2.6613e-05,\n",
            "         1.5477e-05,  2.9930e-05,  2.5973e-01, -2.7633e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3359e-01, -2.3550e-05, -8.0668e-06, -2.8315e-05, -1.2027e-06,\n",
            "          8.1394e-06, -4.5027e-06, -1.1807e-05, -4.6462e-06, -8.3089e-06,\n",
            "         -7.3233e-06, -2.2436e-05, -1.3570e-05,  3.6968e-06,  1.0569e-05,\n",
            "          4.7607e-05, -7.7420e-06, -4.9003e-06, -1.8220e-05, -2.2661e-05,\n",
            "         -7.3891e-06,  1.3272e-05,  2.6286e-05, -3.0978e-06,  5.4629e-01,\n",
            "          1.8499e-05,  2.5791e-05, -1.1325e-05,  3.4232e-06, -6.2519e-06,\n",
            "         -3.0155e-05,  4.8466e-06, -1.6675e-05, -1.8756e-05,  2.0851e-05,\n",
            "         -7.1652e-06, -3.7023e-06, -1.9532e-05, -7.8197e-06, -1.7047e-05,\n",
            "         -1.5400e-05,  9.5221e-06,  2.3628e-05, -5.3545e-06, -1.1496e-05,\n",
            "         -9.3184e-06,  4.4099e-06,  1.6862e-05, -4.6800e-06,  4.6929e-06,\n",
            "         -1.0932e-05,  3.2354e+00, -1.0247e-05,  1.7496e-05, -2.9069e-06,\n",
            "          7.8307e-01,  7.1924e-06, -6.3855e-06, -1.2661e-05,  1.9219e-06,\n",
            "         -1.1203e-05,  1.7101e-05,  1.0859e+00,  2.3943e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3096], requires_grad=True)\n",
            "l1_reg is: 30.18265151977539\n",
            "total_loss 1.158647894859314\n",
            "pred: tensor([28.9979, 24.3437,  5.2431, 15.1748, 10.0877, 25.5754, 30.0768, 25.9167,\n",
            "        25.2411, 16.8526, 11.5774, 20.8215, 10.9452, 24.1444, 36.0233, 21.2443,\n",
            "        38.9887,  7.8134, 20.2055, 20.3377, 25.1120,  6.8976, 11.2026, 23.3927,\n",
            "        30.8676,  6.9986, 16.5996, 19.9963, 25.0334, 21.4932, 20.6181, 28.7633,\n",
            "         8.3943, 20.7246, 33.4578, 27.0709, 24.3231,  6.3933,  4.9654, 29.5987,\n",
            "        10.4759,  2.7627,  6.0822, 21.2995, 10.6020, 25.0256,  8.8373,  3.5624,\n",
            "        15.5060,  7.4026, 26.7802, 13.1256, 14.3607,  9.0074, 13.0132, 16.6924,\n",
            "        15.3770, 17.2604, 11.8890, 17.4877, 12.7775, 21.6774, 11.8122, 24.8606,\n",
            "         7.8883, 14.1968, 24.4502, 13.7108, 27.0918, 25.9111, 12.9850, 13.3328,\n",
            "        16.6039, 20.1132, 22.7954,  8.6505, 15.7485, 13.6153, 20.5300, 12.8555,\n",
            "        16.9631, 31.6907,  8.1846,  9.7830, 19.3307, 19.2594, 19.6278, 16.3813,\n",
            "        25.0757, 26.0346,  4.3756, 25.4817, 13.8725, 11.3232, 25.4308, 20.1438,\n",
            "         2.8462,  9.1959, 38.3179, 16.6142, 28.8672, 23.2041, 14.7311,  5.7689,\n",
            "        21.5461, 34.9601, 21.1045, 21.2601,  8.1578, 32.1619,  7.8731, 26.6217,\n",
            "        24.9529,  2.7963,  6.6365, 28.4775, 13.7732, 12.8937, 16.2570,  9.4673,\n",
            "        10.2070, 22.0529, 28.2032, 14.5433, 11.4640,  7.4814, 12.2245,  8.8741,\n",
            "         9.4965,  8.8605,  9.8995,  9.3810, 20.5158, 21.3562,  6.1889, 20.1099,\n",
            "        22.6987, 22.5093,  3.2082, 28.5687, 10.9977,  6.7478,  5.1486, 31.9176,\n",
            "        16.5204, 24.4129, 16.0904, 12.7538, 24.4311, 23.3118, 26.1302,  8.3489,\n",
            "         5.2167, 23.5057, 23.0234, 11.3550, 10.5486, 17.1205, 12.2116,  8.5981,\n",
            "        10.8567,  9.2867, 20.3541, 17.9139, 27.4361, 27.1201, 22.0141, 23.6423,\n",
            "        25.3318, 19.4893, 24.3859, 23.0402, 23.9767,  6.6229,  3.0847, 13.5940,\n",
            "        25.4131, 14.8052, 16.9821,  4.7861,  4.9785,  4.9181, 26.2774,  5.0930,\n",
            "        25.1116, 23.6683, 13.6978,  4.3625, 13.0159, 26.8613, 10.0922, 17.4175,\n",
            "        13.6217, 23.7370, 21.8522, 23.4472, 22.1824, 19.8785,  8.5668, 16.4015,\n",
            "        24.4331, 27.7575, 12.1483, 26.5842, 14.1884, 20.0950, 10.5849, 10.2656,\n",
            "        10.3981, 15.3914, 11.3240, 15.5000,  2.9826, 10.7555, 12.5347, 18.6893,\n",
            "        26.9117, 22.0412, 17.1865, 11.1700, 26.7845,  3.5637, 25.5128, 28.1244,\n",
            "        25.6797, 26.2284, 13.1768, 12.0845,  2.5514, 22.9682, 14.7558, 33.8347,\n",
            "        22.2936, 10.0958, 13.3066,  6.1487, 26.0242, 14.4312,  3.0096,  9.4663,\n",
            "        17.0679, 21.1966, 14.9319,  9.9485, 21.1879, 19.6163, 32.9346,  9.0551,\n",
            "        14.7131, 14.6907, 13.1816, 13.0734, 25.3970, 21.1105,  6.3660, 23.3195,\n",
            "        31.7839, 12.0500, 27.1207, 22.3358, 10.4708,  9.0248, 19.7043,  5.5953,\n",
            "        19.2942, 22.4601,  9.1389, 38.1773,  5.8145, 20.3856],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([28.4644, 24.4859,  4.9688, 15.8363, 10.4626, 24.6207, 28.5692, 25.7795,\n",
            "        24.7070, 17.3651, 11.8580, 21.1793,  9.6923, 25.3044, 35.9483, 20.4319,\n",
            "        40.9595,  7.2917, 19.6534, 19.4142, 23.7793,  6.9476, 11.3636, 23.2997,\n",
            "        30.5375,  6.8069, 15.7061, 19.5858, 23.2263, 22.0374, 20.3744, 29.0553,\n",
            "         8.9872, 21.2043, 30.6897, 25.7246, 23.6816,  6.1372,  4.6879, 30.1335,\n",
            "         9.1734,  2.3849,  5.6991, 20.2926, 11.1280, 24.6654,  9.2650,  3.8793,\n",
            "        15.1563,  8.0952, 25.5729, 14.3308, 14.7628,  8.9678, 13.5729, 15.7272,\n",
            "        15.4191, 15.3333, 12.1094, 17.4771, 12.1835, 21.5825, 12.2582, 24.0307,\n",
            "         8.9939, 14.1613, 24.7383, 13.7884, 29.4108, 25.9019, 12.5976, 13.3160,\n",
            "        16.0947, 20.9017, 21.6413,  8.5499, 14.8438, 13.4445, 20.6294, 12.6138,\n",
            "        15.3266, 32.4809,  9.1936,  9.5076, 19.4010, 18.8843, 16.7639, 16.8874,\n",
            "        26.0153, 25.2843,  4.2411, 25.0908, 13.8385, 11.8142, 24.3212, 20.4491,\n",
            "         2.7578, 10.0694, 37.4974, 17.0279, 29.6881, 22.6680, 15.7058,  7.2487,\n",
            "        21.2428, 33.9546, 21.4626, 22.9497,  9.5607, 32.0161,  8.5251, 25.4348,\n",
            "        23.4348,  2.6932,  5.0321, 27.6106, 12.5554, 12.8185, 16.1945, 10.3742,\n",
            "         9.3224, 23.3380, 26.5894, 14.0640, 12.9823,  8.9623, 12.4759,  8.9643,\n",
            "         8.1884,  8.7413,  9.7813,  9.8642, 21.2700, 23.3032,  6.2891, 19.0391,\n",
            "        22.7183, 22.3817,  3.9971, 25.8522, 11.6278,  7.5861,  4.2355, 32.6551,\n",
            "        15.0229, 23.7807, 16.1949, 13.1175, 23.9864, 21.3639, 28.1735,  7.4468,\n",
            "         5.8940, 23.2959, 21.4063, 10.8215, 10.2500, 17.1899, 13.7664,  8.7217,\n",
            "        10.8996,  8.7501, 20.1553, 16.3677, 26.4274, 27.4474, 20.8610, 23.9096,\n",
            "        25.0183, 19.6373, 23.2866, 22.5572, 22.0525,  6.1462,  2.9352, 13.8511,\n",
            "        24.4875, 16.1818, 16.0898,  4.9312,  5.8053,  5.2190, 25.5555,  5.8917,\n",
            "        25.6026, 23.0805, 13.5708,  4.3382, 13.0704, 27.1144, 10.5818, 17.0326,\n",
            "        12.8462, 22.9610, 22.0113, 22.6298, 22.3404, 20.3797,  9.8713, 15.4962,\n",
            "        24.2602, 27.5510, 10.0535, 26.7993, 14.4771, 19.9049, 11.1947,  9.5306,\n",
            "         9.3152, 15.7985, 11.3396, 15.5172,  2.9360, 12.4807, 12.1004, 19.1647,\n",
            "        27.2260, 20.3049, 18.8468, 12.8317, 25.1932,  4.2308, 24.3132, 26.6424,\n",
            "        25.5564, 25.0153, 13.4633, 12.4330,  2.6613, 21.9498, 14.3836, 33.1963,\n",
            "        21.5721, 11.2572, 11.9910,  5.7616, 24.8022, 14.5788,  2.6391,  9.4792,\n",
            "        18.3335, 23.0469, 14.9827, 10.4300, 19.3209, 18.7337, 32.2881,  9.7285,\n",
            "        15.1129, 14.6009, 12.3256, 13.1744, 24.9036, 21.7023,  6.4091, 24.4763,\n",
            "        28.4758, 12.3930, 26.1066, 22.8967,  9.6728,  9.2040, 19.2695,  6.0344,\n",
            "        15.5303, 22.2177,  9.6395, 38.0346,  6.2500, 21.4280])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 7.3689e-06, -2.5971e-05,  8.1335e-06,  ..., -7.9764e-06,\n",
            "          1.4563e-05, -4.6829e-06],\n",
            "        [ 8.1866e-05, -1.9136e-04,  1.4882e-05,  ..., -4.9744e-04,\n",
            "          1.8303e-04,  2.8095e-04],\n",
            "        [-2.9228e-04, -2.2053e-04,  1.6713e-05,  ...,  3.7715e-02,\n",
            "          4.1538e-04, -2.2094e-03],\n",
            "        ...,\n",
            "        [ 9.3461e-07,  4.1623e-06, -8.6058e-07,  ...,  7.4669e-06,\n",
            "          1.4796e-06, -1.2967e-05],\n",
            "        [-2.0199e-06, -9.3672e-06, -1.6709e-05,  ..., -1.3407e-05,\n",
            "          1.5501e-05, -1.3086e-06],\n",
            "        [ 8.8717e-06, -1.8141e-05,  1.3937e-07,  ..., -8.8094e-06,\n",
            "          6.7819e-06,  1.2285e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 2.0747e-06,  4.2392e-01,  3.6823e-02, -1.8019e-05,  1.0752e-06,\n",
            "        -5.4728e-06,  2.6270e-05, -1.4593e-05,  1.5821e+00, -1.0916e-05,\n",
            "         2.8945e-06,  9.7145e-07,  1.4342e-06, -3.3416e-05,  4.1254e-05,\n",
            "        -1.0431e-05, -1.7417e-05,  2.0150e-05, -1.0560e-05, -2.4014e-05,\n",
            "         1.4209e-05,  1.6402e-05, -1.5066e-06, -6.2168e-06, -2.2349e-06,\n",
            "        -4.1310e-05,  4.2845e-06,  1.3390e-01,  7.9069e-06, -7.2216e-07,\n",
            "         8.0608e-06,  7.1265e-06, -1.9255e-06,  2.8772e-01,  1.3780e-05,\n",
            "        -3.2055e-06,  1.0498e-05, -1.2733e-05,  1.6133e-05, -1.6993e-05,\n",
            "         2.0958e-05,  1.4406e-05, -4.4315e-05,  1.1923e-05, -1.2976e-05,\n",
            "         5.5947e-06,  1.9484e-05,  4.5096e-06,  1.8805e-05, -1.3053e-04,\n",
            "         5.8164e-06, -5.3189e-06, -1.5431e-06, -7.4956e-06, -5.8212e-06,\n",
            "        -8.9873e-06, -1.4623e-04, -5.6854e-06, -7.3457e-07, -6.6143e-06,\n",
            "         8.8360e-06, -1.7630e-05, -2.0117e-05, -1.0009e-05,  4.9251e-06,\n",
            "        -1.9734e-06,  3.7519e-05, -6.2463e-06,  1.6428e-05,  9.2276e-02,\n",
            "        -1.2647e-05, -1.3618e-05, -5.3261e-06, -8.6843e-07,  7.3170e-06,\n",
            "         7.1017e-06, -1.5641e-05, -1.5871e-05,  9.4430e-06, -1.2905e-03,\n",
            "         4.7011e-06, -1.7314e-05, -3.1454e-06,  8.0834e-06,  9.7568e-06,\n",
            "         9.8740e-06,  1.2365e-05, -5.3557e-06,  2.8563e-05,  8.7901e-06,\n",
            "        -1.3137e-06,  1.7554e-05,  2.4591e-05,  2.6413e-05,  1.5090e-05,\n",
            "         3.0376e-07,  1.3780e-05,  3.4647e-06, -4.3737e-05,  1.5616e-05,\n",
            "         4.6832e-04,  8.0234e-06,  9.0089e-07,  3.0629e-06, -9.8507e-06,\n",
            "         2.2593e-06,  5.8744e-06, -4.4091e-06, -5.9283e-06, -2.6220e-06,\n",
            "        -2.3356e-05,  3.3975e-06,  3.1907e-05, -2.8454e-07,  3.1047e-07,\n",
            "        -2.2284e-05,  4.3186e-06, -1.3017e-05, -9.2185e-06,  8.5564e-06,\n",
            "         1.2628e+00, -3.1959e-07,  1.3565e-05, -1.2318e-05,  3.3642e-06,\n",
            "        -3.7627e-06,  1.0251e-05,  9.7630e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 2.0779e-06,  1.7394e-04,  1.9603e-05,  ..., -8.5482e-07,\n",
            "          3.7317e-06, -4.7468e-06],\n",
            "        [-8.9041e-06, -3.5124e-06, -6.0153e-06,  ...,  1.4586e-06,\n",
            "         -2.0845e-05,  9.9690e-06],\n",
            "        [-2.4860e-05,  1.1304e-05,  1.7539e-05,  ...,  6.1166e-06,\n",
            "         -5.1868e-06,  1.0342e-05],\n",
            "        ...,\n",
            "        [ 6.7781e-06, -1.0267e-05,  3.6587e-06,  ...,  8.4233e-06,\n",
            "         -3.4167e-06,  7.4262e-06],\n",
            "        [-8.7957e-06,  3.1104e-04,  9.9680e-05,  ...,  5.4689e-06,\n",
            "          5.3560e-06,  3.9212e-06],\n",
            "        [-7.4241e-06, -1.1333e-04, -2.6817e-04,  ..., -1.1299e-06,\n",
            "          4.5685e-06,  6.9102e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3392e-02,  5.7119e-06, -2.9553e-07, -1.6223e-05,  3.0186e-05,\n",
            "         2.8543e-05,  4.7537e-06, -4.8437e-06,  1.0720e-05, -2.0312e-08,\n",
            "        -7.5849e-06, -1.4158e-05, -1.8201e-07, -1.6649e-06, -9.0509e-07,\n",
            "        -1.0923e-05, -9.2490e-06,  3.7789e-06,  3.6227e-06,  5.9117e-06,\n",
            "         1.5782e-05, -5.7127e-06,  5.9770e-08, -2.4642e-05,  7.7384e-04,\n",
            "        -7.7642e-07,  1.4427e-05, -1.5895e-05,  2.2499e-06, -2.2432e-05,\n",
            "        -1.0024e-05, -1.0050e-06, -3.4870e-06, -6.0128e-06,  2.5121e-07,\n",
            "        -5.6349e-06, -1.4074e-05, -1.3478e-05, -6.5611e-06, -2.7534e-05,\n",
            "        -1.2488e-05, -8.6893e-06, -2.9040e-06, -1.8151e-05, -5.4619e-06,\n",
            "         1.4386e-05,  2.6940e-06,  1.5482e-05, -1.9352e-05,  8.6553e-06,\n",
            "        -7.8009e-06,  1.0859e+00, -3.3752e-06, -1.5678e-05, -1.3113e-05,\n",
            "         8.8587e-02, -1.2432e-05,  5.1037e-06, -7.6043e-07, -2.4439e-05,\n",
            "         1.9582e-05,  1.2426e-05,  2.5982e-01, -2.9112e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3349e-01, -2.1347e-05, -1.3129e-05, -1.0838e-05,  5.9745e-07,\n",
            "         -6.6312e-06, -6.6880e-07, -1.2573e-05,  5.0196e-06, -1.6287e-05,\n",
            "          1.8420e-05, -4.9103e-06, -7.2391e-06, -1.1988e-05,  1.0416e-05,\n",
            "          4.2821e-05, -7.1759e-06,  2.8689e-06, -1.3241e-05, -1.8197e-05,\n",
            "          1.7212e-06,  2.1996e-05,  2.5360e-05,  2.4362e-05,  5.4619e-01,\n",
            "          1.5732e-05,  8.2673e-06,  4.2004e-06,  7.5251e-06,  1.1084e-05,\n",
            "         -1.2668e-05,  1.0257e-06, -2.3238e-05, -5.0563e-06,  1.5164e-05,\n",
            "         -1.2208e-05,  5.4158e-06, -1.3216e-05, -4.5754e-06, -1.4247e-05,\n",
            "         -2.1931e-05,  8.9673e-06,  1.9749e-05,  2.5252e-05,  4.1789e-06,\n",
            "         -7.9576e-07,  2.2410e-06,  2.2801e-05, -1.6889e-05,  2.5264e-06,\n",
            "          1.2740e-06,  3.2367e+00, -3.2072e-06,  2.6193e-05, -6.9944e-06,\n",
            "          7.8300e-01, -1.4859e-05, -1.0523e-05,  1.7878e-06,  4.9394e-06,\n",
            "         -8.0938e-06,  2.3013e-05,  1.0860e+00,  2.3933e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3096], requires_grad=True)\n",
            "l1_reg is: 30.251020431518555\n",
            "total_loss 1.1802120208740234\n",
            "pred: tensor([10.3015,  6.4002, 16.6174, 21.4501,  9.4219, 12.3609, 21.9615, 20.7622,\n",
            "        10.6472, 11.6936, 24.6840, 17.1543, 17.5774, 26.3744, 13.2520,  4.8980,\n",
            "        24.8696, 12.5986,  3.7571, 18.4120, 13.4562, 15.6132, 29.7993, 11.2494,\n",
            "        12.8631, 22.2703, 24.0459,  8.8241, 13.2089,  2.8989, 28.6607,  9.7460,\n",
            "         8.0328, 18.1213,  5.4257, 20.8864, 20.5084, 18.5861, 28.9619, 15.5034,\n",
            "         5.8208, 10.6702, 24.8555,  3.8840, 28.3345,  9.7102,  5.4784, 10.9696,\n",
            "        29.0723, 12.2296,  5.5132, 26.9020, 22.3594, 21.7376,  3.2419,  3.7024,\n",
            "        25.8085, 10.1510, 16.4665, 23.9175,  7.7495, 24.7206, 25.1138, 16.7699,\n",
            "        12.6848, 10.9710, 15.2852, 16.9476, 21.8170, 10.3798, 10.1145,  9.6389,\n",
            "        21.2439, 16.2982,  6.9383, 15.1710,  9.5552,  7.0667,  5.7505, 19.8196,\n",
            "         4.1571,  6.5600, 13.7372, 10.6377, 11.3270, 34.1070, 25.4368, 13.0373,\n",
            "         9.7129, 12.3913,  9.8465, 13.5139, 17.7763, 12.7371, 13.5483,  3.5263,\n",
            "        18.5171, 12.5062, 20.8728, 20.8714, 17.2589, 24.5451, 13.3478, 11.8470,\n",
            "        25.0228,  9.1764, 25.8392, 20.8724,  9.9595, 14.0227, 32.1115, 21.9537,\n",
            "         6.0669, 24.7328,  8.3986, 21.5577, 16.6107, 13.3509, 22.1460, 16.7454,\n",
            "        23.1356, 25.7470, 12.1936, 10.4586, 11.1009, 15.9167, 21.6037, 27.1332,\n",
            "        24.5558, 22.0892, 12.9978, 25.5870, 24.0452, 23.5571,  5.3629, 27.1258,\n",
            "        11.6887,  5.0041, 25.5107, 35.3944, 20.9838, 29.4840, 21.6229, 25.9813,\n",
            "         9.6711, 13.9655, 30.3835, 14.1199, 26.0047,  5.7574, 14.8549,  3.0674,\n",
            "        16.3755,  9.5148, 11.9624,  9.6878, 15.3371,  5.2567, 19.5574,  3.9233,\n",
            "        11.4803, 27.3697, 26.5503, 24.9467, 13.6483, 25.3682,  9.9248, 36.4571,\n",
            "        23.2572, 12.9924, 24.0198,  4.5755, 14.8845, 21.3233, 12.9130,  5.9342,\n",
            "        23.0074, 14.8800,  5.3137, 15.8064, 32.6682, 23.9873,  5.3607,  5.4647,\n",
            "        14.2361, 19.7812, 25.9639,  9.1908, 15.5726, 19.8969,  8.0561, 16.2670,\n",
            "        27.3925, 10.2228,  6.1482, 14.7948, 20.1412,  8.8136,  5.3899,  9.6608,\n",
            "         6.3373, 26.6851, 21.4783,  6.3925, 25.0416, 13.4794, 23.2806, 24.8373,\n",
            "        10.0191, 10.1422, 11.0010, 13.2822, 16.7465, 27.0294, 33.6246, 13.0775,\n",
            "        29.5608, 12.0750, 14.3237, 13.6106, 33.2281,  6.1517, 24.1084, 25.0018,\n",
            "        19.7279, 10.0869,  6.7524, 21.6924, 20.6041, 21.2835, 33.0765,  5.9066,\n",
            "         2.9261,  9.5491,  5.6022, 19.1269, 11.2738, 15.4704, 22.0125, 27.0633,\n",
            "        10.0306, 18.7412, 29.1765, 12.3762, 18.0459, 26.1231, 14.2230, 20.7422,\n",
            "        19.4368, 12.7423, 13.4761, 27.7056, 25.8833, 20.0307,  8.7666, 34.5331,\n",
            "        16.6836, 11.4770, 26.6022,  9.7865, 23.0152, 28.9328, 20.5279, 14.4901,\n",
            "        15.1195, 12.7766,  9.9142, 11.4656, 35.4664, 12.2714],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([10.0948,  6.2320, 16.8010, 21.5122,  9.3521, 12.6688, 20.6155, 20.2473,\n",
            "         8.8495, 11.8084, 25.3534, 16.5865, 18.0751, 26.5958, 13.2436,  4.6269,\n",
            "        25.2709, 14.0398,  3.3576, 19.2308, 13.9191, 17.0628, 32.5764, 11.5597,\n",
            "        13.0735, 23.4489, 23.5312,  8.6667, 15.6390,  2.5944, 28.4408,  9.8216,\n",
            "         8.7530, 17.5070,  6.3559, 21.0106, 20.1877, 18.2170, 27.7095, 15.1990,\n",
            "         5.3610, 10.8191, 25.0745,  3.7764, 28.4531, 10.2048,  5.3134, 11.1391,\n",
            "        29.4770, 11.9253,  5.7692, 25.6844, 22.3770, 23.8535,  3.0383,  3.0017,\n",
            "        28.4593, 10.0293, 15.9629, 24.4991,  9.1036, 27.3101, 21.9274, 15.6387,\n",
            "        12.8270, 10.6081, 14.9846, 16.6667, 21.0874, 10.2741,  9.7607,  9.6324,\n",
            "        22.1634, 15.6076,  6.8346, 16.4965,  9.7082,  6.9896,  5.0395, 19.9588,\n",
            "         5.9055,  6.4554, 13.5397, 10.0000, 11.2903, 33.9858, 24.3197, 13.5349,\n",
            "        11.1971, 12.7037,  9.9701, 13.0085, 17.3588, 13.6745, 13.9722,  3.6318,\n",
            "        16.5888, 12.5347, 21.5983, 19.5238, 18.8368, 22.2843, 12.7061, 11.6320,\n",
            "        25.1333, 10.7772, 26.1270, 21.3192, 10.1734, 13.4694, 32.1687, 22.2456,\n",
            "         6.8539, 24.2466,  8.2796, 20.8073, 18.0060, 15.5242, 19.9257, 15.6250,\n",
            "        22.4381, 23.3949, 12.5605, 10.0828, 12.5390, 15.8023, 22.9484, 23.7784,\n",
            "        24.1771, 23.7242, 12.3044, 24.1835, 24.9999, 25.2984,  5.7801, 29.0526,\n",
            "        11.6762,  5.6349, 25.3500, 34.2969, 21.8573, 29.6456, 20.7602, 24.8711,\n",
            "         9.8565, 13.6426, 31.6662, 14.9629, 24.8762,  5.8161, 14.6563,  2.9711,\n",
            "        16.9849, 11.5385, 12.0716,  9.3623, 15.5292,  5.8424, 18.3327,  4.3103,\n",
            "        12.1100, 26.6905, 26.4727, 24.4311, 13.0290, 24.5546,  9.5855, 35.1006,\n",
            "        24.5000, 12.2727, 21.9933,  5.3297, 14.8276, 21.7878, 12.8613,  5.2206,\n",
            "        22.9166, 13.2216,  5.6315, 15.8711, 31.6558, 24.1852,  5.3610,  6.1551,\n",
            "        13.2218, 18.9801, 25.8174,  8.4420, 15.8537, 20.5191,  7.3750, 16.7516,\n",
            "        27.6397, 10.7596,  7.0304, 14.7849, 19.7808, 10.0399,  5.1471,  9.4130,\n",
            "         5.7522, 27.1211, 21.8320,  6.5385, 26.2203, 13.7224, 23.9938, 24.4097,\n",
            "        10.1237, 10.2067, 11.7894, 15.3333, 17.3588, 29.0540, 34.0910, 13.0728,\n",
            "        27.3711, 11.8373, 13.9567, 14.1245, 33.9020,  5.3168, 24.2925, 25.6379,\n",
            "        18.1318, 10.5809,  7.1183, 20.0288, 20.2321, 19.8522, 33.6783,  6.4014,\n",
            "         2.5369, 10.7143,  5.2606, 18.5960, 10.9867, 11.7443, 22.0620, 26.5838,\n",
            "        10.2986, 17.1642, 27.6612, 12.3727, 15.6017, 25.9189, 14.1204, 22.3315,\n",
            "        18.1222, 12.8571, 13.1442, 26.2064, 24.7987, 18.4755,  8.9197, 33.0257,\n",
            "        16.1458, 12.6669, 27.2440, 10.5894, 23.2301, 27.9032, 20.0649, 14.5338,\n",
            "        15.1599, 13.1766,  9.4371, 10.2519, 35.6195, 12.6134])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.5292e-05, -2.3791e-05,  1.5039e-06,  ..., -1.6644e-06,\n",
            "          1.8670e-05,  3.0917e-06],\n",
            "        [ 6.3710e-05, -1.9881e-04,  8.6031e-06,  ..., -4.8059e-04,\n",
            "          1.4746e-04,  2.4388e-04],\n",
            "        [-3.2122e-04, -2.4818e-04,  5.7304e-06,  ...,  3.7700e-02,\n",
            "          6.2424e-04, -2.2913e-03],\n",
            "        ...,\n",
            "        [-1.3299e-06, -1.9640e-06,  1.5113e-05,  ..., -2.1269e-06,\n",
            "         -1.9612e-06,  1.2896e-06],\n",
            "        [ 1.8748e-05, -7.8598e-06, -2.3260e-05,  ..., -1.7521e-05,\n",
            "          2.5575e-05, -8.8106e-06],\n",
            "        [-2.1727e-05,  1.2945e-06, -1.7531e-05,  ..., -6.8573e-06,\n",
            "          1.5495e-05, -1.9557e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.4096e-06,  4.2374e-01,  3.6414e-02, -2.8364e-05, -7.4357e-08,\n",
            "        -1.3255e-05,  2.5234e-05, -6.4643e-06,  1.5815e+00, -1.9626e-05,\n",
            "         5.3915e-06,  4.6267e-06, -1.1987e-05, -3.3023e-05,  4.4676e-05,\n",
            "        -1.4534e-05, -3.6977e-06,  8.1780e-06, -3.9219e-07, -3.8679e-05,\n",
            "         1.7030e-05,  2.1251e-05,  7.2911e-06, -1.0330e-05,  1.3470e-05,\n",
            "        -4.4632e-05,  5.7324e-06,  1.3376e-01,  8.3951e-06,  4.0408e-07,\n",
            "        -8.9919e-06, -8.5781e-06, -5.9532e-06,  2.8749e-01,  1.7895e-05,\n",
            "         8.6983e-08,  1.2576e-05, -1.6828e-05,  9.8331e-06, -1.2013e-05,\n",
            "         9.0145e-06, -5.4527e-06, -3.7322e-05,  1.2690e-05, -1.8534e-05,\n",
            "        -1.5174e-05,  5.7840e-06, -1.1175e-05,  2.7491e-05, -5.9566e-05,\n",
            "        -1.1314e-05, -4.7463e-06,  1.4438e-05, -1.1610e-05, -1.4513e-05,\n",
            "         8.3768e-07, -6.4408e-05,  3.7810e-06,  5.1262e-06,  1.1530e-05,\n",
            "        -5.8831e-06, -1.1523e-05, -2.8789e-05, -1.4130e-05, -6.7013e-06,\n",
            "         1.8920e-05,  2.1216e-05,  2.4474e-06,  1.4248e-05,  9.2110e-02,\n",
            "        -1.8254e-05,  6.1847e-06,  1.7007e-05,  1.0086e-05,  6.2581e-07,\n",
            "         8.7879e-06, -1.0452e-05, -2.4545e-05, -6.2420e-06, -1.5778e-03,\n",
            "         5.2229e-06, -8.2139e-06,  7.3522e-06, -1.0047e-06,  1.3853e-05,\n",
            "         1.0631e-05,  1.3764e-05,  1.5383e-05,  1.6956e-05,  9.5147e-06,\n",
            "        -7.7151e-07,  3.8299e-06,  2.2400e-05,  2.5359e-05,  1.2827e-05,\n",
            "        -8.6601e-06,  5.8425e-06, -2.7860e-06, -3.6724e-05,  2.2163e-05,\n",
            "         3.8731e-04,  7.4630e-06, -1.3854e-06, -1.2605e-05, -1.2445e-05,\n",
            "        -7.4215e-07, -2.8319e-06, -3.8300e-06, -1.0055e-05,  1.3067e-05,\n",
            "        -1.9235e-05, -4.4172e-06,  2.1482e-05,  8.7532e-07, -1.3653e-05,\n",
            "         2.2859e-06, -1.6433e-05,  2.4962e-06, -2.9328e-06,  1.5208e-06,\n",
            "         1.2625e+00,  1.0341e-05,  1.5939e-05,  8.4639e-06, -1.2259e-05,\n",
            "        -6.7835e-06,  1.7276e-06,  4.2434e-07], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 3.0515e-06,  9.7156e-05, -8.4083e-05,  ...,  2.5905e-06,\n",
            "         -9.8393e-08,  1.2600e-05],\n",
            "        [-1.7794e-06,  9.0355e-06,  1.4746e-05,  ..., -1.4215e-05,\n",
            "         -1.8665e-05,  6.9881e-08],\n",
            "        [-1.2898e-05,  1.9848e-06,  2.7634e-05,  ..., -1.0966e-05,\n",
            "         -5.0659e-07,  1.4449e-05],\n",
            "        ...,\n",
            "        [-4.9559e-06, -1.2267e-05, -1.2643e-05,  ...,  6.7103e-06,\n",
            "         -5.7123e-11,  1.6115e-05],\n",
            "        [-1.3988e-05,  1.5405e-04, -1.3301e-04,  ...,  6.0165e-06,\n",
            "          8.4846e-06, -2.2044e-06],\n",
            "        [ 9.8331e-06, -1.0019e-04, -2.7171e-04,  ...,  1.1397e-06,\n",
            "         -2.7104e-06, -4.8089e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3218e-02, -3.7888e-06,  1.9736e-06, -1.4038e-05,  3.2042e-05,\n",
            "         1.7933e-05,  9.6329e-07, -6.5067e-07,  1.1077e-05,  8.0445e-06,\n",
            "        -3.8495e-07, -7.8583e-06,  3.4013e-06,  6.0403e-07,  2.3135e-07,\n",
            "        -1.1689e-05, -4.1537e-07,  6.8074e-06, -1.9826e-07,  1.4601e-05,\n",
            "         2.5875e-05,  9.9499e-06, -8.4365e-06, -2.0978e-05,  7.3993e-04,\n",
            "         3.1970e-06,  5.9138e-06,  4.7358e-06,  8.4368e-06, -1.7748e-05,\n",
            "        -9.4740e-06, -4.0357e-06,  1.1569e-06,  4.0331e-06, -1.5423e-05,\n",
            "        -6.1915e-06, -2.0141e-05, -5.3410e-06,  1.0755e-05, -1.0036e-05,\n",
            "        -5.2080e-07, -5.4289e-06, -6.8263e-06,  1.3917e-06, -3.3064e-06,\n",
            "         6.2578e-06, -1.3642e-05,  7.3502e-06, -1.7152e-05, -9.5289e-06,\n",
            "         5.0418e-06,  1.0854e+00,  5.4169e-07, -1.0707e-05,  2.5131e-06,\n",
            "         8.8377e-02, -1.4191e-05, -2.1660e-06,  1.6910e-05, -1.2482e-05,\n",
            "         1.3280e-05, -1.3334e-05,  2.5956e-01, -2.9444e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3338e-01, -9.3634e-06, -7.6844e-06,  1.4879e-05, -7.8118e-06,\n",
            "         -9.9374e-06,  1.2783e-05, -3.2694e-06,  3.7127e-06, -1.3472e-05,\n",
            "          3.1589e-05,  2.0863e-05,  8.4591e-06, -1.6112e-05,  2.6475e-07,\n",
            "          2.8499e-05,  3.3339e-06, -1.6186e-07,  1.2411e-06, -4.1782e-06,\n",
            "         -8.2681e-08,  1.9846e-05,  1.4524e-05,  3.9068e-05,  5.4609e-01,\n",
            "          3.2285e-06, -1.7517e-05,  8.1733e-06,  1.2028e-06,  1.6683e-05,\n",
            "          1.3070e-05, -1.2418e-05, -1.9172e-05,  1.7274e-05,  4.5712e-08,\n",
            "         -6.7640e-06,  3.6220e-06,  2.4690e-06,  8.3446e-06, -1.7299e-06,\n",
            "         -1.7827e-05, -1.5319e-06,  6.2495e-06,  4.2797e-05,  8.2780e-06,\n",
            "          1.6859e-05, -9.7205e-06,  1.8147e-05, -1.7881e-05, -9.4421e-06,\n",
            "          2.2533e-06,  3.2354e+00,  1.3128e-05,  2.4019e-05, -6.7391e-07,\n",
            "          7.8286e-01, -2.4706e-05, -4.2632e-06,  4.7842e-06, -2.3448e-06,\n",
            "          4.6895e-06,  1.8330e-05,  1.0857e+00,  2.3923e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3094], requires_grad=True)\n",
            "l1_reg is: 30.22527503967285\n",
            "total_loss 1.252112627029419\n",
            "pred: tensor([24.7565, 19.5801, 13.4567, 10.1202,  3.7407, 14.6262,  7.0845, 19.9574,\n",
            "        11.1859, 12.5768,  2.7898, 18.2318, 22.9143,  5.4171, 14.5272, 10.4739,\n",
            "        19.4144,  9.5375, 18.7562, 10.6085, 17.4730, 26.1879, 15.5996, 30.2914,\n",
            "        22.5857, 21.1378, 12.3723, 22.9935, 10.3489, 30.1887,  9.4038, 13.5928,\n",
            "        18.2921, 27.5333,  6.5962, 21.6697,  6.2968,  5.8993, 16.6761,  6.0926,\n",
            "        15.0958, 13.2876, 24.2595, 19.4127, 10.0692, 17.4984,  7.3220, 26.5445,\n",
            "         7.8068, 14.1607, 24.2700, 27.6532, 15.9696, 13.2532, 22.1575, 20.1959,\n",
            "        24.5154, 10.6608, 24.1418, 18.2754, 16.5903, 10.3928,  8.9337, 16.1381,\n",
            "        20.4978, 13.6261, 16.0622, 22.2821,  5.1588,  5.5660,  7.0834, 16.5069,\n",
            "        15.6530, 17.6829, 24.0658, 11.8521, 11.0009, 12.7879, 19.3212,  5.3679,\n",
            "        26.3120,  6.6168, 17.6412,  7.6776,  5.1902,  8.3575, 29.5428, 25.7159,\n",
            "        20.1520, 16.8238, 15.8580,  7.1177, 27.0187,  6.0938, 27.0491, 13.2053,\n",
            "         8.6255,  9.4893, 22.6126, 12.9131, 15.6722, 16.6479,  8.0710, 20.2183,\n",
            "         5.3197, 27.8127, 14.3421,  9.1710, 13.0552, 22.3802, 18.8934, 28.3666,\n",
            "        25.4776,  4.6723,  7.8087, 15.9689,  7.8538,  3.5448, 21.9629, 22.6236,\n",
            "        19.2548, 19.5953, 24.6332, 22.4240, 10.2965, 25.6293, 20.4586, 21.4049,\n",
            "        27.6457, 10.1820, 26.6475,  8.5469, 13.1117, 22.0820,  9.1909,  7.4863,\n",
            "        29.3213, 24.6053, 12.7129, 24.4745,  3.8051, 19.8207, 10.4748, 23.9509,\n",
            "        24.1992, 23.2692, 16.3507, 15.8434, 22.7874, 27.4193, 19.8535, 11.3360,\n",
            "         4.0162, 21.4473, 24.3803, 25.3837,  4.5229, 20.6764,  9.1255, 16.4519,\n",
            "        14.5343, 10.1746, 24.4486, 20.1938, 18.7352, 11.0699, 15.5099, 12.9734,\n",
            "         7.5376, 14.2508,  4.0410,  9.2274, 25.3348, 35.0828, 13.8707, 21.8768,\n",
            "        11.1946,  6.7823,  9.5337, 20.6370, 14.6728,  7.6466,  7.7024, 24.1371,\n",
            "        15.0241,  5.5352, 20.3091,  9.6487,  5.9237,  5.1884, 20.7283, 15.8757,\n",
            "         4.1696, 20.5505, 10.3790,  8.1034, 11.4287, 16.1140, 13.2138, 11.0434,\n",
            "         9.6029, 16.5625, 11.6285, 20.6810, 14.0092, 27.2914,  8.7351, 29.3976,\n",
            "        12.4050, 12.2044, 10.4105, 13.9440, 14.0482, 23.3300, 17.0109,  8.9699,\n",
            "         6.0340, 35.2271,  5.1643,  7.8894, 17.5200, 12.7929, 20.6630, 21.8814,\n",
            "        10.6430,  6.1595, 24.7470,  8.8025, 27.7495, 29.4613, 15.0230, 24.6269,\n",
            "        24.4222,  7.1723, 19.8412, 23.4911, 20.8515, 14.3380, 12.2413, 16.9824,\n",
            "         3.5172, 16.0187, 20.3450, 20.8841, 15.8425,  9.4492, 10.0380, 11.5111,\n",
            "         4.9802, 34.3093, 16.0738, 18.7513, 20.5928, 27.6326, 20.3176, 33.5631,\n",
            "        17.0691, 12.1884, 27.8109, 30.3264,  5.5949,  9.1217,  9.6065, 11.2994,\n",
            "        22.8709, 18.2332,  7.9163, 20.8237, 12.8839, 13.5995],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([24.0300, 19.0345, 14.7017,  9.5396,  3.4606, 15.0563,  7.3673, 20.6442,\n",
            "        11.5187, 12.4772,  2.3387, 17.2200, 23.1234,  6.1056, 13.9843, 10.0635,\n",
            "        20.9402,  9.3175, 18.8760, 10.1527, 16.7125, 26.0477, 16.0182, 30.7632,\n",
            "        23.4455, 19.8781, 12.3903, 24.1090,  9.5795, 31.9832,  9.1349, 13.8693,\n",
            "        20.0467, 26.9940,  6.7568, 21.2334,  7.0930,  6.1747, 17.6767,  5.7276,\n",
            "        15.2567, 14.0473, 24.1920, 18.8784,  8.9709, 15.9774,  7.2581, 26.8926,\n",
            "         7.2944, 13.4101, 25.8186, 28.5029, 15.3364, 14.9214, 21.9577, 19.7124,\n",
            "        24.4929, 10.2318, 24.0335, 18.2288, 18.0235, 10.3358,  9.0140, 15.3303,\n",
            "        20.5065, 14.1129, 15.8154, 22.7441,  4.3651,  5.7823,  6.6825, 15.4295,\n",
            "        16.6666, 16.9475, 21.9658, 11.7231, 11.2189, 12.5389, 20.0117,  5.6182,\n",
            "        27.2424,  7.4638, 17.5004,  7.9767,  4.7562,  8.3333, 30.2853, 24.5410,\n",
            "        19.7417, 18.0195, 16.0401,  7.3201, 27.2233,  6.3984, 25.9028, 13.2304,\n",
            "         7.3276,  9.3069, 21.8196, 12.3064, 16.1538, 15.7793,  8.0049, 20.8130,\n",
            "         5.2738, 27.6650, 14.3903,  9.7152, 11.4635, 21.6878, 19.5034, 28.8653,\n",
            "        25.9673,  4.6756,  7.0093, 15.3179,  9.0463,  3.3760, 22.3133, 23.7068,\n",
            "        20.1784, 19.8440, 22.7811, 23.0754, 11.2188, 24.4345, 18.8625, 21.5556,\n",
            "        28.1975, 10.1481, 28.6013,  8.0536, 13.4036, 20.8926,  9.0616,  7.7035,\n",
            "        29.0925, 25.1929, 12.1834, 24.4339,  3.5509, 19.7479, 10.0462, 23.2718,\n",
            "        24.1173, 23.6040, 15.2945, 16.1682, 23.1116, 27.4634, 20.6137, 11.1170,\n",
            "         3.1969, 21.5129, 23.6161, 25.8747,  3.8066, 22.1461,  8.5938, 17.3591,\n",
            "        14.7177, 10.4391, 23.6905, 19.6751, 16.1303, 11.3383, 15.9004, 13.5870,\n",
            "         7.5309, 11.6007,  4.4081, 10.3821, 24.9442, 36.1679, 14.8246, 21.2779,\n",
            "        11.1299,  6.9184,  9.1758, 18.9176, 13.6179,  7.8005,  8.7156, 24.9990,\n",
            "        13.5161,  5.0426, 20.5263, 10.3949,  6.1958,  5.7261, 20.5967, 16.1270,\n",
            "         4.1165, 20.5136,  9.7137,  7.7073, 11.6739, 17.0447, 11.8230, 11.0834,\n",
            "         9.9190, 13.6355, 13.1338, 21.0684, 13.6535, 26.8546,  9.3464, 29.6610,\n",
            "        11.0619, 13.3624,  9.2334, 13.8469, 13.5361, 24.4875, 15.8768,  9.2253,\n",
            "         5.6474, 38.6700,  4.0730,  7.5672, 16.0614, 13.2069, 21.9214, 22.2477,\n",
            "        10.5912,  6.3859, 25.3434,  9.4238, 27.0758, 29.1736, 16.3534, 26.1508,\n",
            "        26.3594,  6.9288, 20.7734, 22.5008, 19.6574, 14.3739, 13.3165, 15.9357,\n",
            "         3.3879, 16.6668, 20.4546, 21.7207, 16.6146,  8.6930,  9.7347, 11.3362,\n",
            "         5.6575, 33.8413, 17.8601, 18.5195, 23.2825, 25.2593, 20.9184, 34.8000,\n",
            "        17.5676, 11.2255, 27.3353, 31.1275,  5.6319,  8.9440, 11.0962,  9.8086,\n",
            "        22.9592, 18.2353,  7.1429, 21.1683, 11.9179, 12.9426])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 1.2423e-05, -1.1829e-05, -1.4463e-05,  ...,  1.4017e-05,\n",
            "          1.2368e-05,  8.9607e-08],\n",
            "        [ 4.3592e-05, -1.9254e-04, -1.2617e-06,  ..., -2.6475e-04,\n",
            "          2.5143e-04,  2.0713e-04],\n",
            "        [-3.3209e-04, -2.9119e-04, -1.4154e-05,  ...,  3.7820e-02,\n",
            "          9.1396e-04, -2.3172e-03],\n",
            "        ...,\n",
            "        [ 6.6313e-06,  2.5223e-06,  1.9490e-05,  ..., -7.6410e-07,\n",
            "          4.9368e-06,  4.1214e-06],\n",
            "        [ 2.7439e-05,  3.4980e-06, -1.9157e-05,  ..., -1.1229e-05,\n",
            "          2.4639e-05, -5.5639e-06],\n",
            "        [-3.9266e-05,  8.7869e-06, -2.3435e-05,  ...,  4.8991e-06,\n",
            "          1.3335e-05, -2.8264e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-7.8451e-06,  4.2353e-01,  3.5829e-02, -2.7674e-05,  8.8922e-06,\n",
            "        -1.0259e-05,  1.4304e-05,  1.0855e-05,  1.5807e+00, -1.7454e-05,\n",
            "        -2.3637e-06, -2.0884e-06, -1.4064e-05, -2.2671e-05,  3.7757e-05,\n",
            "        -8.2279e-06,  1.8647e-05, -1.2601e-05,  1.8759e-05, -4.1877e-05,\n",
            "         9.5674e-06,  1.5627e-05,  5.2122e-06, -4.0177e-06,  1.7605e-05,\n",
            "        -3.7622e-05, -2.9636e-06,  1.3353e-01, -1.1647e-06, -8.5826e-06,\n",
            "        -1.4341e-05, -1.2712e-05,  4.2682e-07,  2.8723e-01,  1.1598e-05,\n",
            "        -6.9478e-06,  4.4376e-06, -1.0526e-05, -5.8379e-06,  2.4685e-06,\n",
            "        -1.1742e-05, -1.3335e-05, -2.1032e-05,  3.3793e-06, -1.3532e-05,\n",
            "        -2.3867e-05, -1.6551e-05, -1.5287e-05,  2.5309e-05, -1.4416e-05,\n",
            "        -1.6736e-05,  5.7676e-06,  1.8822e-05, -5.3315e-06, -1.2331e-05,\n",
            "        -3.1960e-07,  6.5158e-05,  2.2946e-06,  4.1271e-07,  1.7866e-05,\n",
            "        -9.1290e-06,  3.9755e-06, -2.6591e-05, -7.8346e-06, -7.1659e-06,\n",
            "         2.7712e-05, -3.4522e-06,  2.6853e-07,  2.2808e-06,  9.1926e-02,\n",
            "        -1.3300e-05,  1.4007e-05,  2.7113e-05,  9.9455e-06, -1.5391e-05,\n",
            "         3.1731e-07,  4.2192e-06, -2.2350e-05, -1.0350e-05, -1.9093e-03,\n",
            "        -4.3173e-06,  9.9645e-06,  6.7994e-06,  8.1688e-07,  7.5398e-06,\n",
            "         1.3132e-06,  5.0242e-06,  2.4047e-05, -3.4881e-06,  1.6271e-07,\n",
            "         9.7150e-06, -1.8519e-05,  1.0427e-05,  1.4410e-05,  7.9053e-07,\n",
            "        -6.7272e-06, -1.1299e-05,  1.5856e-06, -2.0408e-05,  1.8050e-05,\n",
            "         2.4797e-04, -3.0454e-06,  6.5606e-06, -1.6704e-05, -4.7861e-06,\n",
            "         6.5574e-06, -6.6789e-07,  6.7039e-06, -3.7696e-06,  1.7184e-05,\n",
            "        -5.5296e-06, -1.4478e-06,  2.0975e-06, -8.0817e-06, -1.6212e-05,\n",
            "         1.4415e-05, -2.5101e-05,  6.4790e-06,  1.2722e-05, -1.4813e-05,\n",
            "         1.2620e+00,  9.9404e-06,  8.0766e-06,  1.7161e-05, -1.6310e-05,\n",
            "         5.0301e-07, -1.5940e-05, -1.7980e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-6.0703e-06, -3.1867e-05, -2.0850e-04,  ..., -4.3133e-06,\n",
            "          6.4463e-06,  1.8210e-05],\n",
            "        [ 1.4633e-05,  1.0330e-05,  2.3432e-05,  ..., -1.8322e-05,\n",
            "         -6.7030e-06, -1.8839e-05],\n",
            "        [ 7.8674e-06, -1.6402e-05,  2.6720e-05,  ..., -1.6340e-05,\n",
            "          1.3706e-05,  8.1446e-06],\n",
            "        ...,\n",
            "        [-5.5165e-06, -4.0659e-06, -1.7314e-05,  ..., -4.8314e-06,\n",
            "          1.3075e-05,  1.3935e-05],\n",
            "        [-8.6569e-06, -9.8849e-05, -4.1610e-04,  ..., -3.5001e-06,\n",
            "          1.2837e-06,  2.2801e-06],\n",
            "        [ 1.5365e-05, -7.8365e-05, -2.6490e-04,  ..., -6.8177e-06,\n",
            "          7.3850e-07, -5.3562e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.3020e-02, -2.3385e-06, -5.9842e-06, -2.0725e-06,  2.3713e-05,\n",
            "        -1.6167e-06, -1.2447e-05,  1.3123e-05,  1.3990e-06,  5.3041e-06,\n",
            "         1.6095e-05,  7.8111e-06, -3.3743e-06, -7.3527e-06, -8.7459e-06,\n",
            "        -2.3827e-06,  1.7535e-05, -4.6690e-07,  6.3626e-06,  1.2421e-05,\n",
            "         2.4959e-05,  1.4045e-05, -6.0840e-06, -7.6815e-06,  6.6710e-04,\n",
            "        -3.2273e-06, -1.1747e-05,  1.3303e-05,  4.0050e-06, -3.5352e-06,\n",
            "         1.0205e-06,  3.2380e-06, -4.6617e-06,  3.0754e-06, -1.9529e-05,\n",
            "         3.3075e-06, -1.5601e-05,  1.1982e-05,  1.6338e-05,  1.5713e-05,\n",
            "         2.0252e-05,  7.5058e-06, -3.5645e-07,  8.9790e-06,  8.6328e-06,\n",
            "        -1.1059e-05, -1.8344e-05, -9.9660e-06, -5.1708e-06, -1.5895e-05,\n",
            "         6.6001e-06,  1.0847e+00, -5.9327e-06,  3.7661e-06,  6.5765e-06,\n",
            "         8.8133e-02, -5.7745e-06,  1.2914e-06,  2.2814e-05,  8.2791e-06,\n",
            "        -2.3929e-06, -2.6517e-05,  2.5926e-01, -2.8742e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3327e-01,  1.1415e-05,  7.2153e-06,  2.8019e-05, -5.3803e-06,\n",
            "         -2.9124e-06,  1.4892e-05,  1.5092e-05, -7.4632e-06, -9.3789e-07,\n",
            "          3.3441e-05,  3.4059e-05,  1.2580e-05, -9.8296e-06, -1.8872e-05,\n",
            "          5.5970e-06,  2.7986e-06,  7.1055e-06,  4.2720e-06,  1.8439e-05,\n",
            "          8.2964e-06,  7.9088e-06, -5.2411e-06,  4.2303e-05,  5.4598e-01,\n",
            "         -1.8039e-05, -3.0733e-05,  1.7479e-06, -1.4487e-05,  1.1719e-05,\n",
            "          2.6234e-05, -1.4522e-05, -5.5250e-06,  2.7371e-05, -2.3561e-05,\n",
            "          8.1360e-06, -7.9924e-06,  6.5868e-06,  9.9638e-06,  1.9526e-05,\n",
            "         -4.1455e-06, -9.8416e-07, -1.5900e-05,  4.8588e-05,  1.9500e-06,\n",
            "          2.2740e-05, -1.0498e-05,  3.9617e-06, -8.7741e-06, -1.0212e-05,\n",
            "         -6.8746e-06,  3.2333e+00,  1.7830e-05,  1.2063e-05,  1.5015e-05,\n",
            "          7.8270e-01, -2.3568e-05,  1.1363e-05, -2.5312e-06,  1.0989e-06,\n",
            "          6.1931e-06,  4.1159e-06,  1.0853e+00,  2.3913e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3091], requires_grad=True)\n",
            "l1_reg is: 30.1728515625\n",
            "total_loss 1.0547889471054077\n",
            "pred: tensor([15.0301, 21.8435, 15.9523, 13.2212, 25.8655, 23.0173, 14.9702, 24.4668,\n",
            "        13.8475, 10.1492, 15.3797, 20.2173, 19.0405, 13.0572, 15.3145, 22.0935,\n",
            "        14.8655,  5.3659, 17.5753, 12.2736, 14.6453, 21.0553, 11.0374, 12.5957,\n",
            "        26.6631, 24.4384, 13.3905, 21.3012, 10.3518, 18.0154, 19.1836, 23.3451,\n",
            "        17.8908, 16.4209,  7.0583, 20.6330, 18.8545, 13.3927, 16.4416, 21.9900,\n",
            "        13.2574, 25.9791, 13.1268, 18.7870,  6.5417,  5.5187,  8.2778, 10.2006,\n",
            "        26.4332, 30.5592, 18.8834, 10.6360, 24.7794, 32.2240, 17.7521, 20.7446,\n",
            "         5.3574, 26.8358, 13.1574, 18.1612,  6.5422,  6.4909, 22.0065, 16.0214,\n",
            "        18.6661, 23.5855, 25.2337, 19.9710, 15.6524, 26.6184, 14.6727, 12.9096,\n",
            "        26.8283, 24.8247, 29.3056, 14.6742, 15.2781, 20.3673, 12.1693,  6.9979,\n",
            "        34.0929,  6.0036, 24.5176, 11.9870,  5.6020, 19.5834, 12.5327,  9.4643,\n",
            "        17.0914,  9.4131, 21.8563, 24.0595, 10.2706, 15.8209, 24.3675, 18.9184,\n",
            "        22.7969, 10.6238,  5.6738, 20.9457,  6.5152, 18.4334, 11.5927,  9.5653,\n",
            "        21.5897, 12.4119,  6.3197, 15.2692, 25.3360, 29.9695, 12.2091,  4.7255,\n",
            "        11.8628, 20.4334, 10.3665, 18.1844, 28.7750, 20.5591, 12.6463, 16.0055,\n",
            "        18.1614, 13.8783, 12.4024, 12.9117, 19.8520, 24.8305, 14.9137,  7.0479,\n",
            "        25.7284, 15.9269,  5.3429,  3.1168,  5.2699, 17.3408, 17.3915, 10.3928,\n",
            "        11.8517,  9.3369,  3.9146, 21.6564, 12.1883,  6.4814,  9.5387,  6.8712,\n",
            "        24.3187,  8.0737, 16.6239,  5.4485, 21.0208,  4.2868, 24.4780, 13.3330,\n",
            "        10.6814, 20.9088, 10.7048, 10.6015, 21.2034, 22.4000, 25.0686, 11.1671,\n",
            "        15.3394, 26.5647, 20.8456, 27.9644, 13.5307, 27.1338, 17.5139, 20.9919,\n",
            "        24.3718,  4.4543, 18.8884, 10.5924, 15.8839, 16.6876, 23.0229, 11.7569,\n",
            "        19.9078, 18.8531,  9.8654,  4.3813, 25.7974, 10.3312,  8.6376, 16.6591,\n",
            "        13.5963, 19.5005,  5.6784,  5.6838, 22.2341, 23.7168, 25.5208, 13.3757,\n",
            "        15.8290, 14.3745, 25.8030, 10.5102, 20.0808, 12.3116, 20.7024,  9.2763,\n",
            "         7.7224, 13.4391, 15.3102, 13.3834, 12.0212,  8.1252, 27.2842,  5.5878,\n",
            "         5.2148, 15.7659, 19.5285, 12.5024, 11.2488, 16.7919,  7.3885,  5.7749,\n",
            "         9.4997, 14.2787,  9.3387, 32.4495,  6.4890, 22.0461,  3.0978,  5.9765,\n",
            "        16.1493, 11.6113, 20.2359,  6.9298, 11.9104, 19.0553, 10.1366,  9.4148,\n",
            "        21.4934,  5.7497, 26.7649, 22.9711, 32.2831, 12.4875,  8.5457,  5.9150,\n",
            "        34.2966, 12.7306, 21.5566,  6.4336, 10.7732, 13.7467,  5.6238, 12.1679,\n",
            "        13.1391, 15.2753, 25.0127, 26.8588,  3.4364, 17.4340, 13.5658, 16.8255,\n",
            "         7.7846, 20.4676, 11.5238, 20.9123, 23.8896, 13.9406, 10.1316, 15.3962,\n",
            "         6.3678, 19.8407, 21.8567, 15.1586, 10.0198, 20.9630],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([16.7753, 21.5638, 19.9029, 11.9545, 25.2827, 21.8750, 15.4041, 25.0780,\n",
            "        14.7092,  9.4427, 15.2284, 20.9799, 19.9216, 12.0427, 14.4231, 21.4534,\n",
            "        15.3726,  5.6016, 18.3226, 11.8117, 15.5626, 21.0008, 11.0390, 11.9607,\n",
            "        26.8387, 24.4639, 12.7754, 20.2788,  9.9276, 18.4037, 20.0732, 23.9238,\n",
            "        18.3941, 17.3989,  7.7273, 20.8847, 19.9756, 12.5295, 15.7567, 22.7836,\n",
            "        12.4214, 25.0707, 13.5258, 18.5914,  6.8095,  6.5000,  7.9873,  9.5292,\n",
            "        27.7791, 27.8942, 19.3056, 10.5945, 23.9575, 35.0221, 18.6476, 20.3187,\n",
            "         5.5369, 25.6981, 13.1141, 19.8397,  6.0086,  6.6176, 22.4990, 16.1064,\n",
            "        18.7693, 23.4524, 24.9691, 19.0535, 17.0498, 27.6089, 13.4191, 12.3585,\n",
            "        26.1853, 25.3099, 30.3057, 14.2462, 14.5089, 19.4592, 11.1559,  6.6014,\n",
            "        37.6466,  4.7111, 24.9055, 11.0535,  4.8006, 19.6629, 13.1496,  8.9404,\n",
            "        17.7139,  9.4689, 22.0198, 24.7221,  9.8086, 16.0435, 25.9200, 18.5266,\n",
            "        21.8526, 11.6492,  5.7545, 21.2103,  6.3559, 19.5478, 12.2191,  9.5536,\n",
            "        22.1881, 11.1608,  5.0388, 14.2097, 24.0288, 29.0246, 12.0438,  4.7945,\n",
            "        12.4596, 20.4198, 12.3094, 18.7927, 29.8732, 20.9787, 12.3080, 17.1809,\n",
            "        18.2678, 14.2810, 11.8495, 12.9687, 21.2262, 24.4880, 14.4573,  7.4371,\n",
            "        24.1689, 15.9655,  4.7445,  2.6650,  5.1222, 16.9453, 20.1595,  9.6549,\n",
            "        12.8613, 10.3216,  3.8390, 22.8458, 11.1549,  6.6964,  8.7321,  6.0052,\n",
            "        25.4290,  8.3572, 18.1604,  5.0824, 21.7208,  3.4038, 25.4667, 12.8218,\n",
            "        10.2267, 20.2236, 10.4564, 10.0000, 20.8235, 22.8728, 24.3040, 11.9047,\n",
            "        14.2655, 26.0680, 20.5418, 27.9216, 13.2873, 28.2166, 16.3235, 21.1803,\n",
            "        25.2963,  4.7401, 18.4841,  9.7441, 14.7459, 15.3061, 23.2647, 10.5994,\n",
            "        19.5712, 19.6914,  9.1658,  4.3599, 27.4696, 10.2113,  7.6803, 13.8672,\n",
            "        13.6148, 19.2678,  5.1470,  5.4434, 21.9823, 24.1562, 26.6540, 14.4196,\n",
            "        15.9392, 13.1483, 25.8165, 10.3292, 18.9740, 13.7851, 21.5107,  9.2326,\n",
            "         7.1078, 12.5824, 13.9320, 14.3080, 12.5002,  8.8863, 26.7766,  4.2700,\n",
            "         5.6825, 13.0685, 16.5860, 12.7419, 11.6667, 16.1702,  5.8988,  6.0261,\n",
            "         8.6788, 14.5307,  9.3750, 34.9496,  6.6911, 21.5773,  2.3983,  6.1396,\n",
            "        15.9076, 12.2077, 19.9266,  7.9193, 11.2184, 18.6713, 10.7407, 10.4667,\n",
            "        21.7100,  5.8908, 25.7534, 22.6914, 35.0674, 13.0026,  7.6252,  5.0197,\n",
            "        33.4256, 13.2033, 21.1850,  6.6741,  8.6269, 13.9889,  5.0875, 11.6684,\n",
            "        13.8308, 14.4366, 24.6485, 27.2539,  2.9032, 19.6378, 13.2610, 17.0751,\n",
            "         7.3034, 20.3132, 10.5224, 20.1811, 24.0284, 13.0504, 10.5222, 15.2333,\n",
            "         5.3161, 20.9224, 25.1133, 15.7807,  9.6474, 19.6073])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.5947e-07,  8.9369e-06, -1.8833e-05,  ...,  1.8131e-05,\n",
            "         -3.3057e-06, -1.2616e-05],\n",
            "        [ 2.8889e-05, -1.8806e-04,  6.7899e-06,  ..., -3.2218e-05,\n",
            "          4.4134e-04,  2.9210e-04],\n",
            "        [-3.1902e-04, -3.2085e-04, -2.2050e-05,  ...,  3.7853e-02,\n",
            "          1.2679e-03, -2.0684e-03],\n",
            "        ...,\n",
            "        [ 3.7968e-06, -3.4404e-06,  1.3428e-05,  ...,  1.0463e-05,\n",
            "          1.1469e-06, -3.3284e-06],\n",
            "        [ 2.5260e-05,  3.7201e-06, -5.4641e-06,  ...,  4.4387e-06,\n",
            "          1.3793e-05,  7.3428e-06],\n",
            "        [-4.5051e-05,  5.5299e-06, -1.8748e-05,  ...,  5.4799e-06,\n",
            "          1.3921e-06, -2.6099e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 2.6617e-06,  4.2334e-01,  3.5523e-02, -1.7054e-05,  6.9620e-06,\n",
            "         2.4373e-06, -5.5317e-06,  1.6442e-05,  1.5800e+00, -5.4984e-06,\n",
            "         6.5732e-07,  1.8690e-06, -5.9319e-06, -3.3533e-06,  2.1529e-05,\n",
            "         7.4417e-06,  2.8755e-05, -2.1307e-05,  2.6000e-05, -3.4757e-05,\n",
            "        -7.1513e-06,  5.7623e-07, -6.6567e-06,  1.1659e-05,  1.1326e-05,\n",
            "        -2.1312e-05, -7.8763e-07,  1.3333e-01,  2.3096e-07, -6.6698e-06,\n",
            "        -9.1593e-06, -6.4341e-06, -3.8159e-06,  2.8710e-01, -4.0702e-06,\n",
            "        -3.2795e-06, -1.2888e-05,  5.1480e-06, -9.9403e-06,  5.5011e-06,\n",
            "        -2.0423e-05, -1.0428e-05,  3.6221e-06, -1.5002e-05,  9.6951e-07,\n",
            "        -2.1690e-05, -2.6654e-05, -8.9870e-06,  1.3346e-05,  5.1381e-05,\n",
            "        -1.1615e-05,  5.2233e-06,  1.2773e-05,  1.0321e-05, -3.6328e-07,\n",
            "         8.6385e-06,  3.3442e-04, -9.0433e-06, -1.3828e-05,  1.3571e-05,\n",
            "        -2.0528e-06,  7.9246e-06, -1.4612e-05,  7.8245e-06,  2.4161e-06,\n",
            "         2.5629e-05, -1.5649e-05, -1.1693e-05, -1.8489e-05,  9.1752e-02,\n",
            "         1.1622e-06,  1.1047e-05,  2.6209e-05, -1.8093e-07, -1.9805e-05,\n",
            "        -1.7298e-05,  7.4247e-06, -1.0376e-05, -4.0515e-06, -2.0275e-03,\n",
            "        -2.9028e-06,  1.6323e-05, -3.6970e-06, -7.5459e-06, -8.1493e-06,\n",
            "        -1.7073e-05, -1.2843e-05,  2.1846e-05, -1.1888e-05, -1.8253e-05,\n",
            "         9.1526e-06, -2.8637e-05, -1.0351e-05, -5.4462e-06, -2.0039e-05,\n",
            "         5.0114e-06, -1.6725e-05, -4.4799e-06,  4.2806e-06,  4.3502e-06,\n",
            "         1.1860e-04, -2.5031e-06,  3.7084e-06, -1.0392e-05,  1.2108e-05,\n",
            "         3.1272e-06,  1.1278e-05,  6.1895e-06,  1.1890e-05,  1.0890e-05,\n",
            "         1.6805e-05,  1.1224e-05, -2.5347e-05, -6.1432e-06, -8.5157e-06,\n",
            "         1.5332e-05, -2.2902e-05,  7.0286e-08,  1.6809e-05, -1.9514e-05,\n",
            "         1.2616e+00, -4.0806e-07, -9.0065e-06,  1.4984e-05, -9.9557e-06,\n",
            "        -2.9409e-06, -2.1855e-05, -2.4545e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-4.2775e-06, -1.1343e-04, -2.4995e-04,  ..., -5.3176e-07,\n",
            "          2.3384e-06,  1.3257e-05],\n",
            "        [ 1.9404e-05,  1.4948e-06,  2.1250e-05,  ..., -1.2017e-05,\n",
            "          1.4063e-05, -2.5858e-05],\n",
            "        [ 1.6556e-05, -2.2951e-05,  1.5897e-05,  ..., -1.1177e-05,\n",
            "          1.6497e-05, -7.5292e-06],\n",
            "        ...,\n",
            "        [ 3.9790e-06,  1.3315e-05, -1.1518e-05,  ..., -5.2189e-06,\n",
            "          1.4842e-05,  1.9737e-06],\n",
            "        [ 6.1459e-06, -2.6647e-04, -5.3769e-04,  ..., -2.0752e-06,\n",
            "         -1.5193e-05, -3.6891e-06],\n",
            "        [ 1.0343e-05, -4.8721e-05, -2.4878e-04,  ..., -3.9793e-06,\n",
            "         -6.1575e-06,  4.1513e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.2836e-02,  8.9675e-06, -3.1461e-06,  1.8699e-05,  6.2174e-06,\n",
            "        -9.2114e-06, -1.4516e-05,  1.5520e-05, -1.7311e-05, -7.1623e-06,\n",
            "         2.0926e-05,  1.1913e-05,  5.2799e-07, -4.5135e-06, -6.8247e-06,\n",
            "         1.5993e-05,  2.3691e-05,  2.9860e-06,  2.2679e-06,  4.5818e-07,\n",
            "         1.4133e-05,  7.7307e-06,  6.0333e-06,  1.4286e-05,  5.9670e-04,\n",
            "         9.9044e-07, -1.7644e-05,  1.1013e-05, -9.9836e-06,  1.9258e-05,\n",
            "         4.6611e-07, -2.1680e-07,  1.0114e-07, -7.7862e-06, -1.3225e-05,\n",
            "         1.8565e-06, -1.5143e-06,  1.7574e-05,  1.1364e-05,  2.8887e-05,\n",
            "         2.8947e-05,  9.1470e-06,  1.5467e-05,  5.8120e-06,  9.3782e-06,\n",
            "        -1.6645e-05, -1.2575e-05, -1.5551e-05,  1.5612e-05, -1.1625e-05,\n",
            "        -1.9976e-06,  1.0841e+00, -1.7601e-06,  6.7924e-06,  2.3283e-07,\n",
            "         8.7910e-02,  1.1799e-05, -5.5968e-06,  1.8127e-05,  1.6964e-05,\n",
            "        -6.4982e-06, -2.8381e-05,  2.5899e-01, -2.7111e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3316e-01,  2.0121e-05,  1.0627e-05,  2.9845e-05,  6.8072e-06,\n",
            "          1.3410e-05,  6.7904e-06,  2.1624e-05, -7.5215e-06,  2.0343e-05,\n",
            "          2.5108e-05,  3.5935e-05,  6.2906e-06,  5.8237e-06, -2.6096e-05,\n",
            "         -2.5017e-05, -7.6747e-06,  3.6459e-06, -2.9951e-06,  2.8793e-05,\n",
            "          5.8345e-06, -1.2833e-05, -1.3030e-05,  3.5215e-05,  5.4587e-01,\n",
            "         -2.7175e-05, -3.2626e-05, -1.4033e-05, -1.8607e-05, -2.7444e-06,\n",
            "          2.8082e-05, -6.4146e-06,  1.6762e-05,  2.6460e-05, -3.4806e-05,\n",
            "          1.1546e-05, -8.4455e-06,  2.9523e-07,  1.4239e-06,  2.8659e-05,\n",
            "          1.8169e-05,  9.5061e-06, -2.5834e-05,  4.3801e-05, -1.3737e-05,\n",
            "          1.8032e-05, -1.1902e-06, -1.8807e-05,  9.4223e-06, -9.0399e-07,\n",
            "         -5.0872e-06,  3.2319e+00,  1.2062e-05, -8.6896e-06,  1.9133e-05,\n",
            "          7.8255e-01, -1.2542e-05,  1.5430e-05,  8.9479e-07, -5.8017e-06,\n",
            "         -2.4523e-06, -1.8677e-05,  1.0850e+00,  2.3903e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3089], requires_grad=True)\n",
            "l1_reg is: 30.19886589050293\n",
            "total_loss 1.2394177913665771\n",
            "pred: tensor([ 5.8298,  6.6677,  2.9065, 14.3241, 22.7241,  2.8281, 10.7255, 24.7907,\n",
            "        25.6224, 24.7692, 13.1694, 13.3108, 28.2738, 19.9388, 11.9325, 10.3957,\n",
            "         9.4990, 21.8388, 33.6975, 16.4986, 23.1746, 23.1299, 16.3450, 11.5853,\n",
            "        24.3300, 15.7084,  8.5816,  2.9995, 22.2805, 24.0352, 10.9490,  9.9762,\n",
            "        17.4365,  9.9777, 13.5298, 32.6051, 25.4667, 34.9257, 23.1238, 11.9652,\n",
            "        13.3499, 25.1367, 12.7928, 21.4577, 14.7878, 10.1964, 10.2060, 21.9164,\n",
            "        25.4173, 17.1116, 24.3073, 16.6587, 15.7890,  9.3050,  9.3508, 23.8246,\n",
            "         7.0209,  9.4108, 36.9932, 25.8969, 15.4949, 25.7722, 16.9809, 11.9021,\n",
            "        19.2037,  4.5880, 25.3534, 26.5707, 24.2818,  5.3938, 35.1043,  7.2309,\n",
            "        16.3638,  9.9712, 26.2149, 18.7371, 35.0365, 23.4975, 15.3030, 20.0810,\n",
            "        18.2541, 12.4269, 18.3479,  7.1251,  9.0329, 19.6210, 15.7379, 16.1043,\n",
            "        14.9957, 23.5066, 16.3926,  3.7415, 24.1902, 14.9783, 11.5414, 21.3178,\n",
            "        21.7171, 15.0015, 11.1204, 22.7207, 16.6014, 25.2459,  6.4804, 14.4218,\n",
            "        17.6644, 11.7158, 27.7728, 20.7344,  3.9433, 20.6927, 24.2875, 14.2152,\n",
            "        19.5544, 19.3968, 17.6807,  7.5942, 20.4400,  7.9395,  7.7689,  9.7975,\n",
            "        16.7283, 30.7873, 12.6844, 17.6457, 28.6731, 10.5983, 11.5586, 12.8528,\n",
            "         6.8184, 19.3751,  4.2264,  7.6213, 25.8748, 22.0329, 26.4388, 23.6799,\n",
            "        14.9412,  6.1891, 14.6030, 23.1911, 22.1933, 24.3567,  5.8548, 30.1030,\n",
            "        21.8074, 21.6938, 11.3558, 26.2036, 32.7610, 11.1230, 14.2046,  2.9907,\n",
            "         5.6438, 27.2197, 13.3256, 19.6363,  4.6054, 11.4066, 29.1345, 20.8637,\n",
            "        24.2251, 25.9641, 12.5619,  3.0816, 13.5347, 23.6061, 16.4783, 13.9057,\n",
            "         8.0700, 24.3801, 13.7416, 21.9858, 20.0900, 16.1220, 23.4363,  5.0087,\n",
            "        23.5828, 11.8045, 23.4549,  6.4382,  4.4531, 26.5420, 28.7591, 24.6661,\n",
            "        12.7518, 12.9119, 25.7486, 16.0690, 22.3991, 22.3190, 21.7724, 24.1007,\n",
            "         9.4831,  8.9280, 19.5457,  6.3429, 11.5361,  5.9076, 17.3840, 19.5835,\n",
            "         5.2942,  5.6737, 11.4086,  5.2875, 21.6647, 23.5487, 14.7084, 16.2726,\n",
            "         3.3865, 25.8250, 25.6477, 19.6486,  2.9480, 15.3181, 10.8047, 25.8753,\n",
            "        11.1109, 22.5297, 17.1950,  9.0894, 13.3664, 14.5470, 21.8707, 18.7398,\n",
            "        26.5268, 13.6502, 24.6100, 26.9562, 11.7023, 24.7549, 24.2943,  7.6862,\n",
            "         8.0588, 22.8910, 11.4416, 19.0813,  6.4158, 13.9631, 12.1237, 20.7439,\n",
            "        19.6728, 23.4899, 12.7824,  3.3575, 14.0317,  5.2019, 16.6612, 10.8120,\n",
            "        24.5306,  9.9385,  6.8014, 25.4245, 11.0152, 20.3805, 11.6725,  3.3150,\n",
            "         6.3421,  7.8545, 15.7029,  8.1707, 14.2107, 22.8417, 14.3759, 17.1378,\n",
            "        26.9350,  8.3526, 19.0110, 10.5637, 12.4761, 19.0345],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "target: tensor([ 5.4799,  6.4774,  3.3854, 17.0000, 22.4311,  2.9914, 11.4516, 24.9279,\n",
            "        25.3483, 24.8764, 14.9485, 12.4621, 28.6023, 19.3636, 11.8827,  9.5732,\n",
            "         8.5330, 22.8746, 33.7301, 17.1018, 23.1277, 22.8307, 14.9121, 10.7669,\n",
            "        25.3447, 15.4825,  9.4678,  2.8817, 24.7080, 23.5130,  9.9165,  9.9478,\n",
            "        17.1327, 10.4907, 14.0291, 30.7192, 25.0184, 36.0309, 22.7201, 12.2768,\n",
            "        13.0535, 26.9901, 13.5650, 21.7220, 14.5407,  9.7996, 10.2122, 23.4177,\n",
            "        25.0174, 18.3399, 25.1940, 15.6231, 15.7477,  9.7469, 10.2668, 23.2051,\n",
            "         6.4413,  9.7919, 36.5372, 26.6139, 17.6947, 26.1120, 17.1398, 11.0963,\n",
            "        17.0130,  5.2515, 26.1624, 25.4491, 25.8145,  5.1181, 34.8983,  7.8195,\n",
            "        16.1607, 10.2887, 25.7021, 19.4343, 33.8672, 24.7881, 15.1062, 21.1667,\n",
            "        18.0294, 12.0640, 18.2666,  7.7907,  8.8788, 19.5518, 15.9647, 16.0288,\n",
            "        15.9616, 22.9585, 15.4802,  3.7538, 23.7719, 15.3680, 11.0313, 19.8565,\n",
            "        23.0299, 15.1882, 10.2621, 21.5261, 16.6193, 25.2529,  6.1983, 15.0504,\n",
            "        16.5541, 11.4049, 29.0552, 20.4538,  2.8868, 20.9514, 25.6969, 13.8726,\n",
            "        18.9278, 19.0772, 16.9548,  7.4901, 20.3410,  9.9713,  6.3798,  8.9391,\n",
            "        15.4370, 31.0876, 12.0155, 17.2766, 29.8231, 11.7996, 12.0462, 15.8105,\n",
            "         6.2667, 19.1964,  4.1837,  8.4217, 26.6361, 21.3319, 26.2393, 23.6692,\n",
            "        15.6540,  6.1922, 15.4348, 24.0158, 22.0323, 24.7204,  6.5705, 30.5629,\n",
            "        20.0336, 21.1755, 10.7634, 26.3507, 33.4507, 10.6060, 13.9031,  2.8186,\n",
            "         6.5000, 25.5266, 12.7119, 19.9705,  4.5723, 12.6457, 25.8247, 19.1094,\n",
            "        24.4635, 25.3228, 12.2253,  2.7835, 14.0352, 24.9138, 16.2340, 15.2404,\n",
            "         7.3643, 25.2707, 13.9387, 22.0329, 19.2753, 16.8718, 22.2416,  5.0395,\n",
            "        25.3326, 11.0437, 22.4624,  6.6406,  4.4715, 26.3172, 29.9533, 24.3549,\n",
            "        11.9753, 13.0631, 24.9986, 15.5514, 22.3483, 21.6111, 22.2808, 25.6826,\n",
            "         9.4027,  9.6307, 17.6503,  6.1916, 13.5715,  5.6287, 15.9091, 19.5808,\n",
            "         5.1852,  5.4622, 10.6810,  4.9911, 21.6922, 24.7181, 16.1979, 16.0194,\n",
            "         3.3276, 27.1796, 26.7724, 19.1687,  2.6395, 16.4095, 11.5276, 24.3048,\n",
            "        11.4865, 21.5116, 18.9223, 10.1438, 13.4760, 13.6691, 22.3123, 21.2180,\n",
            "        27.2146, 14.5794, 24.5346, 27.6427, 12.0504, 24.7865, 22.9460,  8.1948,\n",
            "         8.1349, 22.6690, 10.0882, 17.3852,  6.3316, 13.3827, 12.0312, 18.3412,\n",
            "        19.3611, 22.5502, 12.3650,  3.3958, 13.6777,  5.3413, 15.2778, 10.0902,\n",
            "        26.7301, 10.8617,  6.9672, 25.8740, 10.8994, 19.9523, 12.0991,  3.3051,\n",
            "         7.1010,  8.1897, 16.7840,  8.3830, 15.1587, 24.2598, 13.9712, 17.7502,\n",
            "        27.9089,  8.3295, 20.0685,  9.8110, 12.6549, 18.5847])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[-1.4827e-06,  1.7625e-05, -1.2765e-05,  ...,  1.1831e-05,\n",
            "         -7.4083e-06, -1.4049e-05],\n",
            "        [-1.5162e-05, -1.5862e-04, -6.5829e-06,  ...,  2.4130e-04,\n",
            "          4.4255e-04,  2.8431e-04],\n",
            "        [-3.0055e-04, -2.8406e-04, -1.9156e-05,  ...,  3.8161e-02,\n",
            "          1.4100e-03, -1.9975e-03],\n",
            "        ...,\n",
            "        [-8.7559e-06,  1.1930e-06, -2.0275e-06,  ...,  1.0567e-05,\n",
            "         -1.2270e-05, -3.7112e-08],\n",
            "        [ 1.3299e-05, -6.0797e-06,  1.6860e-05,  ...,  8.5333e-06,\n",
            "         -5.9598e-06,  8.9617e-06],\n",
            "        [-4.0258e-05, -7.4007e-06, -4.5300e-06,  ..., -3.9966e-06,\n",
            "         -1.9360e-05, -1.4154e-05]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 2.1169e-06,  4.2314e-01,  3.5525e-02,  2.5097e-06, -4.7753e-06,\n",
            "         3.8669e-06, -1.3376e-05,  1.1467e-05,  1.5792e+00,  1.5272e-05,\n",
            "        -6.6240e-06, -4.5710e-06,  1.1387e-05,  2.4035e-05, -3.0792e-06,\n",
            "         1.1529e-05,  2.7848e-05, -1.9139e-05,  2.2515e-05, -1.8343e-05,\n",
            "        -1.2194e-05, -2.2960e-05, -7.3388e-06,  1.5766e-05, -4.3221e-06,\n",
            "         3.3674e-06,  1.1157e-05,  1.3316e-01, -8.5092e-06,  5.0515e-06,\n",
            "         5.5045e-06,  9.2201e-06,  2.3901e-06,  2.8708e-01, -8.1710e-06,\n",
            "         1.0020e-05, -1.8481e-05,  9.2554e-06, -3.6366e-06, -1.7725e-06,\n",
            "        -1.8237e-05,  2.1846e-06,  1.5812e-05, -2.1545e-05,  4.0182e-06,\n",
            "        -9.7286e-06, -2.5749e-05,  6.6811e-06, -7.4130e-06,  1.5105e-04,\n",
            "         2.9929e-06, -5.2680e-06, -2.6646e-06,  1.4400e-05,  2.0409e-05,\n",
            "         6.7071e-06,  7.9828e-04, -9.2473e-06, -1.6643e-05, -2.9067e-07,\n",
            "         1.4317e-05,  1.4777e-06,  6.1697e-06,  1.1919e-05,  1.0361e-06,\n",
            "         1.3753e-05, -1.6628e-05, -1.2460e-05, -2.7181e-05,  9.1601e-02,\n",
            "         4.1718e-06, -1.6225e-06,  1.5387e-05,  7.0553e-07, -1.3780e-05,\n",
            "        -2.3145e-05,  3.1947e-07,  1.0395e-05,  1.1617e-05, -2.1043e-03,\n",
            "         8.3608e-06,  1.2047e-05, -3.1436e-06, -5.0752e-06, -1.2268e-05,\n",
            "        -2.3621e-05, -1.8919e-05,  9.8684e-06, -9.4486e-06, -2.4828e-05,\n",
            "        -1.3535e-06, -2.7743e-05, -1.9042e-05, -1.3316e-05, -2.8789e-05,\n",
            "         5.5812e-06, -1.1610e-05,  6.4470e-08,  1.6506e-05, -1.7981e-05,\n",
            "         8.0581e-05,  7.9849e-06, -8.8620e-06,  5.2893e-06,  1.7312e-05,\n",
            "        -9.9642e-06,  1.2027e-05, -4.2725e-06,  1.5983e-05, -4.7793e-06,\n",
            "         2.6906e-05,  1.2627e-05, -4.0049e-05,  5.6122e-06,  8.4126e-06,\n",
            "         6.1641e-06, -1.0922e-05, -1.5707e-05,  1.0508e-05, -1.3746e-05,\n",
            "         1.2612e+00,  2.7613e-07, -1.4379e-05,  3.0132e-06,  5.7565e-06,\n",
            "         3.9597e-06, -1.7184e-05, -2.0449e-05], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 7.3382e-06, -1.4209e-04, -1.8548e-04,  ...,  1.2875e-05,\n",
            "         -1.1357e-05, -1.1901e-06],\n",
            "        [ 1.3698e-05, -1.6456e-05,  9.2885e-06,  ...,  3.6564e-06,\n",
            "          2.2752e-05, -2.2174e-05],\n",
            "        [ 1.4377e-05, -1.8843e-05, -3.8412e-06,  ...,  3.4702e-06,\n",
            "          9.0085e-06, -1.1636e-05],\n",
            "        ...,\n",
            "        [ 2.5249e-06,  1.8958e-05,  3.6979e-06,  ...,  4.4323e-06,\n",
            "          6.4332e-06, -1.8792e-05],\n",
            "        [ 9.4730e-06, -3.3662e-04, -4.5035e-04,  ...,  9.2134e-06,\n",
            "         -2.0019e-05,  9.6065e-07],\n",
            "        [-4.1766e-06, -1.2042e-05, -2.2426e-04,  ...,  8.5753e-06,\n",
            "         -2.3638e-06,  2.7081e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.2647e-02,  9.1413e-06,  9.4098e-06,  2.7388e-05, -1.9529e-05,\n",
            "        -6.0466e-06, -6.3768e-06,  7.6773e-06, -2.4151e-05, -8.3850e-06,\n",
            "         1.5271e-05,  5.6047e-06, -5.9603e-06,  8.0412e-06,  4.9067e-06,\n",
            "         2.2531e-05,  1.9231e-05, -3.9069e-06, -1.1418e-05, -2.0308e-05,\n",
            "        -5.6119e-06, -7.9505e-06,  6.9390e-06,  2.4053e-05,  5.0923e-04,\n",
            "        -5.2140e-06, -1.2953e-05, -1.0478e-06, -1.2573e-05,  2.9771e-05,\n",
            "        -1.0033e-05,  6.6743e-06, -5.6130e-06, -7.5606e-06,  2.4482e-06,\n",
            "        -9.4495e-06,  2.1164e-05,  1.2606e-05, -3.1133e-06,  3.0743e-05,\n",
            "         2.6770e-05,  6.2398e-07,  1.9708e-05, -7.0365e-06,  4.9367e-08,\n",
            "        -1.1673e-05,  2.6159e-06, -1.0577e-05,  2.4316e-05,  2.2175e-06,\n",
            "         2.6516e-07,  1.0834e+00,  1.1996e-05, -4.8406e-07, -1.5476e-05,\n",
            "         8.7680e-02,  1.7615e-05, -1.7980e-06,  3.9085e-06,  1.4781e-05,\n",
            "        -1.9270e-07, -2.0059e-05,  2.5871e-01, -2.4643e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3306e-01,  1.7957e-05,  3.7005e-06,  2.1488e-05,  7.7758e-06,\n",
            "          1.8100e-05, -1.0498e-05,  1.7503e-05,  2.4270e-06,  2.9494e-05,\n",
            "          7.6045e-06,  2.7632e-05, -9.3706e-06,  9.9113e-06, -2.2598e-05,\n",
            "         -4.2572e-05, -7.0965e-06, -9.4685e-06,  4.6856e-07,  2.8112e-05,\n",
            "         -6.3883e-06, -2.1501e-05, -1.0032e-05,  1.8832e-05,  5.4577e-01,\n",
            "         -2.5390e-05, -2.4329e-05, -1.8233e-05, -1.2315e-05, -5.7611e-06,\n",
            "          1.9745e-05,  1.0882e-05,  2.6819e-05,  1.5653e-05, -3.4927e-05,\n",
            "          4.6147e-06,  1.1465e-06, -1.5364e-05, -1.6256e-05,  2.6877e-05,\n",
            "          2.8249e-05,  8.9480e-06, -2.4771e-05,  2.9494e-05, -1.7845e-05,\n",
            "          3.7942e-06,  1.7185e-05, -2.9298e-05,  1.5798e-05,  1.7474e-05,\n",
            "          6.5205e-06,  3.2314e+00, -3.1252e-06, -1.7354e-05,  1.2841e-05,\n",
            "          7.8241e-01,  7.3848e-06,  9.0899e-06, -6.0125e-06, -2.0129e-06,\n",
            "         -2.3358e-07, -2.9191e-05,  1.0848e+00,  2.3893e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3086], requires_grad=True)\n",
            "l1_reg is: 30.217723846435547\n",
            "total_loss 1.1234021186828613\n",
            "pred: tensor([19.4617, 14.5569, 16.4295, 16.7375, 18.8812, 20.4944, 22.4743,  4.7778,\n",
            "         8.2270,  6.2078,  7.5977,  5.1123, 13.1194, 17.4591,  6.8136,  6.2947,\n",
            "         5.7878,  6.8873,  7.9045, 12.6297, 13.0763, 14.7864, 12.4118, 22.0192,\n",
            "        16.0912, 20.3663, 25.1874,  7.4207,  5.9567,  6.6425,  5.8281,  5.6488,\n",
            "         7.6271,  7.8467,  6.3454,  5.1281,  7.2724,  7.9466,  9.6571, 18.3290,\n",
            "        20.9526,  3.5231,  3.2941,  4.0306,  5.1339,  6.5957,  9.0436,  9.9106,\n",
            "         9.5826,  9.4540,  9.2020, 11.5796,  9.9158, 13.2020, 14.1186, 14.6607,\n",
            "        11.6402, 13.5287, 12.5989, 14.0572, 15.3002, 17.3178, 14.8640, 24.5377,\n",
            "        24.6688, 31.8445, 31.5735,  8.9292,  9.5331, 10.5059, 10.5232, 14.0562,\n",
            "        20.3536, 25.0847,  8.4394,  9.2939,  9.9040, 14.4102, 18.2107, 22.9547,\n",
            "        26.3562, 15.9436, 17.1950, 15.4516, 20.5583, 22.8775, 33.3861, 35.9852,\n",
            "        10.5848, 15.4898, 16.3199, 16.6492, 27.1293, 31.9942,  6.2146,  9.3240,\n",
            "         6.3832,  9.8829,  9.8768, 13.8438, 16.0918, 15.5241, 11.7772, 12.8084,\n",
            "        18.0203, 17.0800, 18.1662, 19.8467,  4.2221,  5.4927,  5.1367,  5.8929,\n",
            "         7.1766,  8.6147,  2.6560,  2.7179,  3.1464,  3.7159,  3.1531,  5.0659,\n",
            "         6.2558,  4.6679,  6.9260,  9.6320,  9.0460, 12.1096, 20.2366, 21.6186,\n",
            "         6.8769,  8.7579, 10.3775, 13.7746, 15.2841, 23.1958, 24.8245, 25.2936,\n",
            "        23.9789, 25.7100, 30.0501, 34.5608, 31.6549, 28.7191, 22.9032, 24.1856,\n",
            "        23.0902, 26.2789, 24.6052, 19.8947, 24.5142, 25.3832, 23.4329, 23.0774,\n",
            "        22.5011, 24.5877, 17.7485, 23.5880, 26.8604, 25.6769, 25.0504, 25.5078,\n",
            "        21.5545, 21.1931, 12.0591, 14.6342, 15.5944, 12.9369, 15.8170, 13.6884,\n",
            "        19.2516, 17.8126, 17.9103, 15.0399, 17.4888, 16.0112, 14.9551,  7.1635,\n",
            "         8.3769,  9.7944, 11.0024, 12.8543, 14.1744, 12.7139, 13.2268, 14.1796,\n",
            "        18.3044, 18.0763, 20.6730, 21.2460, 21.4008, 22.5522, 25.3501, 26.1311,\n",
            "        23.9143, 26.2153, 25.9649, 20.7010, 22.8997, 27.1019, 27.9672, 29.3766,\n",
            "        33.4530, 27.6938, 10.4254, 11.3823, 11.3263, 12.9609, 13.6309, 13.1640,\n",
            "         9.9583, 18.7095, 23.2719, 23.9771, 26.2280, 25.2140, 24.8461, 21.8929,\n",
            "        14.3146, 15.6931, 16.2751, 10.8680, 13.1387, 10.0388,  9.9370, 12.2371,\n",
            "        17.9349, 19.5088, 20.6446, 24.8297, 24.8098, 19.1430, 20.5358, 22.0533,\n",
            "        22.5005, 25.0649, 27.9947, 25.1264, 26.6297, 22.3703, 25.6054, 23.0749,\n",
            "        26.9419, 29.6788, 19.6977, 12.0720, 15.4426, 16.8932, 21.1700, 19.5557,\n",
            "        24.3034, 21.7628, 10.3476, 11.8382, 12.6096, 12.1194, 12.1276, 11.8537,\n",
            "         9.7447, 16.8543, 16.2447, 18.7445, 20.8465, 24.0696, 22.3466, 17.1385,\n",
            "        21.4825, 19.5332, 18.3649, 14.0580, 15.9407, 15.0837])\n",
            "target: tensor([20.7049, 14.7807, 15.6246, 16.3530, 21.1403, 20.8325, 24.9998,  3.5714,\n",
            "         8.6364,  5.7692,  8.6777,  2.8689, 13.1818, 16.1972,  6.8915,  6.3984,\n",
            "         5.9165,  7.7938,  7.7073, 12.3563, 12.7403, 14.3317, 11.1861, 21.9149,\n",
            "        15.7216, 20.2072, 25.5939,  7.4021,  6.4085,  6.0283,  5.9251,  5.5663,\n",
            "         7.7832,  7.3929,  6.8333,  4.4167,  8.1111,  8.1560, 10.5540, 19.6793,\n",
            "        19.3069,  3.7081,  3.7349,  3.5714,  5.3172,  7.1256,  9.6074,  9.9155,\n",
            "         9.7659,  9.7680,  9.4623, 12.0087, 10.4674, 14.1234, 13.6284, 16.2547,\n",
            "        12.1887, 13.4219, 11.4552, 13.7278, 14.9270, 16.9451, 13.5416, 24.6665,\n",
            "        25.5589, 31.2903, 33.9516,  8.7232,  9.4743, 10.4471, 10.4545, 13.6004,\n",
            "        21.5362, 24.7947,  8.0300, 10.0231, 10.1980, 13.5331, 17.4769, 24.8762,\n",
            "        26.2595, 15.9436, 16.9328, 17.6547, 20.6308, 22.7727, 35.3088, 36.3085,\n",
            "         9.6535, 14.2492, 17.8857, 18.5279, 27.2095, 34.6939,  5.5838,  8.7310,\n",
            "         5.3524, 10.9467, 10.6357, 15.4454, 17.5906, 15.9164, 12.1667, 11.6864,\n",
            "        18.8136, 16.1972, 20.7895, 19.6934,  3.4328,  5.3623,  6.6978,  4.7965,\n",
            "         7.0447,  7.5002,  2.7955,  2.6699,  2.9236,  4.3846,  2.8400,  4.2266,\n",
            "         6.3151,  3.5552,  5.7635,  9.5210,  7.8600, 11.7246, 21.8559, 21.3177,\n",
            "         8.4688,  9.5714, 10.6358, 13.0657, 15.2333, 25.8462, 23.3341, 26.2862,\n",
            "        24.1377, 25.5078, 32.0859, 34.6538, 32.1228, 27.8052, 21.7863, 24.6114,\n",
            "        23.7782, 25.3970, 25.9979, 19.5248, 25.9552, 25.1661, 25.5945, 22.8514,\n",
            "        21.9144, 24.1784, 18.4365, 21.6929, 25.4017, 24.9391, 25.2821, 27.2217,\n",
            "        21.4053, 18.9927, 11.9544, 13.8410, 14.0538, 13.6969, 15.8808, 13.5315,\n",
            "        19.8848, 16.4687, 18.2368, 13.7259, 17.7635, 15.5539, 14.0926,  6.9774,\n",
            "         8.3083,  9.6499, 11.0942, 12.5183, 13.5763, 12.8692, 12.9802, 13.9286,\n",
            "        18.6407, 18.1189, 20.1045, 20.9195, 20.7997, 23.7527, 24.5305, 26.1734,\n",
            "        24.5663, 26.8204, 25.4401, 20.5535, 22.1942, 26.6685, 28.8944, 28.5828,\n",
            "        35.6474, 26.9797,  9.8705, 11.2216,  9.6731, 13.3239, 12.5317, 12.5703,\n",
            "         8.2829, 19.1983, 22.5969, 23.5935, 25.9001, 24.6988, 25.2553, 21.3563,\n",
            "        12.1133, 16.9385, 17.0957,  8.9584, 13.6514,  9.6829, 10.1373, 10.3420,\n",
            "        17.6791, 20.2152, 20.7517, 25.9487, 24.4629, 20.1631, 20.3369, 21.6015,\n",
            "        23.2329, 24.6127, 28.6281, 25.0085, 27.3285, 22.5122, 25.8700, 23.2383,\n",
            "        27.3183, 31.4549, 20.4373, 12.4127, 15.8738, 17.5510, 21.0565, 19.5545,\n",
            "        24.4510, 22.1006,  9.8401, 10.0151, 11.3076, 11.8321, 10.3945, 11.5500,\n",
            "         9.4237, 16.0550, 16.3664, 19.7704, 20.4319, 23.6292, 21.6321, 16.5551,\n",
            "        21.9787, 20.1007, 18.6773, 12.9403, 17.1829, 13.6446])\n",
            "parameters shape are: torch.Size([128, 93])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 7.3262e-06,  1.5445e-05,  2.6947e-06,  ..., -3.8384e-06,\n",
            "         -1.0988e-06, -5.3376e-06],\n",
            "        [-2.9759e-05, -1.3129e-04,  1.7299e-05,  ...,  3.1126e-04,\n",
            "          2.2461e-04,  1.5587e-04],\n",
            "        [-3.2030e-04, -2.5583e-04, -6.5513e-06,  ...,  3.8410e-02,\n",
            "          1.5030e-03, -2.0246e-03],\n",
            "        ...,\n",
            "        [-1.0052e-05, -4.6373e-06, -5.9352e-06,  ...,  6.5331e-07,\n",
            "         -1.4361e-05,  1.2915e-05],\n",
            "        [-7.4656e-06, -4.8990e-06,  2.6948e-05,  ...,  2.2406e-06,\n",
            "         -1.3716e-05,  4.3421e-07],\n",
            "        [-2.5944e-05, -9.0385e-06,  1.8266e-05,  ..., -2.5269e-06,\n",
            "         -2.8038e-05,  6.5962e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([-8.3745e-06,  4.2302e-01,  3.5508e-02,  1.0115e-05, -5.3403e-06,\n",
            "        -4.8466e-06, -1.0442e-05, -3.0167e-06,  1.5789e+00,  2.3947e-05,\n",
            "        -3.1796e-06, -3.6694e-07,  1.6971e-05,  3.8690e-05, -1.5221e-05,\n",
            "         5.2028e-06,  1.7034e-05, -7.1897e-06,  9.3676e-06,  6.4299e-06,\n",
            "        -6.7332e-06, -3.4135e-05,  2.0470e-06,  9.4631e-06, -8.4020e-06,\n",
            "         1.5580e-05,  1.1897e-05,  1.3305e-01, -6.3747e-06,  5.5988e-06,\n",
            "         8.7012e-06,  1.3307e-05, -1.9921e-06,  2.8699e-01, -1.8615e-06,\n",
            "         1.1990e-05, -1.3507e-05,  2.9589e-06,  1.2028e-05,  1.6819e-06,\n",
            "        -6.2623e-06,  3.5368e-06,  1.6772e-05, -1.7440e-05, -3.2392e-06,\n",
            "         1.1040e-05, -1.4933e-05,  1.0778e-05, -1.6092e-05,  1.9921e-04,\n",
            "         6.1424e-06, -4.7102e-06, -6.5625e-06,  8.0714e-06,  2.9103e-05,\n",
            "        -5.0320e-06,  9.1359e-04,  5.6855e-07, -9.1783e-06, -2.7803e-06,\n",
            "         1.9038e-05, -1.4325e-05,  1.4874e-05,  5.5999e-06, -1.0206e-05,\n",
            "        -6.9377e-06, -7.5079e-06, -3.1507e-06, -2.5002e-05,  9.1482e-02,\n",
            "        -3.1245e-06, -3.0260e-06, -4.3546e-06, -8.4878e-06,  1.6443e-06,\n",
            "        -1.8407e-05, -1.6075e-05,  1.9090e-05,  1.5722e-05, -2.1364e-03,\n",
            "         8.4988e-06, -1.7997e-06,  7.3562e-06,  7.1469e-06, -5.9753e-06,\n",
            "        -1.9515e-05, -1.4388e-05, -1.0912e-05,  2.7461e-06, -2.0744e-05,\n",
            "        -8.0943e-07, -1.6923e-05, -1.6878e-05, -1.0388e-05, -2.6664e-05,\n",
            "        -3.8957e-06,  2.9934e-06, -5.8476e-06,  1.7507e-05, -2.8079e-05,\n",
            "         6.1418e-05,  7.4236e-06, -1.0174e-05,  9.3988e-06,  1.2003e-05,\n",
            "        -1.1744e-05,  2.6969e-06, -3.6870e-06,  9.6676e-06, -8.8940e-06,\n",
            "         2.5993e-05,  3.9006e-06, -4.3282e-05,  6.1916e-06,  1.3646e-05,\n",
            "        -1.2090e-05,  9.8596e-06, -1.9912e-05, -5.1516e-06,  1.4431e-06,\n",
            "         1.2610e+00, -9.1040e-06, -9.2166e-06, -1.7761e-05,  9.9050e-06,\n",
            "         1.7477e-07, -2.9857e-06, -6.7618e-06], requires_grad=True)\n",
            "parameters shape are: torch.Size([64, 128])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 7.7953e-06, -1.3672e-04, -1.1938e-04,  ...,  1.4946e-05,\n",
            "         -1.3684e-05, -4.1911e-06],\n",
            "        [-1.4376e-06, -2.2612e-05, -1.1477e-05,  ...,  7.7629e-06,\n",
            "          2.0572e-05, -8.8589e-06],\n",
            "        [ 2.4148e-06, -5.1460e-06, -1.1606e-05,  ...,  6.6524e-06,\n",
            "         -7.7308e-06, -5.3314e-06],\n",
            "        ...,\n",
            "        [-8.7837e-06,  1.4037e-05,  7.3934e-06,  ...,  3.1184e-06,\n",
            "         -1.1135e-05, -2.7481e-05],\n",
            "        [ 2.4732e-06, -3.4669e-04, -3.6565e-04,  ...,  9.3849e-06,\n",
            "         -1.4364e-05, -4.8521e-06],\n",
            "        [-7.2442e-06,  3.0970e-05, -1.9220e-04,  ...,  9.8744e-06,\n",
            "          1.1050e-05, -8.5908e-06]], requires_grad=True)\n",
            "parameters shape are: torch.Size([64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([ 1.2521e-02, -7.0229e-07,  1.0711e-05,  2.5212e-05, -3.2701e-05,\n",
            "         6.8017e-06,  1.0948e-05, -9.3814e-06, -2.0307e-05,  5.1324e-07,\n",
            "         1.8186e-07, -1.0070e-05, -1.7998e-06,  9.3415e-06,  5.4610e-06,\n",
            "         1.8418e-05,  5.2166e-06, -1.1021e-07, -1.3735e-05, -2.8998e-05,\n",
            "        -1.3383e-05, -1.2064e-05, -2.2466e-06,  2.2845e-05,  4.7495e-04,\n",
            "        -7.9590e-07,  1.2662e-06, -1.9030e-06, -4.9045e-06,  2.9233e-05,\n",
            "        -9.4831e-06,  2.8760e-06, -7.5564e-07,  2.6441e-06,  6.5503e-06,\n",
            "        -9.6248e-06,  3.1575e-05, -1.8671e-06, -6.1443e-06,  2.2414e-05,\n",
            "         1.4811e-05, -1.7047e-05,  1.3523e-05, -8.5950e-06, -1.8349e-05,\n",
            "         2.8027e-06,  6.2867e-06,  3.8987e-06,  2.2148e-05,  4.6757e-06,\n",
            "        -7.6986e-06,  1.0832e+00,  1.4375e-05,  2.9659e-06, -1.9612e-05,\n",
            "         8.7542e-02,  1.2851e-05,  1.1621e-05, -1.8887e-05,  2.8165e-06,\n",
            "         1.5482e-05, -2.5681e-06,  2.5856e-01, -2.1421e-04],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1, 64])\n",
            "parameters are: Parameter containing:\n",
            "tensor([[ 5.3295e-01,  6.0097e-06, -1.2532e-05,  3.9675e-06, -1.3525e-06,\n",
            "          1.2321e-05, -1.6058e-05,  3.7945e-06,  1.3807e-06,  2.7727e-05,\n",
            "         -1.8146e-05,  1.0171e-05, -1.3466e-05,  3.5914e-06, -9.4475e-06,\n",
            "         -4.8374e-05,  3.4367e-06, -1.1271e-05, -6.4146e-06,  1.7499e-05,\n",
            "         -7.3873e-06, -1.9303e-05,  2.6674e-06, -5.9108e-06,  5.4567e-01,\n",
            "         -1.3786e-05, -6.8620e-06, -1.2014e-05,  3.3469e-06,  1.5272e-06,\n",
            "          2.2418e-06,  1.6448e-05,  2.5871e-05, -4.0690e-06, -2.5029e-05,\n",
            "         -1.1623e-05, -2.1805e-07, -1.9452e-05, -2.2165e-05,  1.5273e-05,\n",
            "          2.7322e-05, -1.5543e-06, -1.3811e-05,  6.6192e-06, -1.1537e-05,\n",
            "         -1.9019e-05,  2.3721e-05, -2.8740e-05,  1.1536e-05,  2.4013e-05,\n",
            "          6.9673e-06,  3.2312e+00, -6.7892e-06, -1.5153e-05, -2.8161e-06,\n",
            "          7.8230e-01,  1.5329e-05, -6.6161e-06, -2.2314e-06,  1.1395e-05,\n",
            "          1.1765e-05, -2.8653e-05,  1.0847e+00,  2.3883e-01]],\n",
            "       requires_grad=True)\n",
            "parameters shape are: torch.Size([1])\n",
            "parameters are: Parameter containing:\n",
            "tensor([2.3084], requires_grad=True)\n",
            "l1_reg is: 30.19413185119629\n",
            "total_loss 1.1607334613800049\n",
            "Finished training after 1000 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "hsNO9nnXQBvP",
        "outputId": "47b5c71e-4da6-400f-8479-2293a1bd33de"
      },
      "source": [
        "plot_learning_curve(model_loss_record, title='deep model')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAGJCAYAAAAEz3CAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACC10lEQVR4nO3dd1wT9xsH8E8IJBD2BhUUAffGUVfdW6vWVuvGWffWOn6uOnDXUavVOmvdo66qda86wT1wgaCyZIU9ku/vj8CRI4MEgaA879eLV7m77909OVPy5DsFjDEGQgghhBANjAwdACGEEEKKN0oWCCGEEKIVJQuEEEII0YqSBUIIIYRoRckCIYQQQrSiZIEQQgghWlGyQAghhBCtKFkghBBCiFaULBBCCCFEK0oWCNFDuXLl4Ovra+gwSpTExEQMHToULi4uEAgEmDBhgt7XEAgEmDdvXoHH9iX5lPc2Pd8vHyULpMht374dAoEAd+/eNXQo5DOwePFibN++HSNHjsSff/6J/v37GzokQkocY0MHQMjnJDAwEEZGlGMXpQsXLuCrr77C3LlzDR0KISUW/dUjJVZmZibS09P1OkcsFsPExKSQIjKspKQkQ4egVmRkJGxsbAwdBiElGiULpNh6//49Bg8eDGdnZ4jFYlStWhVbt27llUlPT8ecOXPg4+MDa2trmJubo2nTprh48SKvXHBwMAQCAVasWIHVq1fD09MTYrEYT58+xbx58yAQCPDq1Sv4+vrCxsYG1tbWGDRoEJKTk3nXyd2um92kcv36dUyaNAmOjo4wNzdH9+7dERUVxTtXLpdj3rx5KFWqFCQSCVq0aIGnT5/q3FYsl8uxZs0aVK9eHaampnB0dET79u255pzs17h9+3aVc3O3KWe/5qdPn6JPnz6wtbVFkyZNsGLFCggEArx9+1blGjNmzIBIJEJsbCy379atW2jfvj2sra0hkUjQrFkzXL9+Pc/XAiiSgCFDhsDZ2RmmpqaoWbMmduzYwR2/dOkSBAIBgoKCcPLkSQgEAggEAgQHB2u8ZlpaGiZOnAhHR0dYWlrim2++wbt379SW1eX9lX3NuXPnwsvLC2KxGG5ubpg2bRrS0tJ45QQCAcaMGYO//voLFStWhKmpKXx8fHDlypU8n0X2a92/fz/mz5+P0qVLw9LSEt999x3i4+ORlpaGCRMmwMnJCRYWFhg0aJDK/TMzM7FgwQLuvV2uXDnMnDlTpRxjDAsXLkSZMmW49+GTJ0/UxhUXF4cJEybAzc0NYrEYXl5eWLp0KeRyeZ6viXxZqBmCFEsRERH46quvuD/Ajo6OOHXqFIYMGQKpVMp1cpNKpfjjjz/Qu3dvDBs2DAkJCdiyZQvatWuH27dvo1atWrzrbtu2DampqRg+fDjEYjHs7Oy4Yz179oSHhwf8/PwQEBCAP/74A05OTli6dGme8Y4dOxa2traYO3cugoODsXr1aowZMwb79u3jysyYMQPLli1Dly5d0K5dOzx48ADt2rVDamqqTs9kyJAh2L59Ozp06IChQ4ciMzMTV69exc2bN1G3bl2drpHb999/D29vbyxevBiMMXTu3BnTpk3D/v37MXXqVF7Z/fv3o23btrC1tQWgaB7o0KEDfHx8MHfuXBgZGWHbtm1o2bIlrl69ivr162u8b0pKCpo3b45Xr15hzJgx8PDwwIEDB+Dr64u4uDiMHz8elStXxp9//omJEyeiTJkymDx5MgDA0dFR43WHDh2KXbt2oU+fPmjUqBEuXLiATp06qZTT9f0ll8vxzTff4Nq1axg+fDgqV66MR48e4ZdffsGLFy/w999/8657+fJl7Nu3D+PGjYNYLMZvv/2G9u3b4/bt26hWrVqe/x5+fn4wMzPD9OnT8erVK6xbtw4mJiYwMjJCbGws5s2bh5s3b2L79u3w8PDAnDlzeK99x44d+O677zB58mTcunULfn5+ePbsGY4cOcKVmzNnDhYuXIiOHTuiY8eOCAgIQNu2bVVq2ZKTk9GsWTO8f/8eP/74I9zd3fHff/9hxowZCAsLw+rVq/N8PeQLwggpYtu2bWMA2J07dzSWGTJkCHN1dWUfP37k7f/hhx+YtbU1S05OZowxlpmZydLS0nhlYmNjmbOzMxs8eDC3LygoiAFgVlZWLDIykld+7ty5DACvPGOMde/endnb2/P2lS1blg0cOFDltbRu3ZrJ5XJu/8SJE5lQKGRxcXGMMcbCw8OZsbEx69atG+968+bNYwB411TnwoULDAAbN26cyrHs+2a/xm3btqmUAcDmzp2r8pp79+6tUrZhw4bMx8eHt+/27dsMANu5cyd3T29vb9auXTve605OTmYeHh6sTZs2Wl/P6tWrGQC2a9cubl96ejpr2LAhs7CwYFKplNtftmxZ1qlTJ63XY4yx+/fvMwBs1KhRvP19+vRRef26vr/+/PNPZmRkxK5evcort3HjRgaAXb9+ndsHgAFgd+/e5fa9ffuWmZqasu7du2uN/eLFiwwAq1atGktPT+f29+7dmwkEAtahQwde+YYNG7KyZcuqvPahQ4fyyk2ZMoUBYBcuXGCMMRYZGclEIhHr1KkT799t5syZKu/DBQsWMHNzc/bixQveNadPn86EQiELCQnhvXbl50u+PNQMQYodxhgOHTqELl26gDGGjx8/cj/t2rVDfHw8AgICAABCoRAikQiA4ltgTEwMMjMzUbduXa6Msh49emj8ZjpixAjedtOmTREdHQ2pVJpnzMOHD4dAIOCdK5PJuOr88+fPIzMzE6NGjeKdN3bs2DyvDQCHDh2CQCBQ28lP+b76yv2aAaBXr17w9/fH69evuX379u2DWCxG165dAQD379/Hy5cv0adPH0RHR3P/PklJSWjVqhWuXLmitar6n3/+gYuLC3r37s3tMzExwbhx45CYmIjLly/r/Vr++ecfAMC4ceN4+3MPtdTn/XXgwAFUrlwZlSpV4pVr2bIlAKg0dzVs2BA+Pj7ctru7O7p27YozZ85AJpPl+RoGDBjA6xPToEEDMMYwePBgXrkGDRogNDQUmZmZvNc+adIkXrns2piTJ08CAM6dO4f09HSMHTuW975RNxz1wIEDaNq0KWxtbXmvvXXr1pDJZDo1r5AvBzVDkGInKioKcXFx2LRpEzZt2qS2TGRkJPf7jh07sHLlSjx//hwZGRncfg8PD5Xz1O3L5u7uztvOrm6PjY2FlZWV1pi1nQuASxq8vLx45ezs7Liy2rx+/RqlSpXiNZsUBHXP4/vvv8ekSZOwb98+zJw5E4wxHDhwAB06dOCew8uXLwEAAwcO1Hjt+Ph4ja/t7du38Pb2VhlZUrlyZe64vt6+fQsjIyN4enry9lesWJG3rc/76+XLl3j27JnGBFP5fQgA3t7eKmUqVKiA5ORkREVFwcXFRetryP0+sra2BgC4ubmp7JfL5YiPj4e9vT332nO/v1xcXGBjY8M9z+z/5o7T0dFR5d/q5cuXePjwoc6vnXzZKFkgxU72N9J+/fpp/DCqUaMGAGDXrl3w9fVFt27dMHXqVDg5OUEoFMLPz4/3zTibmZmZxvsKhUK1+xljecb8KecWFE01DNq+0ap7HqVKlULTpk2xf/9+zJw5Ezdv3kRISAiv70b2v9Hy5ctV+oVks7Cw0CP6oqPP+0sul6N69epYtWqV2nK5P8Q/lab3ka7vr0+pZcpNLpejTZs2mDZtmtrjFSpUKLB7keKPkgVS7GT3ZJfJZGjdurXWsgcPHkT58uVx+PBh3h/K4jYmv2zZsgCAV69e8b7NR0dH80YXaOLp6YkzZ84gJiZGY+1C9jfDuLg43v78fEvv1asXRo0ahcDAQOzbtw8SiQRdunThxQMAVlZWef4bqVO2bFk8fPgQcrmcV7vw/Plz7nh+rimXy/H69WtebUJgYCCvnD7vL09PTzx48ACtWrXS6YM4u8ZF2YsXLyCRSLR2zPxU2a/95cuXXO0MoOjIGRcXxz3P7P++fPkS5cuX58pFRUWpvA89PT2RmJiYr39f8uWhPguk2BEKhejRowcOHTqEx48fqxxXHpKY/Y1L+RvWrVu3cOPGjcIPVA+tWrWCsbExNmzYwNv/66+/6nR+jx49wBjD/PnzVY5lv3YrKys4ODiotCX/9ttvesfbo0cPCIVC7NmzBwcOHEDnzp1hbm7OHffx8YGnpydWrFiBxMRElfNzDxvNrWPHjggPD+eNFsnMzMS6detgYWGBZs2a6R1zhw4dAABr167l7c/da1+f91fPnj3x/v17bN68WaVcSkqKytwUN27c4PWVCQ0NxdGjR9G2bVuNtQMFoWPHjgBUX2t2jUj2iJDWrVvDxMQE69at4/0/o25kQ8+ePXHjxg2cOXNG5VhcXBzXX4KUDFSzQAxm69atOH36tMr+8ePHY8mSJbh48SIaNGiAYcOGoUqVKoiJiUFAQADOnTuHmJgYAEDnzp1x+PBhdO/eHZ06dUJQUBA2btyIKlWqqP0QMxRnZ2eMHz8eK1euxDfffIP27dvjwYMHOHXqFBwcHPL81tqiRQv0798fa9euxcuXL9G+fXvI5XJcvXoVLVq0wJgxYwAohs8tWbIEQ4cORd26dXHlyhW8ePFC73idnJzQokULrFq1CgkJCejVqxfvuJGREf744w906NABVatWxaBBg1C6dGm8f/8eFy9ehJWVFY4fP67x+sOHD8fvv/8OX19f+Pv7o1y5cjh48CCuX7+O1atXw9LSUu+Ya9Wqhd69e+O3335DfHw8GjVqhPPnz+PVq1cqZXV9f/Xv3x/79+/HiBEjcPHiRTRu3BgymQzPnz/H/v37cebMGd6w1WrVqqFdu3a8oZMA1CZ5BalmzZoYOHAgNm3ahLi4ODRr1gy3b9/Gjh070K1bN7Ro0QKAolZlypQp8PPzQ+fOndGxY0fcu3ePex8qmzp1Ko4dO4bOnTvD19cXPj4+SEpKwqNHj3Dw4EEEBwernEO+YAYZg0FKtOzhhpp+QkNDGWOMRUREsNGjRzM3NzdmYmLCXFxcWKtWrdimTZu4a8nlcrZ48WJWtmxZJhaLWe3atdmJEyfYwIEDeUPLsocVLl++XCWe7GGEUVFRauMMCgri9mkaOpl7GGj2ULiLFy9y+zIzM9ns2bOZi4sLMzMzYy1btmTPnj1j9vb2bMSIEXk+t8zMTLZ8+XJWqVIlJhKJmKOjI+vQoQPz9/fnyiQnJ7MhQ4Ywa2trZmlpyXr27MkiIyM1Dp3M/ZqVbd68mQFglpaWLCUlRW2Ze/fusW+//ZbZ29szsVjMypYty3r27MnOnz+f5+uJiIhggwYNYg4ODkwkErHq1aurHfap69BJxhhLSUlh48aNY/b29szc3Jx16dKFhYaGqh3ap8v7izHFkM6lS5eyqlWrMrFYzGxtbZmPjw+bP38+i4+P58oBYKNHj2a7du1i3t7e3PtR+T2gSfb75cCBA7z9mt5f6v79MjIy2Pz585mHhwczMTFhbm5ubMaMGSw1NZV3rkwmY/Pnz2eurq7MzMyMNW/enD1+/Fjlvc0YYwkJCWzGjBnMy8uLiUQi5uDgwBo1asRWrFjBG+Kp7vmSL4uAsSLsgUUI4YmLi4OtrS0WLlyIWbNmGToc8gkEAgFGjx6tc9MSIZ8T6rNASBFJSUlR2ZfdVty8efOiDYYQQvRAfRYIKSL79u3D9u3b0bFjR1hYWODatWvYs2cP2rZti8aNGxs6PEII0YiSBUKKSI0aNWBsbIxly5ZBKpVynR4XLlxo6NAIIUQrg/ZZmDdvnkov4YoVK3JjrQkhhBBieAavWahatSrOnTvHbRsbGzwkQgghhCgx+CezsbFxnvOlE0IIIcRwDJ4svHz5EqVKlYKpqSkaNmwIPz8/lcVUsqWlpSEtLY3bzl5l0N7evkDnRCeEEEK+dIwxJCQkoFSpUiqLuuVm0D4Lp06dQmJiIipWrIiwsDDMnz8f79+/x+PHj9XO4KaujwMhhBBC8i80NBRlypTRWqZYTcqUveDJqlWrMGTIEJXjuWsW4uPj4e7ujtDQ0DyXEDYUJpPhx9WbcaFeIww4eQi9zp1ERf+7hg6LEEJICSeVSuHm5oa4uDhuOXRNDN4MoczGxgYVKlRQO5c7AIjFYojFYpX9VlZWxTdZYAyVoiNxydwCL6rWhMXF08U2VkIIISWPLs34xWoGx8TERLx+/Rqurq6GDqXACAQC1Hz5DADwskw5wwZDCCGE5INBk4UpU6bg8uXLCA4Oxn///Yfu3btDKBSid+/ehgyrwFknJgAAks3MDBwJIYQQoj+DNkO8e/cOvXv3RnR0NBwdHdGkSRPcvHkTjo6OhgyrwJmnJAMA0kRiZBoV3pr2hBBCSGEwaLKwd+9eQ96+yEhSU7nfk6h2gRBCdCaTyZCRkWHoMD5LQqEQxsbGBTK1QLHq4PilcujxLcTpaUgTiZFsaobMjx9h7OBg6LAIIaRYS0xMxLt371CMBu19diQSCVxdXSESiT7pOpQsFAHbfn1h/uwD0kRiJJma4XXbdqgY4G/osAghpNiSyWR49+4dJBIJHB0daeI9PTHGkJ6ejqioKAQFBcHb2zvPiZe0oWShCJhWrAjze68RY22LJDMJ5O+TDR0SIYQUaxkZGWCMwdHREWbUfJsvZmZmMDExwdu3b5Geng5TU9N8X6tYDZ38kklSUgAAyab0pieEEF1RjcKn+ZTaBN51CuQqJE/mqYraBOrgSAgh5HNDyUIRMc+qWUgykxg4EkIIIUQ/lCwUEUkqNUMQQgjRT7ly5bB69WpDh0EdHItK9sRMSZQsEELIF6158+aoVatWgXzI37lzB+bm5p8e1CeiZKGImKdSMwQhhBDFsEaZTAZj47w/govLjMbUDFFEspshqGaBEEL0xxiDPDnZID/6TArl6+uLy5cvY82aNRAIBBAIBNi+fTsEAgFOnToFHx8fiMViXLt2Da9fv0bXrl3h7OwMCwsL1KtXD+fOneNdL3czhEAgwB9//IHu3btDIpHA29sbx44dK6jHrBHVLBSR7GYI6rNACCH6YykpCKzjY5B7Vwzwh0CiW63wmjVr8OLFC1SrVg0///wzAODJkycAgOnTp2PFihUoX748bG1tERoaio4dO2LRokUQi8XYuXMnunTpgsDAQLi7u2u8x/z587Fs2TIsX74c69atQ9++ffH27VvY2dl9+ovVgGoWikj2ypNhDk4GjoQQQkhhsba2hkgkgkQigYuLC1xcXCAUKhYQ/Pnnn9GmTRt4enrCzs4ONWvWxI8//ohq1arB29sbCxYsgKenZ541Bb6+vujduze8vLywePFiJCYm4vbt24X6uqhmoYhUfx0IgVyON2XKIsbS2tDhEELIZ0VgZmawafIFBTQ/Tt26dXnbiYmJmDdvHk6ePImwsDBkZmYiJSUFISEhWq9To0YN7ndzc3NYWVkhMjKyQGLUhJKFImKbIIVtQjxirG0RY21j6HAIIeSzIhAIdG4KKK5yj2qYMmUKzp49ixUrVsDLywtmZmb47rvvkJ6ervU6JiYmvG2BQAC5XF7g8SqjZKGImJQqBdO0NABA6ieu/kUIIaT4EolEkMlkeZa7fv06fH190b17dwCKmobg4OBCji5/qM9CETLNyhZTRflfzIMQQkjxVq5cOdy6dQvBwcH4+PGjxm/93t7eOHz4MO7fv48HDx6gT58+hV5DkF+ULBQRBgbT9FQAVLNACCFfsilTpkAoFKJKlSpwdHTU2Adh1apVsLW1RaNGjdClSxe0a9cOderUKeJodUPNEEXEafJkiENiAQCpYrGBoyGEEFJYKlSogBs3bvD2+fr6qpQrV64cLly4wNs3evRo3nbuZgl1cz7ExcXlK059UM1CEbHu1Alm6Yo+C2kisV6TfBBCCCGGRMlCERJnJQspIjEyP3wwcDSEEEKIbihZKELZoyHSRGK8GzvOwNEQQgghuqFkoQhxoyHEYqQ+fWrgaAghhBDdULJQhLjRECY0GoIQQsjng5KFIpS9PkSUrb2BIyGEEEJ0R8lCESr/XjHW9k0ZzauJEUIIIcUNJQtFyDMrWXjn6IJ0Y5M8ShNCCCHFAyULRchWGg9xehqYkREiqSmCEELIZ4KShSIkAOASHQUAiLB3MGwwhBBCikzz5s0xYcIEQ4eRb5QsFCHHCRPgHPMRABBu72jgaAghhBDdULJQhGz79YOtNB4AIDW3MHA0hBBCiG4oWShCQgtzSFJTAABJpmYGjoYQQj4fjDEkyWQG+dF3LZ+kpCQMGDAAFhYWcHV1xcqVK3nH09LSMGXKFJQuXRrm5uZo0KABLl26BACQSqUwMzPDqVOneOccOXIElpaWSE5O/qTnmF+06mQRM89KFpJNJWCMQSAQGDgiQggp/pLlcnheeWSQe7/+ujrMhUKdy0+dOhWXL1/G0aNH4eTkhJkzZyIgIAC1atUCAIwZMwZPnz7F3r17UapUKRw5cgTt27fHo0eP4O3tjc6dO2P37t3o0KEDd82//voL3bp1g0QiKeiXpxNKFoqYJCWrZsHMDMjIAEQ0myMhhHwpEhMTsWXLFuzatQutWrUCAOzYsQNlypQBAISEhGDbtm0ICQlBqVKlAABTpkzB6dOnsW3bNixevBh9+/ZF//79kZycDIlEAqlUipMnT+LIkSMGe12ULBQx8xRFFVKyqRk+bvwdjuPGGjgiQggp/iRGRnj9dXWD3VtXr1+/Rnp6Oho0aMDts7OzQ8WKFQEAjx49gkwmQ4UKFXjnpaWlwd5eMaS+Y8eOMDExwbFjx/DDDz/g0KFDsLKyQuvWrQvg1eQPJQtFzFypz0L8wX2ULBBCiA4EAoFeTQHFVWJiIoRCIfz9/SHM9XosLBQd30UiEb777jvs3r0bP/zwA3bv3o1evXrB2NhwH9nUwbGISbg+C2aQp6YaOBpCCCEFydPTEyYmJrh16xa3LzY2Fi9evAAA1K5dGzKZDJGRkfDy8uL9uLi4cOf07dsXp0+fxpMnT3DhwgX07du3yF+LMqpZKGLmqYpmiCQzCSCXGzgaQgghBcnCwgJDhgzB1KlTYW9vDycnJ8yaNQtGWU0ZFSpUQN++fTFgwACsXLkStWvXRlRUFM6fP48aNWqgU6dOAICvv/4aLi4u6Nu3Lzw8PHjNGoZANQtFjOvgaGoGWWysgaMhhBBS0JYvX46mTZuiS5cuaN26NZo0aQIfHx/u+LZt2zBgwABMnjwZFStWRLdu3XDnzh24u+csMigQCNC7d288ePDA4LUKACBg+g4gLUakUimsra0RHx8PKysrQ4ejE//V69CpZlOI09NwerwvKj9/ZuiQCCGk2ElNTUVQUBA8PDxgampq6HA+W9qeoz6foVSzUMTce/cCAKSJxMg0+vw76xBCCPnyUbJQxCzNcibUSKZsmRBCyGeAkoUiZsJkEKenAVCMiCCEEEKKO0oWipiRlZXSLI4SMBoRQQghpJijZKGICQQCpfUhzJB8966BIyKEkOLrM+6DXywU1POjZMEALJKTAADx5hZgNDETIYSoyJ7dMD093cCRfN6yV6k0MTH5pOvQpEwGYCeNAwDEWNuCyWSGDYYQQoohY2NjSCQSREVFwcTEhJvUiOiGMYbk5GRERkbCxsZGZWppfVGyYAD28XEAgGhrG3z4aToq3r6l/QRCCClhBAIBXF1dERQUhLdv3xo6nM+WjY0Nbxrp/KJkwQDss2oWoq1sIJdKDRsMIYQUUyKRCN7e3tQUkU8mJiafXKOQjZIFA7CLV0zzHGttY9hACCGkmDMyMqIZHIsBagQyADtpPABFzQIhhBBS3BWbZGHJkiUQCASYMGGCoUMpdPZZNQvRWTUL1MmREEJIcVYskoU7d+7g999/R40aNQwdSpEo7e4GAIi1soZcIKBkgRBCSLFm8GQhMTERffv2xebNm2Fra2vocIpE1dkzIZDLIRMaI97CEqBJRwghhBRjBk8WRo8ejU6dOqF169Z5lk1LS4NUKuX9fI7MHBxgnZQAIKvfAiULhBBCijGDjobYu3cvAgICcOfOHZ3K+/n5Yf78+YUcVREwMoJdfBziLK0RY20LUDMEIYSQYsxgNQuhoaEYP348/vrrL52HxcyYMQPx8fHcT2hoaCFHWUgEAt7ETDT3OSGEkOLMYMmCv78/IiMjUadOHRgbG8PY2BiXL1/G2rVrYWxsDJmab9tisRhWVla8n8+RQCTijYiIWLDQwBERQgghmhksWWjVqhUePXqE+/fvcz9169ZF3759cf/+/QKbdao4EggEOetDWNki/uhRwwZECCGEaGGwPguWlpaoVq0ab5+5uTns7e1V9n+JspshYqysDRsIIYQQkgeDj4YoqbJrFqJpymdCCCHFXLFaG+LSpUuGDqHIcDUL1iVjbglCCCGfL6pZMBA7pQ6ODKAREYQQQootShYMJHsxqTSRGMmmZkgLDDRwRIQQQoh6lCwYiFl6GiQpyQCAWEtrsLQ0A0dECCGEqEfJggHZJihqF2KsrZFw7ryBoyGEEELUo2TBQMru2c01RcRY2SDpv/8MHBEhhBCiHiULBiKpXRt23FwLNhCVL2/YgAghhBANKFkwoOyahVgra8hiYw0cDSGEEKIeJQsGlDPlszWSrl0zbDCEEEKIBpQsGJAtlyzYGDQOQgghRBtKFgxIuYMjACTdvGnAaAghhBD1KFkwoJxlqhVTPof4DjJkOIQQQohalCwYkENWshBrZQ2ZEf1TEEIIKZ7oE8qArBOkMJLJIDcyQqwlLVVNCCGkeKJkwYCEjHEjIj7a0OqThBBCiidKFgzMJjEBACA1tzRwJIQQQoh6lCwYmGVSIgBAam5u4EgIIYQQ9ShZMDCrrGQhQWJh4EgIIYQQ9ShZMCChrS0sk7OTBapZIIQQUjxRsmBgVklJAIAEc0XNQkZYmCHDIYQQQlRQsmBg2TUL8VnJQsSSpYYMhxBCCFFByYIBGVlYwCZBCgCIy5pnQZ5V00AIIYQUF5QsGFApv8Wwi48DAERb2wAABCKR4QIihBBC1KBkwYDEFSrkLFOdlSzASGCweAghhBB1KFkwIKGVFdxrVgegaIbINBIi8dx5A0dFCCGE8FGyYGCeffvAJCMdABBu72jgaAghhBBVlCwYmImdLTw+vAMAvC7jbuBoCCGEEFWULBiY2MMD5d+HAACCS7kZOBpCCCFEFSULxUDpqAgAQLidg4EjIYQQQlRRslAMOMV8BABEULJACCGkGKJkoRhwio0GAETa2Rs4EkIIIUQVJQvFgGNWshBtbQsASPb3N2Q4hBBCCA8lC8WATWICACBVbIpUExHe9u1n4IgIIYSQHJQsFAOS1BRuroU4SysAQMqDB4YMiRBCCOFQslAMCADYJChqF7KTBemZfw0YESGEEJKDkoViwLxRI9gkKlafjM1afRK0RAQhhJBigpKFYsDVbzFcP0YCAO5VrGrgaAghhBA+ShaKARNnZzS7dwsA8NCrEgBAIKCqBUIIIcUDJQvFhEt0FAAg3sJSsYOSBUIIIcUEJQvFhFViIgBAam5h4EgIIYQQPkoWignrJMVoiGQzCdKNjUE9HAkhhBQXlCwUE+YpyTCSywEAUnNLpL18aeCICCGEEAVKFooJkbMzrBMUwydvVa2JxEuXDBsQIYQQkoWShWLCrGZN1H+qmLXxfgUaPkkIIaT4oGShmLD5/nvUePkcAJAokQAAWGamIUMihBBCAFCyUGwILcxhkZIEAEg0UyQLYbP+Z8iQCCGEEACULBQbpjVrwiIlGQDw2KsSQp1cEH/0qIGjIoQQQihZKDYEAgEskpO47VV9hhowGkIIISQHJQvFSHbNAgB8cHQ2YCSEEEJIDkoWihFzpWRBnJFuwEgIIYSQHJQsFCNWSYlwiI02dBiEEEIIDyULxYgAwOpVPwMAIm3twQwbDiGEEALAwMnChg0bUKNGDVhZWcHKygoNGzbEqVOnDBmSwTnGxQAA0kRiSM0tDRwNIYQQYuBkoUyZMliyZAn8/f1x9+5dtGzZEl27dsWTJ08MGZZBiTIzYRcfCyCrdoFR/QIhhBDDMmiy0KVLF3Ts2BHe3t6oUKECFi1aBAsLC9y8edOQYRmMkYVieWqnrH4LEXb2CJs+3ZAhEUIIIcWnz4JMJsPevXuRlJSEhg0bqi2TlpYGqVTK+/kSOcUokoUoW3vEHz1m4GgIIYSUdAZPFh49egQLCwuIxWKMGDECR44cQZUqVdSW9fPzg7W1Nffj5uZWxNEWjZyaBQcDR0IIIYQUg2ShYsWKuH//Pm7duoWRI0di4MCBePr0qdqyM2bMQHx8PPcTGhpaxNEWDaeYjwCASDt7A0dCCCGEFINkQSQSwcvLCz4+PvDz80PNmjWxZs0atWXFYjE3ciL750viMHIkgJyahUhbShYIIYQYnt7JwunTp3Ht2jVue/369ahVqxb69OmD2NjYTw5ILpcjLS3tk6/zObIbPAhATp+FSFtqhiCEEGJ4eicLU6dO5ToWPnr0CJMnT0bHjh0RFBSESZMm6XWtGTNm4MqVKwgODsajR48wY8YMXLp0CX379tU3rC+CQCCAbZ8+cI5VNENE29hCZmQElpFh4MgIIYSUZMb6nhAUFMR1QDx06BA6d+6MxYsXIyAgAB07dtTrWpGRkRgwYADCwsJgbW2NGjVq4MyZM2jTpo2+YX0xnKf/hOg9e2CSkYEMExN8tLZF3JEjsO3Z09ChEUIIKaH0ThZEIhGSkxULHp07dw4DBgwAANjZ2ek9lHHLli363v6LJxCJYMQYrJISEW1jC6m5JcLnzKVkgRBCiMHonSw0adIEkyZNQuPGjXH79m3s27cPAPDixQuUKVOmwAMsqcxTkhFtY4skMzNDh0IIIaSE07vPwq+//gpjY2McPHgQGzZsQOnSpQEAp06dQvv27Qs8wJLIsl07mKcqam8SzSTcfsYYpGfPIj042ECREUIIKYn0rllwd3fHiRMnVPb/8ssvBRIQASR1asM8UZEsJCklC0nXruH92HEAgMrPnxkkNkIIISWP3jULAQEBePToEbd99OhRdOvWDTNnzkR6enqBBldSsYwMmKekAMhJFjKjopBy/4EhwyKEEFJC6Z0s/Pjjj3jx4gUA4M2bN/jhhx8gkUhw4MABTJs2rcADLInM6tSBRYqiZiHc3hEAEOHnh8SLFw0ZFiGEkBJK72ThxYsXqFWrFgDgwIED+Prrr7F7925s374dhw4dKuj4SiRJnTqQpCpqFg607gQGQPrPKaRqmAabEEIIKUx6JwuMMcjlcgCKoZPZcyu4ubnh48ePBRtdCVbx7Rvud+V+C4QQQkhR0ztZqFu3LhYuXIg///wTly9fRqdOnQAoJmtydnYu8ABLqlZ3/4NJhqIPSIyVtYGjIYQQUpLpnSysXr0aAQEBGDNmDGbNmgUvLy8AwMGDB9GoUaMCD7Aky15QKs7yy1owixBCyOdF76GTNWrU4I2GyLZ8+XIIhcICCYoo2Erj8d7JFbGWVLNACCHEcPROFrL5+/vj2TPFWP8qVaqgTp06BRYUUbCPjwMAhDqXMmwghBBCSjS9myEiIyPRokUL1KtXD+PGjcO4ceNQt25dtGrVClFRUYURY4lV76liXoWLPg0NHAkhhJCSTO9kYezYsUhMTMSTJ08QExODmJgYPH78GFKpFOPGjSuMGEusRo8CAABvyrjzpn0mhBBCipLeycLp06fx22+/oXLlyty+KlWqYP369Th16lSBBleSicqXh22CFKUiwwEAN6vVMmxAhBBCSiy9kwW5XA4TExOV/SYmJtz8C+TTldu7B4BiCCUAXKndwJDhEEIIKcH0ThZatmyJ8ePH48OHD9y+9+/fY+LEiWjVqlWBBleSCa0UwyU9370FQMMnCSGEGE6+lqiWSqUoV64cPD094enpCQ8PD0ilUqxbt64wYizRLJOTAABSiYWBIyGEEFJS6T100s3NDQEBATh37hyeP38OAKhcuTJat25d4MERwDJJkSwkSswNHAkhhJCSKl/zLAgEArRp0wZt2rQp6HhILpbJiQAAqbk5GACBYcMhhBBSAumULKxdu1bnC9LwyYJllaRIFjJMREgzEcE0a70IeWoqjExNDRkaIYSQEkKnZOGXX37R6WICgYCShQJmlpYKk4wMZJiY4KONHcpEKYZSRiz2g+vP8w0cHSGEkJJAp2QhKCiosOMgGggAVA56hYcVKuNWtZooc1GRLCRevWrYwAghhJQYeo+GIEXHddFCAMDX928BAA636MAdywwLM0hMhBBCSh5KFooxmx49UOnZU7S8ewMA8MHRGenGORNiMZnMUKERQggpQShZKOYEAgFsEqQwycgAAHRetSVnnQhKFgghhBQBShY+AwIAdtI4AECGiQku+nwFAGCGC4kQQkgJQsnCZ8IiayZHADDJzAQApAcF493YcUh59NhQYRFCCCkBdE4Wli1bhpSUFG77+vXrSEtL47YTEhIwatSogo2OcIRKi3QZyxTJQujIEUg4exbB339vqLAIIYSUADonCzNmzEBCQgK33aFDB7x//57bTk5Oxu+//16w0RFOxbdvuN9TxIrJmDI/0IgIQgghhU/nZIExpnWbFK4hx/Zxv2cnC4QQQkhRoD4Ln4Gyf+2CdVIiulw5BwBIMTUzcESEEEJKEkoWPgMSHx/Ff9MUfUaS1dQsyFNTizQmQgghJYdeq07+8ccfsLCwAABkZmZi+/btcHBwAABefwZSOMyyEgJ1zRBR69bBeepUlf3Jd+6AyRnMG9Qv9PgIIYR8mXROFtzd3bF582Zu28XFBX/++adKGVJ4zFMVNQtxllYqx5Jv31HZJ09Lw9v+AwAAFf3vwsjcvHADJIQQ8kXSOVkIDg4uxDCILioGvwYAPPCuDLlAAKM8OpkypaYJWVISJQuEEELyhfosfEYqB7+GKD0dUgtLhDk45X0CjVghhBBSAHROFm7cuIETJ07w9u3cuRMeHh5wcnLC8OHDeZM0kYJnLJehbPg7AEBQKbc8yysPbxUIBIUWFyGEkC+bzsnCzz//jCdPnnDbjx49wpAhQ9C6dWtMnz4dx48fh5+fX6EESXJ4fFAkC7NHTMb4iXN4q1ASQgghhUHnZOH+/fto1aoVt7137140aNAAmzdvxqRJk7B27Vrs37+/UIIkORo99Od+f1ihMi7VaWDAaAghhJQEOicLsbGxcHZ25rYvX76MDh06cNv16tVDaGhowUZHVNQOfMLbPthK8W+Q9uKF9hOpGYIQQkg+6ZwsODs7IygoCACQnp6OgIAAfPXVV9zxhIQEmJhQlXhhMa1SBQBgqbT6JAC8dC+PNBMTMHX9RZQ7OFKyQAghJJ90ThY6duyI6dOn4+rVq5gxYwYkEgmaNm3KHX/48CE8PT0LJUgCuG1SLNIlAGCSkc47lmhGQyIJIYQUHp2ThQULFsDY2BjNmjXD5s2bsXnzZohEIu741q1b0bZt20IJkgDGWTNlAoB9fBzvWJKZBACQcOEiQseMQejIUbTQFyGEkAKj86RMDg4OuHLlCuLj42FhYQGhUMg7fuDAAW4qaFK4Gj/0x6GWOf1FEiWKZOHdqFHcvtSnT2Hi4pJzEjVDEEIIySe91oYAAGtra7X77ezsPjkYopshR/ch1USEk00Vo1PUNkPI5UUcFSGEkC+VzsnC4MGDdSq3devWfAdDdGOWnoYpu//AO2dXPKhQBYlmOixZTTULhBBC8knnZGH79u0oW7YsateuTe3hBmLRsiUSL1zgts1TkgEApxq1QEv/myrlM6Oiiiw2QgghXy6dk4WRI0diz549CAoKwqBBg9CvXz9qeihiFi2a85IFm0QpAMC/UjWVhaUiV65C8k3VBIIQQgjRl86jIdavX4+wsDBMmzYNx48fh5ubG3r27IkzZ85QTUNRkfOf89Cj+wAAzMgIwa5leMcoUSCEEFJQ9Fp1UiwWo3fv3jh79iyePn2KqlWrYtSoUShXrhwSExMLK0aSxbRKZd62bYIUNV88BQD80lu3PiWEEEKIvvK9RLWRkREEAgEYY5DJZAUZE9HArHp1uG3eBOfZ/+P2Ocd8BAA89qqE16XdDRUaIYSQL5heyUJaWhr27NmDNm3aoEKFCnj06BF+/fVXhISE5GuOBT8/P9SrVw+WlpZwcnJCt27dEBgYqPd1ShKLpk1h17cvyu3bCwAwlmVyx043bKbxvORbtwo9NkIIIV8mnZOFUaNGwdXVFUuWLEHnzp0RGhqKAwcOoGPHjjAyyl8FxeXLlzF69GjcvHkTZ8+eRUZGBtq2bYukpKS8Ty7psp55n9NHuV0HW3WEf6Vqaou/nzARmbGxiN2zB7L4+CIJkRBCyJdBwHTsnWhkZAR3d3fUrl0bAi1j9g8fPpzvYKKiouDk5ITLly/j66+/zrO8VCqFtbU14uPjYWVlle/7fo7SQ0Pxuo1ieu1rNXwwe+QUAMA3V85i4h71c12Y1amDlIAAmDdtCvfNm4osVkIIIcWPPp+hOg+dHDBggNYkoSDEZ33j1TQkMy0tDWlKqytKpdJCjac4E7m5cb83eeiPeZt+wbzhE/HEw1vjOSkBAQCApKtXCz0+QgghXw69JmUqTHK5HBMmTEDjxo1RrZr6qnQ/Pz/Mnz+/UOP4XHl8CAUAfHB0BoNidcqCJk9KQtD3PWHepDFcZs4shDsQQggpjvI9GqKgjR49Go8fP8bevXs1lpkxYwbi4+O5n9DQ0CKMsHhziVaMikgxNYPUPO/OprLEJGRERIBlZICpWUcifOEivOnaDfLUVG5f3NGjSH/zBrE7/9Q7vozISMQfPwGWkaH3uYSUFNLTp5Ea+MLQYRCiQu+FpArDmDFjcOLECVy5cgVlypTRWE4sFkMsFhdhZMVbhTu38aJefQCAKDMD9nGxiLaxRWBZT9R/+kDruS/q1uV+F3t7wePvvyFQWkk0dtcuAEDIQF9u5AVk+V+cKqhbd8hiYpDx/h0cRozI93UI+VIl3byF9xMmAgAqP39m4GgI4TNozQJjDGPGjMGRI0dw4cIFeHh4GDKcz47Q0hLlT57gtqu/eg4AWDh4DFL0SKrSXr5CelCQ2mMpD5SSjk/osyKLiQEAJF68lO9rEPIlS6UEgRRjBk0WRo8ejV27dmH37t2wtLREeHg4wsPDkZKSYsiwPltjDuwEACSYW+BVmXJ6nRu7ew9ed+6MjPDwQogsBy/5IIQQ8lkwaLKwYcMGxMfHo3nz5nB1deV+9u3bZ8iwPitG5ubc7/bSODR4dA8AsKNTD72uE7t7N9JfvUZQj+8KND5CCCGfP4M3Q6j78fX1NWRYnxUTFxc4z5zBbVd/rZgB079ydZxo3BL+laohytpW5+vJoqPBaPpuQgghSorNaAiSf3YDBnC//3D2OBo+9AcArOw3DFPGz8LkCbOgz7qgcppBkxBCiBJKFr4wQrkcM7f/xtsX6lJaZQlrbV61as3bTnn0CCGDhyBNad2OzOhohC9chJhdfyE9OFjr9Vh6On+bljQnhJDPSrEYOkkKlkVKMrxCg/HKrRy3b8j/luLYlGGwSEnO83x5QgJvO/j7niplwmbPQeKFCwCACGgf6iVP58+tEP7zz3CdOzfPOAghhBQPVLPwhbBs04a3PXvLWrS+dQ31nihGHzAjI2z5RvVDP79yD/PSVluQKpfjvaMztx23Zy+SbtzQev2IJUvxrFJlpL6gCWoIIcTQKFn4QrjMmc3bdo8Iw6zt67H01yXcvr+bt8NHPTo7aiOP56/L8bxyFaQ8eaK2bLdn79Dv59W4712Z2xcyaLDW68dkTS8e9E3XTwuUEELIJ6Nk4Qth7OiotilAAOB/W9Zx2xu/7QMAiLG0RqaRUKW8rtR1ggzu8R0yIiJU9j9KViz+dbZBk3zfjxBCiOFQsvCFKbdfdY6KBk/uc7+fr98ELTbsQY9lGzF3+IQCv39Qt+4AgLhDhxHU4zukPHzIHTNSswYFIUShsFf1JeRTULLwhTGrUUNln0VKMqbs2qSy/7+adXGhbkNe88CnksXGIuavvxA2axZSnzxBcM9e3DGjEj4KgmVmImL5ciTSEuFEDRolRIozSha+QN5Xr6js63T9Isq/C1HZv2DIOEycNEeveRjyErFgodr9Jb1mIe7QYcRs2YrQYcMNHQohhOiFkoUvkNDBAaLy5VX2z9/0CyoFv8LAEwdhlcgfHplkJuFtZwiFahOINBMT/Fu/CeIsLPWOS6Dlm1N6aCiit2z9oieEyvjwwdAhEEJIvtA8C18ggUCA8ieO43mVqrz9ZaLCsWGpYtTEjep1IFX6wP9h4VqUC3uHQScO4lk5Txxo1Ql1nz3C7K2KzpFrevki3sISttJ4HG7ZAZWCX3HX0kY5PRBqqVl407UbWHIy0kND4DpvHu9Y7J49sO3dm9tODXwBk9KlILSwUNwjIwOxu3fDomVLiNzc8owpL8n37kFobQNxeVoF9XMmi4/Hh5mzYN31G1i1bWvocPJEfRZIcUbJwhdKYKS90shOGsfbTpKY44lnRUwZP4vbd6FeIzR66I+m92/j7+bteOWfl/PSKY4M45y32MFWHfHd+X/gHBsNAJBJpTCytETM1m1gyYrJopJv3Va5Rvj8nyFPSUXCuXOw/uYbhM+bByMrK3gcPgxRmdJ4Xl3RTyPCb4nWyaF0kf7uPd72VowYye+1YnbsgDw9HQ7DhmksEzZvnkpSRApW1LpfkXj+PBLPn4cVLf9MyCehZogSauz+HfAOeQOL5ESt5RYOGYsjuRIFfaSJxLztyRNykpEX9RvgRYOvELl8ObcvPShIbVNE5LJlSAkIQHjWB6xcKsXr1q2R+vRpvmNTJz0oSGVf0o0beNG4icZ5JJTJU1MR4bcEUStXITMmRmO5uL2fz8qqidevI+jbHgX+rAtbZvRHQ4dAyBeDkoUSqtTHSGzym4VDP43CzK2/ovvF0xrLbuzRL9/3STMR8bbfO7nytuVS/uROABC5cpXO1w/6Vr+luLOlBgYi6tf1kCfnmv5aTVVwyKDBkEVHI7jHd5D+84/W67LMnBU7WVpavmIrbkKHDEXq06cI/XFEvq8Rd+gwPv6uGJGTGRsLQDE6JPv3wiD7GF1o1yakpKFmiBJOlJmBNneuo82d6+h95hh6Lvkt75P0kCYSqeyLtrKBfa5mEGWxu3cX2P1Tnz1D0o2bsBvQHwJjY0jPnkXSteuI26f4Zv/x999R+dFDpL15A5PSpYE8hq+9nzQZZrVqwaRUKbXHWTo/QWAyGd5PmADTqtUK5gUZkCw+Pt/nhs1S1ChlhIchbs9eOE2dgvjjJ5D2/Dk8T5+CqFy5fF2XyeVgaWkwMjNTOZZ8506+4yWE8FHNwhfMbfNmvco7xsdio99MOEdHFVgMuWsWAODfBk0L7Pq5ZXz4AHlqKlKfPkXynTsI6v4tIpctQ9jcuQhfvBjvx47jEgXFCRmI3rIFbzp2QnDv3ghV6meQ9vq12nto+jbMMjLwslFjpR0MiZcuIeHsOUStXq1a/jMbV5979dD8iNuzFwAQuXwF0p4/BwC8bt8h39d727sPAmvX0drkQwj5dJQsfMEsmuZMr2xaU3WyJnUqhgRh7//GoceFU3mWHT9xDh6Vr4B9rTshzcQEoU4uvNEPyWJTLBo0RuW8+xWr6BRLfrxq2QqBtWoj6NseeNt/ALc//tBhxO78U+05kctXAADSnvI7wb3p1FlteeVe64wxyFNTkfYmCM9r11EpK/1H83NMvHhR8wvJkvbmDV62aInYffvzLKuOLDERLCMj74JZMj9+BMsatcIYA5PJ8jiDT56UhNj9+5H5Ub/+Avltjkh5oFgoTZdnSQjJP0oWSgjnqVP1Kj/42H70+vc4mt5THZ2Q7WGFyhg3dT429uiH9mt3YsD8X3CoRXukZ42A+L17H7wp465y3u2qtZBkqlpt/Dl6P2EiAmvVxocZ04HMTJXj0n//1Xjuu1GjkXT7Nj5u2qyxliF8zlxkhoUhfO7cPD/0WWYmkm7e4vphZMbG4kXdenjVrh0iV69G8r17Ws9PvHoVL5s0xYcpUwAAb/v1x5vOXbSeoyz5zh0E+tRF+Jy5eNmkKRKvXdf53JcNG+lc9nMlL4CamaL2KbVfrARNwhZ36BASLlwwdBiFipKFEkJgZgaPo39DUr8+t0/o4IDyp9R32JOkpWLEkd2YseM31HvyABN3b0GjB3fzvM/6ngPRbt2f2Ne6Ey75fKWx3LxhE/R+DYbwsllz1Z1ZNQtpr14h4cwZAEDqg4cqxaK3bQfy+IAPGTAQUatW4VWLlirHEi9fRorSCIQYDTUj2T5u2oQQX1+EjhwFAEi+eRMAkPkhDNEbf8fb3n2Q/vYt75xMOcOop2+x5V0UorM6IGbXhqT4+6uMDoneuk3j/ZVrcgAgdOhQrfF+qvTg4E++RlE1BcXs3InAGjWR8BnVgDCZDME9eyF01GjVY4whfNFije/JtKAgvGjwFT5u2FDYYRpcekgIwmb9D+/UPKcvCSULJYhpxYoou3MHt23x9dcQe2ifeMgsLQ3Lfl2Cb66ew+S//sCsreu0ls+2sUc/GMtUv2lnu1tFe7NIhlAIeTGYpCZTzSqaQd2/BYA8v3XH/qn9w513n/Bw3nZqYCBCfxzBzT8BKCan0iYuq6ki+VZW7YKaVUU/bvydt33qYzwOR8Ri1sv3vP2aPkQjly1DZmysTsNIC9vHDRtzNhhDzI4deNW6DTLev9d8kpLo7dvxvHIVSM9orv2Rp6fj3dixeT77vEQs9gMAfPhpul7nMTW1VUUlLTAQqY8eIVHNN+aUgADE/vknIhYvVtuXJXL5CsgTEhC1Zm1RhGpQmdHqR91ErlyFyBUrdDpfnpqq9pg8NRVxhw4hIyLyk2IsCJQslBCi0qVVd+r5rcouIR6t7/yHaq+e61Q+xtqWt13jBb9PQKqazo+AIlHwnbsSI6YvLNA1KwrSh59+0v8kHZ+3PDWVa4tXlvHuXR4n5lT7BtbxQdK1a1qLp799i0ilSbCS7+ZdcwQALxs3QXCP79TGWJgYY4jZ9ZfGOCP8liDj3TtE6PAHGgAilywFALwfP15jmfjDh5Fw9hzC5/+s9rg8PR0Rfn5I+u8/lf1h8+cj4dIlnWJRG9/KVXherTqeVaqMZ9Vr5LsW5OPG3/F+6jSuWSDtzRtE/boeskTtc6wwueb7KY+MSQ9RXXOmMCXdvImI5ct17nDLGIMsLq5wg8pFlpCA6M2bEf3HFq39cTIiI/GycRO8at5C7fGo1WsQNut/CP7++8IKVWeULHzhPM+dQ/mTJyC0sdFYxrzZ13pdc/6m1Ri7bzt6/XscAND87g38PUX74kh/LPwJy9f58fYNnLeS69+gLMLOER8cnfHSvTzelHZHjJU1Lvh8pXfiIBcIcLVmXUTlSloKQvzRY3qfE37+Ana174oQZ/XDLuOO/I2gHt8hsFZthM+Zq/E6KY8e8/ofyNPSkP7uncqHSdyBA1rjed2uPRI1ldH2wZT1oZN044bW638Kde3dSVeuIGLhQrzt1z+7VE55pfktkKlfp0xtZAkJWo/H/rkLMTt2ImTwEP7+v3Yjbs9evBsxkn+CQIDMqCiEL16scbQNAMji4hCtPJopIwOpD1WbujTFHNynL2L+3AUAiFq9GtLjx5F8R5FkvenYCR9//RURfn7aLlNg4g4eLNDrhfgOQsyWrYjdu1en8u/GjsWLrxoitggnQuPVCGnpJJx8WzG8V1Myk5iVbGZGGr5mgeZZ+MKJyqjWKFh17ADpP6dg5zsQAGBsZ6/XNe0S4vHtpTPINBKi2utA1Hv2EGItbfO/LpsDz/eKbx8Td2/BL30Uf1gj7RzwR9cfYJWUiCPN22Ltinko/TESiZKcRa0OtuyAu5Wr46OtPXZ16I4tC3+Cro0TZ+s3wRJfRft9p6vnMfj4AdglqJ8r4J2jC6ySEmCVrHkhq2CX0ghzcELDx9o7Cu5v1RFlIsPR6FEAb/+m2g1xsFVHbOv8Pc6PUZ3oKmzGjLxeElhGBvcto8Kd2zAyM0NQt+5qZ57UeA3GkPbiBQDAiOV8KMuMjHLW79BzFERqYKBe5TWRJSTg7YCBSA8ORvm/j0BUtix3LPekUPHHT3C/p9zjP+uikv4uVO3+zPAwjed8+Gk6kv77D3F79qLSI/UJQNjsOSr75EqTfH343//A0tJhP2woTEqVhtDCnDsWs30HUgICkBIQALv+Oe8zlsav6s6zZkjHmoy8vrWH/W82bL77Tqdr6SM9RP2zzy3x3HkAQPi8ebD9oVeBx1FSUM1CCVRq5UpU9L8L04oVP+k6xnIZmjz05xKFHfMmw/f4AVgn5MzKWCnoFaoGveS2v7l6Dscm53R8O9C6E7Z07YUYa1v0W7AGUok5pBIL7vjpRs3x0VaRzASVdsetqrWQIRQiWWwKQFF7MGf4RCzyHY3TX32NaCsb7tyb1Wpzv59s2gor+g3DBwcnXhkA+ODghP4//4I+C9YAgMYajEFzV2Dm6Gl4VaashhLAo/IVsOG7/pg1SnX0yQPvSoqYhap9CXSlPCJCFhuL1+076JUoAED830cR1LUbAEAoy0kWlOfECOqR9x/3mG3buaGV2df7VC/q1Ufas2dgKSm89t60N29UCyvVPrAM3dv2WXq6zj31pSdO6nxd3j00VOHL4+O5Jovco1uUt5P9/dVcVPEfWWIS4g8egvT4cQR90xVvOnXi3yMlhfs9dxV4hlLfmLwWrkrV1i9FKZEIX7hI63UARXV79LbtnzSx15eOZWYW67lXKFkogQQCAYzMc76J2A3or6W07twjPmDgP4exf+ZonJwwCHM2r8G8zatVylkmJ2HXbPXtxF1X/qF1FMXzcp4YMX0Ruq7YjH8aNseskVNwtXZ9nGvQBEsHjsSSgYpvn3KBAJfqNuSde6OGD/ouWIPvlvJ7aN+roJj3IUlijpONW6D7st/xvCx/ie8MpQ/4ty5q+n9kCXdw0nhMUAB/B5S/caa9eo0AsTmWDBih85Lh8UeO8GowBEqpUarSOh7ZNQ/ayOLjEf/3UYT/rL49X1+qQ0NzPsyyq2uzpb18yd9+9UrrtbNHIcgSExFYvwFCBgzUKaY0pRqTzNhYJJw7x/swZqk53/azPwjfT5rM69yqyxBS6ekziFyxMmeHmmQm9q+/kBERgdg/d/L25+6EKzDKeW65h6QqN32kBfNHxuQWrmahs8zoaJUPNHXvlZQAfk1PyKDBiFy6FB+mq689S3vzBuELF+nVkS921y7V6dpz+ZQP3+SAAK6zrDwtjVezo/kc7bWO2rxs3AQfJk/O9/mFjZIFAtPKlbnfXeaqVn/qS5SZCUlaKloE3ORWmMyt1EfNfxRONVbf2QcAjjRvhzdlyiLT2BjLB/yIm9X5EyHdrVITyWJTjJusuc0fAFb0GYrl/Yap1CKs6Dcc8ZZWWDyIPwwqyjanqcZIy7fSDGFOy17u0RzKVf6Jpmb5Gu0hPZnzTTd8/nyMmzIPZxo2w7qeun345ZaplASpm5o7L2GzZiF2t+aRAvr88c/48IG3nfLkMVhGBuKPH1f54MqM4X9jVv7AYnI5pKf5a528GzkKyQH3kHTtGlhqqs6dOZW9bNgI78aMRdj/cpZmjz9yhPv9RYOvkPr8ucr6IdqGkEau+gWBdXzwfsIE3n51H3IJ//6LV82aax1hkBkdjSQ1K7dmXZRfm5CVnKUFBSE1MO/kMO7gQbxs3ARRq3Kt3ZIrVnlSkkrTRHpWkpJ48SKC+/Xj1XAAignQYnftwqtmzfKMQ1nY3Hlq92dERCI9OBiRS5fpdb1sqc+f422fvnjVqjVYZiZe1KuPFw2+ynOSMlmMnuuRKD07WXw8bxI3eUoKMopBX4VslCwQAIDnubNw37kDtr17Q9KgQaHfTwCg3Y3Lep8n1eEbdKfV2/DEU3sTy8mmrfBP45b44OgMmZohhqHOpXC5dn2kiMWQGRnheg0f7liCxFylfLZMpQ6b6cYm/INKf1O7/LIVPw8Zl8cr0U75G6W22g6t11BKblJzrRBaEF41a6Z1bgZlr9u1521nfgjD8zo++DB1mkrZkIGak6PE8+fxfsJElf2pT5+q/cauTlpQEFI0dCiUnjypmN1STT+dmF27dLp+tuhNm9R/O9azz0i2V23aIvXRI53LJ9+5gzcdOiKoa1ekvQnSOvFX+KLFAIDozX/wEwSl32P37MGbLt9ovWfKXX9ELMrVdKFDDYC6YaTS48fVln3VrBlet++AmO3beftjdvJrZeIOHcab7t8iI4zfx0T53z712XNF01VqKuR5jCBRtxCdJnGHDuODhsnyGGMIrF2HN3Ra31lRCxolCwQAICpTBubZEzYZ6fGN1yj/b6HpOzdi88Kf0Mz/JvbMGosLI3ujwaOcarzy73KGZPke196zP792te+GRA0f/vOGT8TqHwbjtx798Nv3ORMOJZhbqC0PAOkmOQlCqpj/4SvIVY9xWUtzi7J3ji4Is3fUWkaez3+HDKXkJj81C7nd966MNb18kaKUeEQuy9+3OwB5Tmqlj4TTp8FkuiULbzp0RHBPzZ3hQocOw4vGTVT2J549l+/4ePI5+yHLo1o+N+WJtN507Ijn1WtAFheHDzNmql5bqfklNdfU6NnC5/+sUkOkjkyaM8okr5VcAcUH5Yv6DTQ2Y+gqe76LbGGzZiHt2TNE+C1RxBUfj4ily7h1SwDwJjJT25dEmZpk4f2UqXhWqTLijx5Vubc6ssREfJimOjQ7Imuor6HQaAiilePEiTBv+BViduzkVYFns2zVCglnz+b7+l7vQzDvjzXc9qKNK/BL7yGQmptj/N7tmDlqKtJMROj97zGEOTjhTMNmaPjQHzeUvukDQDP/m7hau77eH5qnGzXXevzfr1SHlSYo9fdIMjVDvIUl16yiPI214pt6zh9FIy3j1tW5XbkGnnhWwM5OimW4988YDcc49Qsm5TdZKOiahYmTFM1YktQUDDtadEPVdJF89y4y1EyyBSiGo5pV131l0KTr6vshFFQHvrza4nOL3rIV9kMGay0Tu28/LFupzhSa2+uOnSDLtTBX7vb6j7/xV6dNDrgHExdnHaMF70P1/STN7fSMMcRs2YLEK1chT05G/N9/53np9HfaJ+ViMhkEuToZy1MViVDEkqW8piUA3PTnAPDxtw2wbKnlGQoESA18gahffuF2Zc+k+uGn6bDu2jXP+F/Urad2v95NHAWMkgWiQlSmDLL/VDn8qJg/ofTKFciMjFRZ9td14QJkREaone44P4RyOab8lTO+fOOSWWACAYwYw9j9O1D32UM0C7iFCZPm4Gn5Clw5l5iofH9g6uu+dxUwKJpSFg0ajVtVa2HSni0IdXJFktJSybm/qQuY7t8W5QIBfhrH/xYV4uyqOVlQ841GJhDglVs5eL4LgbFcfbV2hlJTSbqGSbIu166PnR174NtLp9Hpum7TFQeXclPZl25sgkeeFVDj1XOY5LOa/VNlhKofbhe7Zw+MzIfCSCxSLFX+mYlcvjzPZCHxwgW1szHmljtRAIDAmrW0nvO2T588r5sfiRcv8Tt+aiD95x8kXLoE1wUL8Lp1a61lE86eg1X7dvydWf//pD7XPuGcLEGK1KdPYVqlChKvXYfQ2op3PCMsDO+ypltX563vIJTdvg2ZUfqv7Jv03w2w3P1OihA1QxAVTlOmwLprV7hv57c1l1m3FiZubrDqnLMao9DaGg65xr8XJAEAo6z2TPPUFLS+8x9MZDJM+WszzJXmRKgd+ERtU0Wvs+rbND9FYDlPPCnvjdk/TsKNGj6QC4VY0W849rXtghNNc/5QpYrEeF3aHZu7/oC3LqXUJjMZGoZRJplJVPZlN5ccbNkBx5ry/yCqu/bu9t0wYsZirOuluX1fuRlCas5vjrlWsy7eOzpjeb/heFPGHb9+NyD36Ropd5yMs7BEoqkZVvYdiikT/odN3QvngyU3BkVHUl3EHz6MNx074lWr1nl+YBRXSTdvGToEnSXfvIlnlSrj3TjVUVGRSsu5Z2iYxyK395MmQ3rsuNbOtty9796F9PQZ3j4BBEgOCEDaM/XNK1w8b0MQ9G0PxB06jNChQxH8fU9E/7GFOx7x8wLt9755E5GrV+NlU/0mwsumS5NNYaGaBaJCaG2NUkuXqO63sYHXWcU8+pJ69bisWmCsfd4Ax8mTIPsYjZgdO7SW04fHh3c4NH0krtfwQZStPeo/eYDagU9QISQIoswMBFSshrrPHqLGq+e4W6k6XruV451fNuwd3rqWAQBYJSZgzP4dWDxYdTltTcZOzXu44IgZi7nf97fuxOv8mO1Sna/Q8u5/ONSyI25XrQlJajIm7NmGFFNTlbKJEnPEWlphfVb/iXY3czqIMgE/WWAAtn7TEwBw7Os2mLhnKwDgbqXqeFLeG73/PQ6TzAy8KZ2zKmiUTc6IjzMNmmKJ7yg4xEYjKStJSVUTkybZo0KSxabovnwTjORyLqE52KojRh/8E/tbdcKJpi2xYs0iOMWqrzHJLdrKBnbSOMizak283r3NmUgql63f9MRf7bpi+drF8AnUfS2LEN9BOpeVCwSIs7DSONnXp0gyNYNpWiou1GuMMhFhqPxW84yPABDi61vgMWiTLDaFJE39mga6SlCzKmv0xt/hNGECUh4/gSxequYszdTViuQWu2sXYnftAlbl1FgkXr6MxMu6d7hW7siaeP68XjFG51qfRR+5hwwXJUoWSL7Y9urJ/W7esCHMateGaeVKXGZvO6A/XGbyO0mxjAzE7t5dYDGIMzLQ0v8mty3KzORmV/R5/pjbv8lvJtKNTfBXh26o9joQsZbWqPj2DQbPWQ4AODpV0dSiT7KgL3WJQvY9f/u+P+Isrbl9V2s3wLK1i1XKJkjMkWSaU+MQozS5VKZQiIWDRqNs+Af0P3UE/2joi7Gi3zBE2Dvio40tKr4NwoV6OePwo2ztuN//btYWALgJsbKlG5tgd7tvEOxaBrO3rIVQqRf7v/VzOvzJhELcrFoL0qzOoMo1H8KsBcY2fKeYXfBIs3b48e+8vxGebNwCK/oNx+Bj+5EsNsXedt/g+3MnMeqQ+hEIuzp0BwDs7NRDr2RBn3UElvcbjtONmmPtinmo/rpgZrEEgBdu5TB2ynyU+hjBNelcHNk7z/MC3cvDv1I19Dx3UmPTU0E40qwN1v4wGD/t2ID2N6+oHH/oVRGrfxiMcfu2o9ZL7d/W1QmsVx9yDVNtn6vXCLbSeO7fND/DYAHtfSXyYqimAEMulkPJAvlkAhMTlNujSAKS79xB2stXsFZqqsjmMmc2bPv1w5uOHYs0PiPGYJqRjiHH9vP2r1i9ELZKs01+c/ksjjVrg7XL58IuIR7Py3riQKuOsE5KwO2qtQAAbW5ewVk1nR4/hXKikO1kYzVLVptJeM0TYUoTQEXaOeB81of1D/8ew4kmrVTOlwsEiMgaVfHAu7LKPT7a2EEqMUeYgxOvE6eyAfNWctd44lkBB2Yo5qNINzaGn9LcFA+9K+Ohd2W11xCnp/NGS5inpqgtJ5WY86bfXtFPkdRl15gAihlA00QijNu3nVfDkKk0HNZRw1wfn0ouEHAdZP9q3xVL1n/CqI+s62U3uS3v/yPSRSK1fT+Uy6eITXG8aSuUiQxHkwd3MWKGYkiibUI8OuRjaHJeZAIBdrfvxv0bLB04Um2yMGHiHDAjI0ycNEenJCc3TYlCqJMLFg0eCyAnecpZKwT89TQKUarS0vHqxFhaQ5yRrvG9/TmiPgukQJU7dAhe58/BrIb6JajF5T3geeY0KtzRMHFMEfIJfILyH3LaRCfu3YqLI3uj+psXKB0VgVZ3/8PGpf/Dgo2r4B0ShK8DbmHGjg3YP2M0nKP176AEAJN36fbHTN2wygSJBYJdczrfTRmnOrwNAK7UboBYK9UEJFYpKQl1KQ2Wq5/Draq1MGbqfIyYsRjvnVzVXjtCaQjnRxs7tNiwB/4VqyLO0kpteXXEGRk43TAn4TJVU5V9pFlbdF35B07rkJgd+7oN/m3QlLdP+fVbJ/I/eDLVzKuRHwdbduB+N8u1xHCKSIwdnXrgtVIzTza5QIBwOwfuSyIDcL2GD7qs/AOXa9fnyuRl5qip6PzLVvz+bV/MHjGZ96Uzws5B35ejk3P1m/CSNU2U31sygQBzhk/Ats6fvj5EpFJNV3GdGDlBYo4eyzbimxWbwYACXcgu+vf8N2F8KkoWSIEyEuXdm1xUtiyElrpNT1wciDIzsMlvJuZvXg0BAMe4GOz93zgs+XUJVv2yAH/OmYjNC39C9TyW7q7+6jkaKC1C5ajnUKj3Ti7cwlgAVD7ssy0cMlZl7ojrNXyw5gdfrddPF4kQmo/JnaZM+B/uVaiqc3njzEw89cgZyZJ7PgoAWPuDot/A0oEjVY6pE2Vjx9tOVKqBUZ6C+3iTlmi7bidONG6JQHcPbj8DcKxpawS686f51mbDdznfaLO/QcoEAgS6l8fu9l2xvfN3GPo/1bHxm7r3Ru9F63C9Zl1IJeboufhX/G/kFCSbSTBv+ERcqtMAAjWTFOVOIG4prX0CAB+VPpTspIWzBkOIi/oVU7W5X7EqrtZuwA0B/iRKzyAj96RnWZLFptjXuhOeeHh/+v3yITtBlAuF2NemM3ou+Q3Hm+Q9ZLW4o2YI8kVxGDUSH3/bkHfBAtDgCX/VPr/1y/B3s7Zo7n8DIS6lcbFuQzjHfIRXaDDCHJzww1nFKokb/WZBkpoM2wQplvX/EVezvk2WiQjDO2f13+gBwL9ydZ1jyz2a4n8jp2goWTCUk5i8RNnZ41yDnP4NyvM73K1UHZI0/atumUCAF1mdWM1TU3jJwn81fPDO0QWlo8Kxqu8wAMDKfor/bps/BeXC3+Nmtdrcaqi6Vpt7hQbjVdY9TzZpidJR4RpHetytVB0R9g6wTpBiX5suAIA/O3RHGzsHlX4h84dNQKko1fkgkk3NEG7nAM/3IWpXXn3v5ML9LtMyjDioVBn80nsIfE8cRB09+nIAUJvEKJMJBPjgyJ9vQfnfl7eyKYAIW3tYJybANCNdp/szpVeeKhJBlKk6aZef7yhcq1UP5d+FYMsi1cmNChtTSmh+/7YvAGBV32Hoci3vYavFGSULxGAcRo3iJncReXmi3N59MJKY4XkV7d9SPY7+rXGVQ0OOkTdPTUHfM4pZ2kp/jNS4lHXFkJwVFAecPITrNXzQ9tZVlA1/z/1xsUpMQKZQiAohQbhfUfdv7fnhHB3Fa14oapFZVfJvSrtj6nj1TSt52d7le2zv8j23PW/TL7zjJxu3QLN7qkMLB81dgXmbfsGR5jnj7rPn0MiLfVwslywA0JgoxJtbqH1dMdY2vA8WZeoWBlsyYASu16qHqTt/R+s711SOK69fom6Crew+EfOHjMfbUmUwecL/NCZG8eaWuFG9NprduwWzPBZQSjc2hihrKuZVfYfiHzX9bbIlmklgnaSYMvm9gxP6LVgDt/D32Dlft2SWP+OoGFCzpHx2jcKbMqpNQBqvKxRi3OR58PgQimm7Nul8njp5NSHJjIyQbmKS53MtbihZIAbjMHYMrL/pAmNXVwiMjblZ1Zx++gkfN26E+VdfIeHMGZXzjHJ1vrPu8S2kp07DskULWHfrhvAFC8FSP21IV1Hxeh+CgzNGwSLrj555SjJ8nj+Gc7RikimhXI44CyvIjIywcPBYxFlaIcSVnxAtXbcEGcbGeFbOE90un8X3S35TdysAgCg9HeuXzcawrOrxqq8DsWr1IqzqMwRnGuq3iE9BOdugKS7XboB0DdNND53pp/cQvbW9fHnbT8t7Y2879WsWzBvOX0ciUWIOSzUfQtmSTM0wbex03qRg2mxTSmKUfbSx400jrixZzTwb12spZvb7o2svfKUmEVVuitn0bR/Ue/YQnu/eYlWfIbhfoSriLC0x/MgenZoS/jdiEh57VcKT8t6YvHuL1rL72nRBneePYR8fq5IoCGWZSFOaAj1JKVnI7jQc6lI6zwSNQTFCR7nWoqffehydPJTXCRbImZclt0QzCUzT0tSOEhk0ZzneO7niuYcXpu7apFOymDu+7HM0TQ6XnVT9OH0Rgkq54eiUYbD4jDpAUrJADEYgEEBUrpzKfvtBvrAbOAAsLQ0RVpawbNMGocN/5I4Lrfmd91wXLkQppYVpPE+fwqvm/JUrxRUr8pYbLk6UR2QoV1UKs2Y5zB7Dv+YXxdwOMZbWsE6U4pJPQ9R49Zyb1bHxQ8W89edG98WRZm1R/kMoJk/4HwDA9WME1q6YD2NZJmwSE1D2wzu8LVUGHa9fgigzA9N3bkSrO9chlMsxa+QUZAqNsWXhNKzqMxSJZhKUiQzXaS2LvqeOIFFijqNZQy91pSlRAKAyR4YuYnJ1KtM0MkOdTd1+wKTdWxBYtjycYqJhnSjFeydXbOv8HWq9fApRRobOiQIAvZ9FXmKtbbghqco+5uq3MWzWEjR6cBf/1azL7TvetDWvr8vRr1sjVSSGVVIiWt79DwKm6KPz2KsSAEWHxryShb+btdHY6dEkM5PXJKbcPGSVlLMok9Tcgksi1DnepBXXj0XZ5ToNVKr3lWdKZVD0bXjv5IzBs5ejbNg7DPjnMOo/eQCLFMU8tWH2jrwOvWkmIo3NIv6VqsEt4gOcYmOQZGqGk41b4J2TK25Ur405f6zFK7dyauMEgJ6L1+PPeZO49/Mjr0q82sf3js5Y7DsKVd68xKhDuxBh5wDnmI96Jy6FhZIFUiwJjIwgMDOD6wL+jGhmderwOkeaVq2qMubZxMUFlZ8/w6u27ZARoliMSlyhgk7JgsDMDJYtWsB++DCkPHqE8NmfvmR3QctOHlrd/U/tcaFcju8uKpZo/mnHBmzv/B3mbVoNh/icZZ1XrV6IZx5eaPgogNtX75litcJdcyYiw9gYLjEfsfoXxfPPNBKi87ULsExOwlMPLzjGxcDn+SPsbdOF67jm+jEC35//B4AAoowMdL90Bj+NnY5QZ/07xdkkxKsdUloUHnhXxpip87mEwD4uFtE2iuTjUt2GKuUd4mJUPqgL29/NVROQq7VV1xRQThQARc2VstW9h3C/LxswApZJiTgwI6f/SXb/ggMtO+Bsgyao+PYNcsudmCkTZWQgWWkWzSQzCfctXLlfRbi9E6yTEhFjaQ3bhHiVD8jz9Rqrvb6xmmnDlWsW0k1MMGHSHDwv5wUAeOtaBguGjEO9Jw+w7FfFxHMPciWSCRJzGCXJsb91Z3z1+B683ikWknrgVQlTxs+CkVyO86P7Yl3PgbzauHFT52t8DgAQb2mFc0rzmij33fiveh3MGqVYgfJp+QoQZWZid/uu6HX2OEYcLri5aT4FJQvks1DuwH4k/PsvHEYoppYWWltDFh8P86+bajxHIMqp/nSZNRPW33RB6LDhGst7XboIE5ecTmKmlSpBnpD4aasmGlj7m1fUjoO3S4jnaiJys5fGqewzlstQ97kimVDuczHoxEEMOnFQpXz2REmrV/2M/a064d+vvsbSdUtgmZyIdT0HqnyILdywAgsHjUHXK2fx45HdEECxkNaWrr3woqz6EQoOsdFgAiPug3zYkT3Y3J3fBt/q9jVu/gld5R4Rkn19Tabu/B1zf5yIVLFuM1zO2bwGPw9TneY4N5OMdGRoWK9DXW2FLgmLumnElSWYW+B5WU9uWyiTQSox55pLXuoxWgQAzFOTefecNHE2PEODseD3VbyRLiNmLEKT+3dwrVY9DDh5CE3u34XrxwhI0lJxu0pNhDuo71NzrGlrnGjSEg0f3UPjB3fhEfaOdzzOwopLFJTdqVqT+z33MONEc3NcrNsQW7r2wpauipVHt/48FU/LK/pCyI2MFMNda/IXs9NFkllOE6qRUrKwvD//79Lu9ooFp/a16YKv791GlI0d/CtVx9j92/W+Z0ERMKbDQuLFlFQqhbW1NeLj42Flpfs4b/L5ywgPR9L1/2DVpTOMNFRhpz5/jndjxsJx/HhYd8mZJOpZJfVV0pWfq59pTlP5glbu4EG87dMHLF23nuGfk9xt0jFW1gi3c8CyASPQ+ep5fHfxNDKNhCrtyTKBACOnL8JLdw8sX7MYSWZmXB+DvEYtZHfokxkZ4dulGyHN6jRY4+UzyAUCrqr94E8j8d7JGcEuZfBL36F6v7Y9s8bieTlPzB82QeVYM/+bvOab0pFhGHjiEG+20MpBL7Hql4Uwlsmw9Zvvsaed4oOi7Id3mLprE8ZMy3tq8eLKLj4WdZ4/4Y1+0ZXH+xAEqZmnQpszY/uj1+JfdaqVOjZ5KCQpydjStRf3zAFg5ME/EVCpGm9oas0XT9Hm9jVuYrAD00dh4NwVavuWaOMZGsw1QyxevwwBlarhvaMzblWtBbmGdWKUjd6/A7M3/JJnOV3p8xlKNQvks2Ti4gKbHt9qLWNaqRK8zqkun+0wejQ+rl+v872cpk5F7P59kMXEapxZriCYlC4Fz3/PqPS3+BLkrla2k8bDThqP7T9P5fap63gmZAy/+83kzpcZGaHHhVN5zmkB5FRHC+VybFwyC1dr1YNTbDTqPH+MBHML/PZdf/Q5fRT20jjYS+NQ41UgkiQSlVEN7f+7hNONmsMrNBjh9g5ocv8ub2lz+/hYfH3vNvqeOoK/sqaYBgDT1FTM/WMNxtja4YV7eaxavRAe70NU5sAY9vdero3c810It7/b5X9RNYi/FsCUP3/Hnx2/5UavDDh5CF2vnEWPpRvzfB6GEGNtm69EAYDeiQIALBgyTufmq29W/oGWd67jSa7+J8rzZ2R7UKEKaii9596UctM7UQD4/W8SJOY42Eq/2WyDs9azMQSqWSAlUvSWLUgPfgv74cMQOmw47AYN4q13oc7rTp2R/lr9Yj62fXrrtOKdNpUeP4LA2BgxO3ciIzwCMVu3ftL1SP5cqVUPVkmJWNVnCNJEYuycNwkv3DxQJfgV187sX7Eqpkz4HzpfPcfrABjo7oG/2ndDplAI3xMHUSE0GGkmJkg0M+c174Q4l8LAeSthkpGOfbPGcp1cP1rbcqNZtiyYhvIfQrk1Meo+fYAlvy7F5ToNsGCoohlj8fplaPj4Hr73W6+1GaLu04e4W0X9rKqGJk5PUwyDLGF6nznKq9HQRbVXz3Fu2A8FFoM+n6GULBCiozddvtG46pvXhfN41VKxHoOxqysyw8K4Y/YjRyB6g+o3v0rPnkIWE4OMsHCI3MqojPLQp/kj9z2zlf1zJyJXrETKgwdqziLapBubgAkU01OrE27nAMe4GI2rXuYl3twSKWIxXGI+8vbv7NAdSWYSjDj8l9qe8DIjI6zoOwzWiQlc/46DLdpjfc+BaHH3P/S4cBpOMR/xT+MW8Hr3FplCIaq9foHvluZMVrZlwTR8cHTG7BH8xZRa3vmPt7gYADjFfESkhumjGzy+pzKT5PFJQ/Bvg6ZYl2v4qiY9z57A/jaqa8loMvzwbhz7ujVvZs6CYMhOtbo6MH0UGl86DyMz3ZZezws1QxBSCCT163PJgtfly3jVujWQkQH74cNhUqoUyh3YD6G1NUTu7ki+dw+JFy7CYfQoGJmawqxGDSReuQLrLt/gbR9FNbdAIICxvT2M7e213VYnzjNn4P3YcSr7hXZ2cJk3F8G9+xTJ3BNumzfB/Kuv8Lx68fwWqw91swMqy/0hry/rpARYJ6k2aw04dUTreUK5HD/9yV8joPvlf+H17i0qBb/mmjQG/nOYO86g6AOQZCbBb0tnw14ah/IfQrF1wVRYJCVhzQ+DUP/pQ3xz9Ry+ehSAF+4e6H75X8RZWqFK0CtcrVkXZSLDkWBujhNNWuGxZwWIMjKwcMNKfHB0xsB5iuWeW975DxYpyfj20hkuWfAOCcK0P3/HsFmqy94D4Ib+AoBlUiK6XD2H3e27qS2bXdvS4+JptFu3U+tz0lepqAiVZGH2lrVYMET1/6vC0PTebW42V3U6Xr8Ah/hYsKwJsIoaJQuE6MiqfTvE/vUXhPb2MHF2QqWHD5D54QOMSymGBppVz5mOWVK7NiS1c75xWbZoAcsWLcAYg22f3jBx0789VhvLVjmrTLr98QdCh+Z01DOtXBkV/e9CIBTmq7Om15XLiFi4CAn//ptnWYummkenkMIjlMu1LgUtALB58QxkCI15cwh4fFCMHlj4+ypuX5s719HmznUAQKmPkQCApg9yloGu8SoQcoEADIo+Je4RHzDk6D783awthiktNb5gwwocbtEe03dugFNsDLpe/hdPyldAv1NHcK9iVbS/cRnn6zZCu5tXcKlOAzzxrIiRh3ahw43LsE5MUNt3oFzWaAdRZgaGH96NTd/2gWVSIpasX4pMoRBPylfAuXqN8aZMWe6cUlERaBZwk6vyl6Qko/FDf/x4eDfspXHotWgdIu0cMPjYfkzJmpcEUIykaeZ/Ey/LlMPxpq2QJFG/EmtB6XL1HMxTknn9YZQ5Za0lIzBRvyZGYaNmCEL0kBoYCJPSpSG0UJ0Up6ClPHyIyF9+QfKNm9y+CnduI2TwEFi2bYOolTl/4Cs/f8YlAl7nz+FVq9YAgPInjkPslTN0LLuM2+8bEb35DyTfzfkQgEAA5PpzYD/iRzhNmMA7V5MKN29AaGMDAHjZ9GtkRuVvZc6CZlzKFZkfVJtoSMHSdZpsdaQScwSWLQ+f549hxBgyjYS4X6EKqga9gFlaGh5lzT2gPGyXAbhRvQ6cYqO5uRCyPSpfAZMmzobPs0eYvXUdzFNTwABcqV0fFd++4dUKJUjM8dHGFh4f3mGx7yiczVrB9MzYAVztUrqxCa8m4+uAW5i1bT2+91vPjbLJNmPbem659k7XLuD78yfxwcEZZcPf42TjlrhQtyHXhOJ7/ACOfd0arh+jsGblPKSbiPDYswKmqVlRdsmvS9DgyQOub1NBoD4LhHxBlCeXUh7e+aZbd6Q9f87tTw8NhTwhAeIKFfC8mqKWI3eykPLkCTJCQmDVQbG8ctyhwwibNQtWnTvDztcXwd/xlxF2GDcWjqMUk/RkJwtld/2Jt/1Uv/Upx5b2+jU+rv8NVh07IHbPXiRdv84dsxsyGJI6dfButGL4oNO0aYU6l0W5A/sR/D2/86rdwIGI2bGj0O5JDC/NxERjfxNtsmeZtMg1gdV7ByfcqF4HXa6d564bY2mNV2XKghkJMG/oBEz9axNa3r0BmUCAjzZ2cI5VXVl2Wb/hONW4BRxio3Fg5hjIBQLIBUa80UAbu/eBUC7HwJOHcKR5W4gyMtDt8r8QQNHXKfdEdPn12SQLV65cwfLly+Hv74+wsDAcOXIE3bp10/l8ShZISZD2JgiRK1bAYeQIXlNHemgoIletgv2QoTCrlrPYFJPJ8LxqNQBA+ZMnIPb0VLmmsvTQUJiULg15cgpe1OVPluQ4fhwcRiomz4lcsQJpwcEos3YtUh48wNveOUMMK9y9o7W2RXr2LN6PHQdxpUoo/7eiTV6WkACBsTGMzMzwbtx4nZo58kO51sW2Xz9I6tWDRYvmCBnoi5R76hf7KiqicuWQHhz8ydexGzyYGz1T0f8uku/d5zVFkeIjxtIax75ujY7/XYRTbEzeJ+SiaT6Y/NDnM1TzOqZFICkpCTVr1sR6Pca8E1LSiMt7wO239bxEAQBEbm4o88svvEQBgKI5QQ8iNzcIjIwgtDBHmQ2/we33nJEbyu2jTlOmwO3XXyEwMoKkdm14XbkM2/794b5ta57NMlZt2qD8P//AY/8+bp/Q0pLr1V16zWq4LuRP7e0wahRsB/BrMPJaVbTy82fwOHpU6QR++67QxgZW7drCSCSC68/zIXTk9/L3PJv/hMVuoPpFobQxcXfL9/2yWbZrB9sfenHbRubmsGjSGB5Hj8KipeYVIIlh2CXEw/fkoXwlCoZk0GShQ4cOWLhwIbp37553YUKIbpSSBaGdfmsWWLZoAYtmzeAwZgzElSrB5gfNY7pNnJzgMmsmzBuqrpegjri8BwQaZtsUCASw+e47VHr4AF6XLsLVzw8OI36E84wZKL1mDVfOceJEuMybp/U+RpKcYWXl9uaa+0IpjxJ7e8P7yhWYN8mZNEjk5gb37dsU9xo/DuWPH9PptQGA84wZqPTwAdw2b1Y5VuHWTTVnQNHwrsTVz0+liHXXb1Bq5Qq1iYxF61Yos2Y1RO7ucNu8CeUO5Uy9bVqxAtx+y/uLWKmVK/Isk18Cif4TFxHNhAUwciq/DJos6CstLQ1SqZT3QwjhEwgE8Dh8CGV374axrfZ1DTRxHDMa5f8+UiQdOZUJRCLF7Jzdu0EgEkEgEMCqndI6CIzB9ode8PxXdely5TLZlPtrKG4gyLUpgMu8uQAAq2+6AADMv/oKFR8+gMPIkRB7e3P7XZf4wXXRQrhv3641foEw58+q48SJ8Pz3DITW1nCaNg0A+CutyuXwPPsv7AYNgteli7Duxp+kp8zGDXCZPx/WnTpB5KZaC6Hcdm3RtCnMqlZVKZNNXLGi2v1W7dtrPEeZ/bCcZo3y/5yEna8vSq9eDYexYzSeY91JvxkK8yL29oZl27Yoo0MSZGh2AwdAUl/zUMj88Diwv0Cvp4/Pauikn58f5s/XvrIXIQQwrVLF0CEUEkUioNw8Yv/jj4j+PWfeAWPHnEWHssvZDRqEhDNnYNe3r8oVRWXKoOLDB7xrKq83UmrJEjhNnAgTV8Uyxunv+IsVOc+cCbMaSk1ESh/gDj/mLBBkN3AAxF6eMKtRAy++yqqNYQwiNzc4/zSNK2feqCGS/rsBALBs3px3L68L55H28iVCf1QsqKbPEFy3Db9xE4cpEyitSWBarRqcf5qG2H37IT1xIqeMmRkcJ0yALF4Ks5o1IS5fHs7TfwIAyNOa4+O6X3nX9L7xH9Jfv4Y8ORlxB/gLjTlOmoSoVTkjeeyHDYNV584I6qp+NkOrb7pAeuw4AMCsVk1uJVrTatWQ+vgx7Hx9ISrvAYmPD950yntyJzMfH6T4q19E7VOIK1aEbd8+kNStC6GtLZeoF+TaMial9F/BtaB8VsnCjBkzMGnSJG5bKpXCTU22TQj5Mom9FSv/mbi6wrZ/fxiZmcHOdyDiDh+CVTvFN2QjMzN4Xb4MgbEQgqxlkJ1/mganaVM19iLXtBgZoFguPTtRAMBbIh0A7HL1qzAyVz8eXyAUwuLrrwEA5o0aIem//2Dbt49KOZd58/BuzFjYDx2icsykVCmYlCoF9x07ID19Co6jR6mUya3C7VtgGRkwtreHy9w5CJ+vWJjK4+hRbqhr+ZMnkOzvD5sePSAQCmFarRpSHj7MWeLd2xsCoRCuP6t+WTMSi1F291942ycnETO2tYVx3bpIvHqV21dmw29IDwqG/eBBXLIgadAADmPHaH/+JiYou+tPxB89CqcpU7j9HgcPqJSt9PQJIhb7wbRqVYTNmKH2emV3/YmM0FCEjhyF9NevIRCJCmTxNmMHB9j21D5lvPvOHQgZMPCT72UIn1WyIBaLIRaXvDnECSnpyp84joywMJhWqsTtc5mVMxbd+/JlLjEAABNn1amAC2q4mdDaGmV+W4/YPXvhNGmiynHT6tVh80MvrZ0x3Tb9joywMLVNCyJ3d5Q/dlTNWTnMG9SHeQPdqriFSr3crb/9FgmXLsGicROYVsxZQEns6ckbNWNkZgbPM6fxvHJWDVUeU1pL6tSBQCIBS07WWMayRQsg1xppdoN8VRIFq86dkfHhA1ICAhTxW1hAUrcuJLlG6qgjMDKCy/9mAYDGZEEgEEDk7g7PkyeQ+uwZjF1c8LJhI7VlAcUziz+cMxum0MYGsrg4lXKaksTc8eVmN2QwYraorgNjWqMGUh8+zPOaReWzShYIISWT2MtLtf+BEnV/hAuTZcuWsNQw0kAgEMA1j06YAmNjtYlCYTMSi+H+++95F0Su5EqHEfYSHx8kKdUkZF1FbVm3zZuR+vQpLJo1UznmMHIExJ6eXPV9YTapmVauzMWTcu8emEzGa9ICFDVH2cmC0NEBXufOIbBmLZVrOc9Un5woU25G8L56BUk3b8KyXTsYmZohOcAfknr18HHtOgBA2W1bkXzvPlIC/CEQmxq8adGgyUJiYiJevXrFbQcFBeH+/fuws7ODu3vBTodLCCEkfxjLe7GsUosXIerX9bxhnKJyZdWWtWjaBBZN+UtXe126iMyoKK6Gw+PwISQH3INVly75illoawtZbKxOZZXjMXF1hbGTIyxatIA8KQlCCwuUWrYUEX5LUGbtWl6fFNs+fRC7e7fiPBcXtdd2njULEYsWwf7HHxVNSNu2wsjKCsaOjrDOem2OSp1EHUeNApPLITAygkWTxrBo0jhfr7+gGXRSpkuXLqFFixYq+wcOHIjtWnocZ6NJmQghpPBkf7sXV66M8kcO51FavaRbtyG0tYFphQp5Fy5Aqc+eIXzRIjhNmozwefOQ9uIFgPxPasQYg0AgAMvI4BZKK//PP4g7eBAWTZtoHUKcEREJYyfHAmsKKyifzaqTzZs3x2c82zQhhJQIKhN/6UHXvhUFzbRyZZTbtavArpf9QS8wMYH1dz0gT0iEyKMcnKdNzfNcdX1oPjfUZ4EQQoha5U8ch/Sff2A3eLChQylWSi1caOgQihwlC4QQQtQSe3nBcdw4Q4fx6agG+5N9VjM4EkIIIfoSe2seSUN0QzULhBBCvmjOs2fDyNoaNt9+a+hQPluULBBCCPmiGdvawnXuXEOH8VmjZghCCCGEaEXJAiGEEEK0omSBEEIIIVpRskAIIYQQrShZIIQQQohWlCwQQgghRCtKFgghhBCiFSULhBBCCNGKkgVCCCGEaEXJAiGEEEK0omSBEEIIIVpRskAIIYQQrShZIIQQQohWlCwQQgghRCtKFgghhBCiFSULhBBCCNGKkgVCCCGEaEXJAiGEEEK0omSBEEIIIVpRskAIIYQQrShZIIQQQohWlCwQQgghRCtKFgghhBCiFSULhBBCCNGKkgVCCCGEaEXJAiGEEEK0omSBEEIIIVpRskAIIYQQrShZIIQQQohWlCwQQgghRCtKFgghhBCiFSULhBBCCNGKkgVCCCGEaEXJAiGEEEK0omSBEEIIIVpRskAIIYQQrShZIIQQQohWlCwQQgghRCtKFgghhBCiFSULhBBCCNGKkgVCCCGEaEXJAiGEEEK0omSBEEIIIVpRskAIIYQQrShZIIQQQohWlCwQQgghRKtikSysX78e5cqVg6mpKRo0aIDbt28bOiRCCCGEZDF4srBv3z5MmjQJc+fORUBAAGrWrIl27dohMjLS0KERQgghBMUgWVi1ahWGDRuGQYMGoUqVKti4cSMkEgm2bt1q6NAIIYQQAsDYkDdPT0+Hv78/ZsyYwe0zMjJC69atcePGDZXyaWlpSEtL47bj4+MBAFKptPCDJYQQQr4g2Z+djLE8yxo0Wfj48SNkMhmcnZ15+52dnfH8+XOV8n5+fpg/f77Kfjc3t0KLkRBCCPmSJSQkwNraWmsZgyYL+poxYwYmTZrEbcvlcsTExMDe3h4CgaBA7iGVSuHm5obQ0FBYWVkVyDVJ3ui5GwY9d8Og524Y9Nz5GGNISEhAqVKl8ixr0GTBwcEBQqEQERERvP0RERFwcXFRKS8WiyEWi3n7bGxsCiU2KysrejMZAD13w6Dnbhj03A2DnnuOvGoUshm0g6NIJIKPjw/Onz/P7ZPL5Th//jwaNmxowMgIIYQQks3gzRCTJk3CwIEDUbduXdSvXx+rV69GUlISBg0aZOjQCCGEEIJikCz06tULUVFRmDNnDsLDw1GrVi2cPn1apdNjURGLxZg7d65KcwcpXPTcDYOeu2HQczcMeu75J2C6jJkghBBCSIll8EmZCCGEEFK8UbJACCGEEK0oWSCEEEKIVpQsEEIIIUQrShZyoeWy88/Pzw/16tWDpaUlnJyc0K1bNwQGBvLKpKamYvTo0bC3t4eFhQV69OihMilXSEgIOnXqBIlEAicnJ0ydOhWZmZm8MpcuXUKdOnUgFovh5eWF7du3F/bL+ywsWbIEAoEAEyZM4PbRMy8879+/R79+/WBvbw8zMzNUr14dd+/e5Y4zxjBnzhy4urrCzMwMrVu3xsuXL3nXiImJQd++fWFlZQUbGxsMGTIEiYmJvDIPHz5E06ZNYWpqCjc3NyxbtqxIXl9xJJPJMHv2bHh4eMDMzAyenp5YsGABb30Deu6FgBHO3r17mUgkYlu3bmVPnjxhw4YNYzY2NiwiIsLQoX0W2rVrx7Zt28YeP37M7t+/zzp27Mjc3d1ZYmIiV2bEiBHMzc2NnT9/nt29e5d99dVXrFGjRtzxzMxMVq1aNda6dWt279499s8//zAHBwc2Y8YMrsybN2+YRCJhkyZNYk+fPmXr1q1jQqGQnT59ukhfb3Fz+/ZtVq5cOVajRg02fvx4bj8988IRExPDypYty3x9fdmtW7fYmzdv2JkzZ9irV6+4MkuWLGHW1tbs77//Zg8ePGDffPMN8/DwYCkpKVyZ9u3bs5o1a7KbN2+yq1evMi8vL9a7d2/ueHx8PHN2dmZ9+/Zljx8/Znv27GFmZmbs999/L9LXW1wsWrSI2dvbsxMnTrCgoCB24MABZmFhwdasWcOVoede8ChZUFK/fn02evRoblsmk7FSpUoxPz8/A0b1+YqMjGQA2OXLlxljjMXFxTETExN24MABrsyzZ88YAHbjxg3GGGP//PMPMzIyYuHh4VyZDRs2MCsrK5aWlsYYY2zatGmsatWqvHv16tWLtWvXrrBfUrGVkJDAvL292dmzZ1mzZs24ZIGeeeH56aefWJMmTTQel8vlzMXFhS1fvpzbFxcXx8RiMduzZw9jjLGnT58yAOzOnTtcmVOnTjGBQMDev3/PGGPst99+Y7a2tty/Rfa9K1asWNAv6bPQqVMnNnjwYN6+b7/9lvXt25cxRs+9sFAzRJbs5bJbt27N7dO2XDbJW/YS4nZ2dgAAf39/ZGRk8J5xpUqV4O7uzj3jGzduoHr16rxJudq1awepVIonT55wZZSvkV2mJP87jR49Gp06dVJ5LvTMC8+xY8dQt25dfP/993ByckLt2rWxefNm7nhQUBDCw8N5z83a2hoNGjTgPXsbGxvUrVuXK9O6dWsYGRnh1q1bXJmvv/4aIpGIK9OuXTsEBgYiNja2sF9msdOoUSOcP38eL168AAA8ePAA165dQ4cOHQDQcy8sBp/BsbjQd7lsop1cLseECRPQuHFjVKtWDQAQHh4OkUiksviXs7MzwsPDuTLq/g2yj2krI5VKkZKSAjMzs8J4ScXW3r17ERAQgDt37qgco2deeN68eYMNGzZg0qRJmDlzJu7cuYNx48ZBJBJh4MCB3LNT99yUn6uTkxPvuLGxMezs7HhlPDw8VK6RfczW1rZQXl9xNX36dEilUlSqVAlCoRAymQyLFi1C3759AYCeeyGhZIEUitGjR+Px48e4du2aoUP5ooWGhmL8+PE4e/YsTE1NDR1OiSKXy1G3bl0sXrwYAFC7dm08fvwYGzduxMCBAw0c3Zdr//79+Ouvv7B7925UrVoV9+/fx4QJE1CqVCl67oWImiGy6LtcNtFszJgxOHHiBC5evIgyZcpw+11cXJCeno64uDheeeVn7OLiovbfIPuYtjJWVlYl7huuv78/IiMjUadOHRgbG8PY2BiXL1/G2rVrYWxsDGdnZ3rmhcTV1RVVqlTh7atcuTJCQkIA5Dw7bX9TXFxcEBkZyTuemZmJmJgYvf59SpKpU6di+vTp+OGHH1C9enX0798fEydOhJ+fHwB67oWFkoUstFz2p2OMYcyYMThy5AguXLigUoXn4+MDExMT3jMODAxESEgI94wbNmyIR48e8f5HPnv2LKysrLg/zA0bNuRdI7tMSfx3atWqFR49eoT79+9zP3Xr1kXfvn253+mZF47GjRurDA1+8eIFypYtCwDw8PCAi4sL77lJpVLcunWL9+zj4uLg7+/Plblw4QLkcjkaNGjAlbly5QoyMjK4MmfPnkXFihVLXFU4ACQnJ8PIiP/RJRQKIZfLAdBzLzSG7mFZnOzdu5eJxWK2fft29vTpUzZ8+HBmY2PD6yVONBs5ciSztrZmly5dYmFhYdxPcnIyV2bEiBHM3d2dXbhwgd29e5c1bNiQNWzYkDuePYyvbdu27P79++z06dPM0dFR7TC+qVOnsmfPnrH169eX+GF8ypRHQzBGz7yw3L59mxkbG7NFixaxly9fsr/++otJJBK2a9cursySJUuYjY0NO3r0KHv48CHr2rWr2iF8tWvXZrdu3WLXrl1j3t7evCF8cXFxzNnZmfXv3589fvyY7d27l0kkkhI7hG/gwIGsdOnS3NDJw4cPMwcHBzZt2jSuDD33gkfJQi7r1q1j7u7uTCQSsfr167ObN28aOqTPBgC1P9u2bePKpKSksFGjRjFbW1smkUhY9+7dWVhYGO86wcHBrEOHDszMzIw5ODiwyZMns4yMDF6Zixcvslq1ajGRSMTKly/Pu0dJlztZoGdeeI4fP86qVavGxGIxq1SpEtu0aRPvuFwuZ7Nnz2bOzs5MLBazVq1ascDAQF6Z6Oho1rt3b2ZhYcGsrKzYoEGDWEJCAq/MgwcPWJMmTZhYLGalS5dmS5YsKfTXVlxJpVI2fvx45u7uzkxNTVn58uXZrFmzeEMc6bkXPFqimhBCCCFaUZ8FQgghhGhFyQIhhBBCtKJkgRBCCCFaUbJACCGEEK0oWSCEEEKIVpQsEEIIIUQrShYIIYQQohUlC4QQQgjRipIFQkqgcuXKYfXq1TqXv3TpEgQCgcqCVISQkoGSBUKKMYFAoPVn3rx5+brunTt3MHz4cJ3LN2rUCGFhYbC2ts7X/QoCJSyEGI6xoQMghGgWFhbG/b5v3z7MmTOHt9KhhYUF9ztjDDKZDMbGef9v7ejoqFccIpGoRC7LSwhRoJoFQooxFxcX7sfa2hoCgYDbfv78OSwtLXHq1Cn4+PhALBbj2rVreP36Nbp27QpnZ2dYWFigXr16OHfuHO+6uZshBAIB/vjjD3Tv3h0SiQTe3t44duwYdzz3t/rt27fDxsYGZ86cQeXKlWFhYYH27dvzkpvMzEyMGzcONjY2sLe3x08//YSBAweiW7duGl/v27dv0aVLF9ja2sLc3BxVq1bFP//8g+DgYLRo0QIAYGtrC4FAAF9fXwCKpeT9/Pzg4eEBMzMz1KxZEwcPHlSJ/eTJk6hRowZMTU3x1Vdf4fHjx3nelxCiQMkCIZ+56dOnY8mSJXj27Blq1KiBxMREdOzYEefPn8e9e/fQvn17dOnSBSEhIVqvM3/+fPTs2RMPHz5Ex44d0bdvX8TExGgsn5ycjBUrVuDPP//ElStXEBISgilTpnDHly5dir/++gvbtm3D9evXIZVK8ffff2uNYfTo0UhLS8OVK1fw6NEjLF26FBYWFnBzc8OhQ4cAAIGBgQgLC8OaNWsAAH5+fti5cyc2btyIJ0+eYOLEiejXrx8uX77Mu/bUqVOxcuVK3LlzB46OjujSpQsyMjK03pcQksXAq14SQnS0bds2Zm1tzW1fvHiRAWB///13nudWrVqVrVu3jtsuW7Ys++WXX7htAOx///sft52YmMgAsFOnTvHuFRsby8UCgL169Yo7Z/369czZ2ZnbdnZ2ZsuXL+e2MzMzmbu7O+vatavGOKtXr87mzZun9ljuGBhjLDU1lUkkEvbff//xyg4ZMoT17t2bd97evXu549HR0czMzIzt27cvz/sSQhijPguEfObq1q3L205MTMS8efNw8uRJhIWFITMzEykpKXnWLNSoUYP73dzcHFZWVoiMjNRYXiKRwNPTk9t2dXXlysfHxyMiIgL169fnjguFQvj4+EAul2u85rhx4zBy5Ej8+++/aN26NXr06MGLK7dXr14hOTkZbdq04e1PT09H7dq1efsaNmzI/W5nZ4eKFSvi2bNn+bovISUNNUMQ8pkzNzfnbU+ZMgVHjhzB4sWLcfXqVdy/fx/Vq1dHenq61uuYmJjwtgUCgdYPdnXlGWN6Rs83dOhQvHnzBv3798ejR49Qt25drFu3TmP5xMREAMDJkydx//597ufp06e8fgsFfV9CShpKFgj5wly/fh2+vr7o3r07qlevDhcXFwQHBxdpDNbW1nB2dsadO3e4fTKZDAEBAXme6+bmhhEjRuDw4cOYPHkyNm/eDEAxIiP7OtmqVKkCsViMkJAQeHl58X7c3Nx417158yb3e2xsLF68eIHKlSvneV9CCA2dJOSL4+3tjcOHD6NLly4QCASYPXu21hqCwjJ27Fj4+fnBy8sLlSpVwrp16xAbGwuBQKDxnAkTJqBDhw6oUKECYmNjcfHiRe4DvWzZshAIBDhx4gQ6duwIMzMzWFpaYsqUKZg4cSLkcjmaNGmC+Ph4XL9+HVZWVhg4cCB37Z9//hn29vZwdnbGrFmz4ODgwI3M0HZfQgjVLBDyxVm1ahVsbW3RqFEjdOnSBe3atUOdOnWKPI6ffvoJvXv3xoABA9CwYUNYWFigXbt2MDU11XiOTCbD6NGjUblyZbRv3x4VKlTAb7/9BgAoXbo05s+fj+nTp8PZ2RljxowBACxYsACzZ8+Gn58fd97Jkyfh4eHBu/aSJUswfvx4+Pj4IDw8HMePH+fVVmi6LyEEELBPbWQkhBAdyOVyVK5cGT179sSCBQuK7L6XLl1CixYtEBsbCxsbmyK7LyFfEmqGIIQUirdv3+Lff/9Fs2bNkJaWhl9//RVBQUHo06ePoUMjhOiJmiEIIYXCyMgI27dvR7169dC4cWM8evQI586do74AhHyGqBmCEEIIIVpRzQIhhBBCtKJkgRBCCCFaUbJACCGEEK0oWSCEEEKIVpQsEEIIIUQrShYIIYQQohUlC4QQQgjRipIFQgghhGj1fxfAJOWeqCuJAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "3iZTVn5WQFpX",
        "outputId": "770e22bf-24e5-4d4a-e3bd-965e29545577"
      },
      "source": [
        "del model\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
        "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)\n",
        "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-5bebdf951c03>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQikz3IPiyPf"
      },
      "source": [
        "# **Testing**\n",
        "The predictions of your model on testing set will be stored at `pred.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8cTuQjQQOon",
        "outputId": "916dd21e-c8db-4669-8804-42afc95b5eed"
      },
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    print('Saving results to {}'.format(file))\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tested_positive'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])\n",
        "\n",
        "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results to pred.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfrVxqJanGpE"
      },
      "source": [
        "# **Hints**\n",
        "\n",
        "## **Simple Baseline**\n",
        "* Run sample code\n",
        "\n",
        "## **Medium Baseline**\n",
        "* Feature selection: 40 states + 2 `tested_positive` (`TODO` in dataset)\n",
        "\n",
        "## **Strong Baseline**\n",
        "* Feature selection (what other features are useful?)\n",
        "* DNN architecture (layers? dimension? activation function?)\n",
        "* Training (mini-batch? optimizer? learning rate?)\n",
        "* L2 regularization\n",
        "* There are some mistakes in the sample code, can you find them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tmCwXgpot3t"
      },
      "source": [
        "# **Reference**\n",
        "This code is completely written by Heng-Jui Chang @ NTUEE.  \n",
        "Copying or reusing this code is required to specify the original author.\n",
        "\n",
        "E.g.  \n",
        "Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"
      ]
    }
  ]
}