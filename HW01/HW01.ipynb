{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML2021Spring - HW1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meibohuhu/python_projects/blob/main/HW01/HW01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0_QVkxCrX3"
      },
      "source": [
        "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZnPAiwDRWG"
      },
      "source": [
        "Author: Heng-Jui Chang\n",
        "\n",
        "Slides: https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.pdf  \n",
        "Videos (Mandarin): https://cool.ntu.edu.tw/courses/4793/modules/items/172854  \n",
        "https://cool.ntu.edu.tw/courses/4793/modules/items/172853  \n",
        "Video (English): https://cool.ntu.edu.tw/courses/4793/modules/items/176529\n",
        "\n",
        "\n",
        "Objectives:\n",
        "* Solve a regression problem with deep neural networks (DNN).\n",
        "* Understand basic DNN training tips.\n",
        "* Get familiar with PyTorch.\n",
        "\n",
        "If any questions, please contact the TAs via TA hours, NTU COOL, or email.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx3x1nDkG-Uy"
      },
      "source": [
        "# **Download Data**\n",
        "\n",
        "\n",
        "If the Google drive links are dead, you can download data from [kaggle](https://www.kaggle.com/c/ml2021spring-hw1/data), and upload data manually to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMj55YDKG6ch",
        "outputId": "48b3e058-8ff3-49f4-9d21-6a90d0f0cf79"
      },
      "source": [
        "tr_path = 'covid.train.csv'  # path to training data\n",
        "tt_path = 'covid.test.csv'   # path to testing data\n",
        "\n",
        "!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
        "!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n",
            "To: /content/covid.train.csv\n",
            "100% 2.00M/2.00M [00:00<00:00, 65.6MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n",
            "To: /content/covid.test.csv\n",
            "100% 651k/651k [00:00<00:00, 17.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_4-77xHk44"
      },
      "source": [
        "# **Import Some Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-onQd4JNA5H"
      },
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "myseed = 42069  # set a random seed for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtE3b6JEH7rw"
      },
      "source": [
        "# **Some Utilities**\n",
        "\n",
        "You do not need to modify this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWMT3uf1NGQp"
      },
      "source": [
        "def get_device():\n",
        "    ''' Get device (if GPU is available, use GPU) '''\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
        "    plt.ylim(0.0, 5.)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure(figsize=(5, 5))\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39U_XFX6KOoj"
      },
      "source": [
        "# **Preprocess**\n",
        "\n",
        "We have three kinds of datasets:\n",
        "* `train`: for training\n",
        "* `dev`: for validation\n",
        "* `test`: for testing (w/o target value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ-MdwpLL7Dt"
      },
      "source": [
        "## **Dataset**\n",
        "\n",
        "The `COVID19Dataset` below does:\n",
        "* read `.csv` files\n",
        "* extract features\n",
        "* split `covid.train.csv` into train/dev sets\n",
        "* normalize features\n",
        "\n",
        "Finishing `TODO` below might make you pass medium baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zlpIp9ANJRU"
      },
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
        "    def __init__(self,\n",
        "                 path,\n",
        "                 mode='train',\n",
        "                 target_only=False):\n",
        "        self.mode = mode\n",
        "\n",
        "        # Read data into numpy arrays\n",
        "        with open(path, 'r') as fp:\n",
        "            data = list(csv.reader(fp))\n",
        "            data = np.array(data[1:])[:, 1:].astype(float)\n",
        "        print(f\"data id: {data}:\")\n",
        "        if not target_only:\n",
        "            feats = list(range(93))\n",
        "            print(f\"feats id: {feats}:\")\n",
        "        else:\n",
        "            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n",
        "            pass\n",
        "\n",
        "        if mode == 'test':\n",
        "            # Testing data\n",
        "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
        "            data = data[:, feats]\n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            # Training data (train/dev sets)\n",
        "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
        "            target = data[:, -1]   ## y labels: 1\n",
        "            data = data[:, feats]   ## features: 93\n",
        "\n",
        "            # Splitting training data into train & dev sets\n",
        "            if mode == 'train':\n",
        "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
        "\n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data[indices])\n",
        "            self.target = torch.FloatTensor(target[indices])\n",
        "            print(f\"data.shape: {self.data.shape}\")\n",
        "            print(f\"target: {self.target}\")\n",
        "            print(f\"target.shape: {self.target.shape}\")\n",
        "\n",
        "        # Normalize features (you may remove this part to see what will happen)\n",
        "        ## Normalization for features after 40\n",
        "        self.data[:, 40:] = \\\n",
        "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
        "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "        print(f\"self.dim is {self.dim}\")\n",
        "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
        "              .format(mode, len(self.data), self.dim))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]   # Returns (x, y) pair\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]    # Test mode - only x, no y\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns the size of the dataset\n",
        "        return len(self.data)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureTransformation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureTransformation, self).__init__()\n",
        "        self.compact_states = nn.Linear(40, 10)  # Transform first 40 features to 10\n",
        "\n",
        "    def forward(self, x):\n",
        "        states = x[:, :40]  # First 40 features\n",
        "        other_features = x[:, 40:]  # Remaining features\n",
        "\n",
        "        # Transform state features\n",
        "        compact_states = self.compact_states(states)\n",
        "\n",
        "        # Concatenate with other features\n",
        "        return torch.cat([compact_states, other_features], dim=1)"
      ],
      "metadata": {
        "id": "UdopOBdbtfYz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlhTlkE7MDo3"
      },
      "source": [
        "## **DataLoader**\n",
        "\n",
        "A `DataLoader` loads data from a given `Dataset` into batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlhLk5t6MBX3"
      },
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
        "    return dataloader"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGuycwR0MeQB"
      },
      "source": [
        "# **Deep Neural Network**\n",
        "\n",
        "`NeuralNet` is an `nn.Module` designed for regression.\n",
        "The DNN consists of 2 fully-connected layers with ReLU activation.\n",
        "This module also included a function `cal_loss` for calculating loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49-uXYovOAI0"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.feature_transform = FeatureTransformation()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "        # self.net = nn.Sequential(\n",
        "        #     nn.Linear(input_dim, 64),  # First layer: input_dim -> 128 neurons\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(64, 16),         # Second layer: 128 -> 64 neurons\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(16, 1)           # Output layer: 64 -> 1 neuron\n",
        "        # )\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "        self.lambda_l1 = 0.01  # Add this line to initialize lambda_l1  ## mhu\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_transform(x)\n",
        "        print(f\"x shape is {x.shape}\")\n",
        "        print(f\"x is {x[0,:10]}\")\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "        ''' Calculate loss '''\n",
        "        # TODO: you may implement L1/L2 regularization here\n",
        "        # return self.criterion(pred, target)\n",
        "        # print(f\"pred: {pred}\")\n",
        "        # print(f\"target: {target}\")\n",
        "        return self.l1_loss(pred, target)  # L1 regularization      ## mhu\n",
        "\n",
        "    def l1_loss(self, y_pred, y_true):  # Only need self, y_pred, y_true as parameters    ## mhu\n",
        "        # Calculate MSE loss\n",
        "        mse_loss = self.criterion(y_pred, y_true)\n",
        "\n",
        "        # Calculate L1 regularization term\n",
        "        l1_reg = torch.tensor(0., requires_grad=True)\n",
        "        for param in self.net.parameters():\n",
        "            l1_reg = l1_reg + torch.norm(param, 1)\n",
        "            # print(f\"parameters shape are: {param.shape}\")\n",
        "            # print(f\"parameters are: {param}\")\n",
        "        # print(f\"l1_reg is: {l1_reg}\")\n",
        "        # Combine MSE with L1 regularization\n",
        "        total_loss = mse_loss + self.lambda_l1 * l1_reg\n",
        "        print(f\"total_loss {total_loss}\")\n",
        "        return total_loss"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvFWVjZ5Nvga"
      },
      "source": [
        "# **Train/Dev/Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAM8QecJOyqn"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOqcmYzMO7jB"
      },
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    ''' DNN training '''\n",
        "\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(  ## optimizer is SGD\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    min_mse = 1000.\n",
        "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()                           # set model to training mode\n",
        "        index = 0\n",
        "        for x, y in tr_set:                     # iterate through the dataloader\n",
        "            optimizer.zero_grad()               # set gradient to zero\n",
        "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
        "            # print(f\"x, y are {x}, {y}\")\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
        "            optimizer.step()                    # update model with optimizer\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "            # print(f\"x shape {x.shape}\")   ## x shape torch.Size([270, 93])\n",
        "            # print(f\"epoch {epoch}: parameter with {model.parameters()}; index {index}\")\n",
        "            index = index + 1\n",
        "\n",
        "        # After each epoch, test your model on the validation (development) set.\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
        "                .format(epoch + 1, min_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "\n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_mse, loss_record"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hSd4Bn3O2PL"
      },
      "source": [
        "## **Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrxrD3YsN3U2"
      },
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:                         # iterate through the dataloader\n",
        "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0pdrhQAO41L"
      },
      "source": [
        "## **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSBMRFlYN5tB"
      },
      "source": [
        "def test(tt_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    preds = []\n",
        "    for x in tt_set:                            # iterate through the dataloader\n",
        "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            preds.append(pred.detach().cpu())   # collect prediction\n",
        "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
        "    return preds"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvckkF5dvf0j"
      },
      "source": [
        "# **Setup Hyper-parameters**\n",
        "\n",
        "`config` contains hyper-parameters for training and the path to save your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPXpdumwPjE7"
      },
      "source": [
        "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "target_only = False                   # TODO: Using 40 states & 2 tested_positive features\n",
        "\n",
        "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
        "config = {\n",
        "    'n_epochs': 3000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader   ## totally 2700 data\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)  Stochastic Gradient Descent\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.003,                 # learning rate of SGD  0.001 0.003\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j1eOV3TOH-j"
      },
      "source": [
        "# **Load data and model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNrYBMmePLKm",
        "outputId": "9988a72d-e389-4a67-e2a4-59fe015408bc"
      },
      "source": [
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data id: [[ 1.         0.         0.        ... 53.9915494 43.6042293 20.7049346]\n",
            " [ 1.         0.         0.        ... 54.185521  42.6657659 21.2929114]\n",
            " [ 1.         0.         0.        ... 53.6370693 42.972417  21.1666563]\n",
            " ...\n",
            " [ 0.         0.         0.        ... 67.731162  38.740651  12.6134414]\n",
            " [ 0.         0.         0.        ... 67.7950996 38.595125  12.4772268]\n",
            " [ 0.         0.         0.        ... 68.2840782 38.4538196 11.8117187]]:\n",
            "feats id: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92]:\n",
            "data.shape: torch.Size([2430, 93])\n",
            "target: tensor([21.2929, 21.1667, 19.8966,  ..., 12.6134, 12.4772, 11.8117])\n",
            "target.shape: torch.Size([2430])\n",
            "self.dim is 93\n",
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)\n",
            "data id: [[ 1.         0.         0.        ... 53.9915494 43.6042293 20.7049346]\n",
            " [ 1.         0.         0.        ... 54.185521  42.6657659 21.2929114]\n",
            " [ 1.         0.         0.        ... 53.6370693 42.972417  21.1666563]\n",
            " ...\n",
            " [ 0.         0.         0.        ... 67.731162  38.740651  12.6134414]\n",
            " [ 0.         0.         0.        ... 67.7950996 38.595125  12.4772268]\n",
            " [ 0.         0.         0.        ... 68.2840782 38.4538196 11.8117187]]:\n",
            "feats id: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92]:\n",
            "data.shape: torch.Size([270, 93])\n",
            "target: tensor([20.7049, 14.7807, 15.6246, 16.3530, 21.1403, 20.8325, 24.9998,  3.5714,\n",
            "         8.6364,  5.7692,  8.6777,  2.8689, 13.1818, 16.1972,  6.8915,  6.3984,\n",
            "         5.9165,  7.7938,  7.7073, 12.3563, 12.7403, 14.3317, 11.1861, 21.9149,\n",
            "        15.7216, 20.2072, 25.5939,  7.4021,  6.4085,  6.0283,  5.9251,  5.5663,\n",
            "         7.7832,  7.3929,  6.8333,  4.4167,  8.1111,  8.1560, 10.5540, 19.6793,\n",
            "        19.3069,  3.7081,  3.7349,  3.5714,  5.3172,  7.1256,  9.6074,  9.9155,\n",
            "         9.7659,  9.7680,  9.4623, 12.0087, 10.4674, 14.1234, 13.6284, 16.2547,\n",
            "        12.1887, 13.4219, 11.4552, 13.7278, 14.9270, 16.9451, 13.5416, 24.6665,\n",
            "        25.5589, 31.2903, 33.9516,  8.7232,  9.4743, 10.4471, 10.4545, 13.6004,\n",
            "        21.5362, 24.7947,  8.0300, 10.0231, 10.1980, 13.5331, 17.4769, 24.8762,\n",
            "        26.2595, 15.9436, 16.9328, 17.6547, 20.6308, 22.7727, 35.3088, 36.3085,\n",
            "         9.6535, 14.2492, 17.8857, 18.5279, 27.2095, 34.6939,  5.5838,  8.7310,\n",
            "         5.3524, 10.9467, 10.6357, 15.4454, 17.5906, 15.9164, 12.1667, 11.6864,\n",
            "        18.8136, 16.1972, 20.7895, 19.6934,  3.4328,  5.3623,  6.6978,  4.7965,\n",
            "         7.0447,  7.5002,  2.7955,  2.6699,  2.9236,  4.3846,  2.8400,  4.2266,\n",
            "         6.3151,  3.5552,  5.7635,  9.5210,  7.8600, 11.7246, 21.8559, 21.3177,\n",
            "         8.4688,  9.5714, 10.6358, 13.0657, 15.2333, 25.8462, 23.3341, 26.2862,\n",
            "        24.1377, 25.5078, 32.0859, 34.6538, 32.1228, 27.8052, 21.7863, 24.6114,\n",
            "        23.7782, 25.3970, 25.9979, 19.5248, 25.9552, 25.1661, 25.5945, 22.8514,\n",
            "        21.9144, 24.1784, 18.4365, 21.6929, 25.4017, 24.9391, 25.2821, 27.2217,\n",
            "        21.4053, 18.9927, 11.9544, 13.8410, 14.0538, 13.6969, 15.8808, 13.5315,\n",
            "        19.8848, 16.4687, 18.2368, 13.7259, 17.7635, 15.5539, 14.0926,  6.9774,\n",
            "         8.3083,  9.6499, 11.0942, 12.5183, 13.5763, 12.8692, 12.9802, 13.9286,\n",
            "        18.6407, 18.1189, 20.1045, 20.9195, 20.7997, 23.7527, 24.5305, 26.1734,\n",
            "        24.5663, 26.8204, 25.4401, 20.5535, 22.1942, 26.6685, 28.8944, 28.5828,\n",
            "        35.6474, 26.9797,  9.8705, 11.2216,  9.6731, 13.3239, 12.5317, 12.5703,\n",
            "         8.2829, 19.1983, 22.5969, 23.5935, 25.9001, 24.6988, 25.2553, 21.3563,\n",
            "        12.1133, 16.9385, 17.0957,  8.9584, 13.6514,  9.6829, 10.1373, 10.3420,\n",
            "        17.6791, 20.2152, 20.7517, 25.9487, 24.4629, 20.1631, 20.3369, 21.6015,\n",
            "        23.2329, 24.6127, 28.6281, 25.0085, 27.3285, 22.5122, 25.8700, 23.2383,\n",
            "        27.3183, 31.4549, 20.4373, 12.4127, 15.8738, 17.5510, 21.0565, 19.5545,\n",
            "        24.4510, 22.1006,  9.8401, 10.0151, 11.3076, 11.8321, 10.3945, 11.5500,\n",
            "         9.4237, 16.0550, 16.3664, 19.7704, 20.4319, 23.6292, 21.6321, 16.5551,\n",
            "        21.9787, 20.1007, 18.6773, 12.9403, 17.1829, 13.6446])\n",
            "target.shape: torch.Size([270])\n",
            "self.dim is 93\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 93)\n",
            "data id: [[ 0.         0.         0.        ... 24.7478373 66.1949496 44.8734726]\n",
            " [ 0.         0.         0.        ... 23.5596222 57.0150091 38.3728286]\n",
            " [ 0.         0.         0.        ... 24.9933415 55.291498  38.9072574]\n",
            " ...\n",
            " [ 0.         0.         0.        ... 22.4236395 60.9348512 43.1225126]\n",
            " [ 0.         0.         0.        ... 17.4760626 54.8623859 44.0162552]\n",
            " [ 0.         0.         0.        ... 21.2171063 66.8707632 37.9308586]]:\n",
            "feats id: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92]:\n",
            "self.dim is 93\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHylSirLP9oh"
      },
      "source": [
        "# model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device\n",
        "model = NeuralNet(63).to(device)  # Construct model and move to device"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX2B_zgSOPTJ"
      },
      "source": [
        "# **Start Training!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GrEbUxazQAAZ",
        "outputId": "e8321026-6d35-406f-e933-8b6c35ed7889"
      },
      "source": [
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0384,  0.0978,  0.0187, -0.1050, -0.0224, -0.0003,  0.1278, -0.0004,\n",
            "         0.0703,  0.1161], grad_fn=<SliceBackward0>)\n",
            "total_loss 303.30010986328125\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0093,  0.0659,  0.1165, -0.1022,  0.1538, -0.3108, -0.0692,  0.0974,\n",
            "        -0.1026,  0.0924], grad_fn=<SliceBackward0>)\n",
            "total_loss 317.9201354980469\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2595,  0.1238,  0.0020,  0.0165,  0.1874, -0.0929,  0.1695,  0.0859,\n",
            "         0.0405, -0.0040], grad_fn=<SliceBackward0>)\n",
            "total_loss 284.6129150390625\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2286,  0.1017,  0.1324, -0.1713, -0.0625, -0.0390, -0.0474,  0.0762,\n",
            "         0.1593,  0.0021], grad_fn=<SliceBackward0>)\n",
            "total_loss 260.20819091796875\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1622,  0.1226,  0.1325, -0.1681, -0.1089, -0.0943,  0.1811, -0.0014,\n",
            "         0.1610, -0.0425], grad_fn=<SliceBackward0>)\n",
            "total_loss 195.95001220703125\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2104,  0.1123,  0.1170, -0.1798, -0.0671, -0.0584, -0.0887,  0.1004,\n",
            "         0.1801,  0.0521], grad_fn=<SliceBackward0>)\n",
            "total_loss 114.19096374511719\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1530, -0.0245,  0.1037, -0.2400, -0.0869, -0.2095, -0.0185, -0.0662,\n",
            "         0.0184,  0.0964], grad_fn=<SliceBackward0>)\n",
            "total_loss 38.53239822387695\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1210,  0.1959,  0.1322, -0.1492,  0.0015, -0.3147, -0.0085,  0.0677,\n",
            "         0.1940,  0.2503], grad_fn=<SliceBackward0>)\n",
            "total_loss 139.17340087890625\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1880,  0.1360,  0.1020, -0.1943, -0.0656, -0.0901, -0.1550,  0.1426,\n",
            "         0.2153,  0.1447], grad_fn=<SliceBackward0>)\n",
            "total_loss 124.14813232421875\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0794,  0.0277, -0.1681, -0.2662,  0.1591, -0.3244,  0.0465, -0.0147,\n",
            "         0.1830,  0.3467])\n",
            "total_loss 61.232826232910156\n",
            "Saving model (epoch =    1, loss = 61.2328)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0169,  0.2574, -0.2061, -0.0603, -0.0795, -0.0449, -0.1976,  0.2487,\n",
            "         0.1799,  0.2029], grad_fn=<SliceBackward0>)\n",
            "total_loss 53.6312370300293\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0122,  0.1161,  0.0206, -0.1206, -0.0134, -0.1264, -0.0230,  0.1477,\n",
            "         0.0079,  0.2302], grad_fn=<SliceBackward0>)\n",
            "total_loss 54.151710510253906\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1060,  0.0204,  0.0249, -0.2426, -0.0787, -0.2580, -0.1625, -0.0148,\n",
            "         0.2172,  0.2935], grad_fn=<SliceBackward0>)\n",
            "total_loss 67.07795715332031\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0538,  0.2282, -0.2327, -0.0321, -0.1080, -0.0096, -0.2192,  0.2378,\n",
            "         0.1664,  0.1854], grad_fn=<SliceBackward0>)\n",
            "total_loss 70.03916931152344\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0357,  0.1035, -0.0591, -0.2023,  0.1129, -0.1193, -0.1930,  0.1374,\n",
            "        -0.0280,  0.1316], grad_fn=<SliceBackward0>)\n",
            "total_loss 65.9227294921875\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0921, -0.0459,  0.0580, -0.2087, -0.1186, -0.1701, -0.0925, -0.0574,\n",
            "         0.0161,  0.1477], grad_fn=<SliceBackward0>)\n",
            "total_loss 34.11891174316406\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1266,  0.1056, -0.0132, -0.1958,  0.0981, -0.0338, -0.0044, -0.0447,\n",
            "         0.0733,  0.1934], grad_fn=<SliceBackward0>)\n",
            "total_loss 38.933170318603516\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1510,  0.1015, -0.1616,  0.0791, -0.1012, -0.0107, -0.1994,  0.0637,\n",
            "         0.0930,  0.2770], grad_fn=<SliceBackward0>)\n",
            "total_loss 70.8718490600586\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1721, -0.0386, -0.0682, -0.1872,  0.0137, -0.0040, -0.1074, -0.0079,\n",
            "         0.0222,  0.0785], grad_fn=<SliceBackward0>)\n",
            "total_loss 30.59668731689453\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0439,  0.0146, -0.1776, -0.2294,  0.1314, -0.2693,  0.0110, -0.0263,\n",
            "         0.1439,  0.3818])\n",
            "total_loss 15.802349090576172\n",
            "Saving model (epoch =    2, loss = 15.8023)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1124,  0.0549, -0.0855, -0.0869,  0.0522, -0.2170,  0.0395,  0.1606,\n",
            "         0.1788,  0.1570], grad_fn=<SliceBackward0>)\n",
            "total_loss 17.543373107910156\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0995,  0.1136, -0.1106,  0.0410,  0.0594, -0.0366, -0.0787,  0.1164,\n",
            "         0.0282,  0.3380], grad_fn=<SliceBackward0>)\n",
            "total_loss 24.305187225341797\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0303,  0.1200, -0.0380, -0.1984,  0.1127, -0.1032, -0.2081,  0.1331,\n",
            "        -0.0549,  0.1904], grad_fn=<SliceBackward0>)\n",
            "total_loss 37.93798065185547\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0420,  0.0108, -0.0856, -0.0342, -0.1402, -0.0405, -0.1408,  0.0543,\n",
            "         0.1133,  0.1156], grad_fn=<SliceBackward0>)\n",
            "total_loss 34.74352264404297\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0480, -0.0386, -0.1398,  0.0723,  0.0483, -0.0690,  0.0206,  0.1007,\n",
            "         0.0160,  0.1883], grad_fn=<SliceBackward0>)\n",
            "total_loss 26.095699310302734\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1649, -0.0271, -0.0522, -0.1866,  0.0138,  0.0115, -0.1091, -0.0183,\n",
            "         0.0004,  0.1100], grad_fn=<SliceBackward0>)\n",
            "total_loss 14.8304443359375\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0202,  0.1367,  0.0464, -0.0979, -0.0261, -0.0758, -0.0483,  0.1402,\n",
            "        -0.0482,  0.3142], grad_fn=<SliceBackward0>)\n",
            "total_loss 19.73720932006836\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1170,  0.1063,  0.0214, -0.1938,  0.1210, -0.0667, -0.1223, -0.0310,\n",
            "        -0.0340,  0.3322], grad_fn=<SliceBackward0>)\n",
            "total_loss 26.036149978637695\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.1288,  0.0457, -0.0141,  0.0751, -0.0995, -0.1408, -0.0645,  0.2258,\n",
            "         0.0035,  0.1310], grad_fn=<SliceBackward0>)\n",
            "total_loss 18.95905876159668\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0555,  0.0469, -0.1479, -0.2419,  0.1405, -0.2566,  0.0135, -0.0273,\n",
            "         0.1165,  0.4318])\n",
            "total_loss 15.081939697265625\n",
            "Saving model (epoch =    3, loss = 15.0819)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.1328,  0.0464, -0.0130,  0.0740, -0.1013, -0.1401, -0.0665,  0.2251,\n",
            "         0.0018,  0.1309], grad_fn=<SliceBackward0>)\n",
            "total_loss 16.184127807617188\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0860,  0.0511,  0.0818, -0.0984, -0.0372,  0.0085,  0.0735, -0.0454,\n",
            "        -0.1318,  0.2322], grad_fn=<SliceBackward0>)\n",
            "total_loss 20.04759979248047\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0990, -0.0006, -0.0309,  0.0220,  0.0301, -0.0545,  0.0586,  0.2002,\n",
            "         0.0804,  0.0971], grad_fn=<SliceBackward0>)\n",
            "total_loss 18.74087142944336\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.1107,  0.0091,  0.0456,  0.0232,  0.0959, -0.2609,  0.0382, -0.0575,\n",
            "        -0.1099,  0.2303], grad_fn=<SliceBackward0>)\n",
            "total_loss 13.39966869354248\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1376,  0.1482,  0.0274, -0.2174,  0.1077, -0.0175, -0.0117, -0.0510,\n",
            "         0.0232,  0.2805], grad_fn=<SliceBackward0>)\n",
            "total_loss 11.85885238647461\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0990,  0.1646,  0.1210, -0.1676, -0.1276, -0.0536,  0.0618,  0.0235,\n",
            "         0.1263,  0.1740], grad_fn=<SliceBackward0>)\n",
            "total_loss 16.5845890045166\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1684,  0.1439, -0.1293,  0.0524, -0.0891,  0.0031, -0.2042,  0.0590,\n",
            "         0.0423,  0.3579], grad_fn=<SliceBackward0>)\n",
            "total_loss 14.65298843383789\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1954,  0.0093, -0.0379, -0.2229,  0.0293,  0.0011, -0.1110, -0.0079,\n",
            "        -0.0227,  0.1586], grad_fn=<SliceBackward0>)\n",
            "total_loss 10.532912254333496\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1744,  0.1489, -0.1292,  0.0504, -0.0872,  0.0033, -0.2028,  0.0605,\n",
            "         0.0402,  0.3630], grad_fn=<SliceBackward0>)\n",
            "total_loss 8.426688194274902\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0918,  0.0758, -0.1391, -0.2753,  0.1602, -0.2691,  0.0156, -0.0174,\n",
            "         0.0992,  0.4768])\n",
            "total_loss 9.85171127319336\n",
            "Saving model (epoch =    4, loss = 9.8517)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0703,  0.0197, -0.0269,  0.0018,  0.0440, -0.0598,  0.0630,  0.2057,\n",
            "         0.0671,  0.1264], grad_fn=<SliceBackward0>)\n",
            "total_loss 10.46373176574707\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0412,  0.1773, -0.0777, -0.0017,  0.0895, -0.0377, -0.0709,  0.1295,\n",
            "        -0.0109,  0.4264], grad_fn=<SliceBackward0>)\n",
            "total_loss 10.27711296081543\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2073,  0.0182, -0.0375, -0.2285,  0.0341, -0.0005, -0.1083, -0.0055,\n",
            "        -0.0271,  0.1706], grad_fn=<SliceBackward0>)\n",
            "total_loss 10.982135772705078\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0142,  0.1909, -0.0305, -0.1562,  0.0948, -0.0759,  0.0400,  0.1756,\n",
            "         0.0911,  0.1911], grad_fn=<SliceBackward0>)\n",
            "total_loss 9.736695289611816\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1721,  0.1344,  0.0162, -0.0325,  0.0205, -0.0440, -0.0808, -0.0389,\n",
            "        -0.1596,  0.3708], grad_fn=<SliceBackward0>)\n",
            "total_loss 7.4417314529418945\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0300,  0.0766, -0.0602, -0.0901, -0.1022, -0.0512, -0.1279,  0.0675,\n",
            "         0.0734,  0.2097], grad_fn=<SliceBackward0>)\n",
            "total_loss 7.664210319519043\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0588,  0.1225, -0.0714, -0.2578,  0.0700, -0.1955, -0.2424,  0.2298,\n",
            "        -0.1620,  0.4864], grad_fn=<SliceBackward0>)\n",
            "total_loss 9.290635108947754\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1165,  0.2003, -0.0046, -0.2671,  0.1554, -0.1236, -0.1965,  0.1542,\n",
            "        -0.0991,  0.3094], grad_fn=<SliceBackward0>)\n",
            "total_loss 9.330306053161621\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2398,  0.1206,  0.0999, -0.1080,  0.0213, -0.2481,  0.0477, -0.0321,\n",
            "         0.1407,  0.3027], grad_fn=<SliceBackward0>)\n",
            "total_loss 7.666090488433838\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1327,  0.0970, -0.1368, -0.3042,  0.1827, -0.2848,  0.0207, -0.0094,\n",
            "         0.0837,  0.5196])\n",
            "total_loss 7.355422496795654\n",
            "Saving model (epoch =    5, loss = 7.3554)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0433,  0.1731, -0.0321, -0.1671,  0.1498, -0.1175, -0.1666,  0.0831,\n",
            "         0.1071,  0.1168], grad_fn=<SliceBackward0>)\n",
            "total_loss 7.6469879150390625\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1488,  0.2486,  0.1368, -0.1681,  0.0126, -0.2555, -0.0542,  0.0674,\n",
            "         0.1019,  0.4179], grad_fn=<SliceBackward0>)\n",
            "total_loss 6.650484085083008\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0357,  0.1764, -0.0322, -0.1717,  0.1539, -0.1204, -0.1656,  0.0844,\n",
            "         0.1041,  0.1243], grad_fn=<SliceBackward0>)\n",
            "total_loss 7.618752956390381\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0570,  0.0893, -0.0605, -0.1076, -0.0872, -0.0611, -0.1246,  0.0723,\n",
            "         0.0630,  0.2366], grad_fn=<SliceBackward0>)\n",
            "total_loss 5.849908828735352\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2068,  0.0635,  0.1187, -0.2996, -0.0461, -0.1855, -0.0737, -0.0540,\n",
            "        -0.0713,  0.3615], grad_fn=<SliceBackward0>)\n",
            "total_loss 7.4173970222473145\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1706,  0.3153, -0.0462, -0.0439,  0.1931, -0.0610,  0.0652,  0.2366,\n",
            "        -0.0684,  0.3234], grad_fn=<SliceBackward0>)\n",
            "total_loss 6.889554977416992\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1185,  0.2591,  0.1491, -0.0645,  0.1986, -0.2851,  0.0113,  0.1549,\n",
            "        -0.1543,  0.5362], grad_fn=<SliceBackward0>)\n",
            "total_loss 6.034191131591797\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2070,  0.1208,  0.0950, -0.1767,  0.0248, -0.0327,  0.0917, -0.0200,\n",
            "        -0.1745,  0.3592], grad_fn=<SliceBackward0>)\n",
            "total_loss 5.9490838050842285\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2549,  0.1904, -0.1256, -0.0024, -0.0442, -0.0290, -0.1900,  0.0755,\n",
            "         0.0110,  0.4503], grad_fn=<SliceBackward0>)\n",
            "total_loss 5.676762580871582\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 1.7925e-01,  1.2023e-01, -1.3301e-01, -3.3767e-01,  2.0780e-01,\n",
            "        -3.0937e-01,  2.8127e-02,  6.1244e-05,  6.7825e-02,  5.7565e-01])\n",
            "total_loss 6.050445079803467\n",
            "Saving model (epoch =    6, loss = 6.0504)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2420,  0.2066,  0.0355, -0.2875,  0.1616, -0.0581,  0.0048, -0.0305,\n",
            "        -0.0134,  0.3952], grad_fn=<SliceBackward0>)\n",
            "total_loss 6.3514628410339355\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0878,  0.1054, -0.0572, -0.1336, -0.0698, -0.0798, -0.1195,  0.0775,\n",
            "         0.0515,  0.2777], grad_fn=<SliceBackward0>)\n",
            "total_loss 6.785539627075195\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2452,  0.1721,  0.0221, -0.0858,  0.0601, -0.0808, -0.0705, -0.0244,\n",
            "        -0.1848,  0.4588], grad_fn=<SliceBackward0>)\n",
            "total_loss 5.296441078186035\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2710,  0.3549, -0.0906, -0.1908,  0.0135, -0.0369, -0.2052,  0.0909,\n",
            "        -0.1007,  0.2617], grad_fn=<SliceBackward0>)\n",
            "total_loss 5.457340240478516\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2037,  0.1333, -0.1297, -0.3543,  0.2210, -0.3238,  0.0342,  0.0043,\n",
            "         0.0597,  0.6095], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.9892897605896\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2061,  0.1086,  0.1213, -0.0433,  0.0898, -0.3353, -0.0397,  0.0996,\n",
            "         0.0384,  0.3178], grad_fn=<SliceBackward0>)\n",
            "total_loss 6.050326347351074\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0557,  0.0969, -0.1380, -0.1158,  0.1906, -0.2881, -0.0708,  0.0613,\n",
            "        -0.1879,  0.5249], grad_fn=<SliceBackward0>)\n",
            "total_loss 5.747152328491211\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0077,  0.0356, -0.0645, -0.0497, -0.0388, -0.1216, -0.0689, -0.0250,\n",
            "        -0.0135,  0.3857], grad_fn=<SliceBackward0>)\n",
            "total_loss 5.516992092132568\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([-0.0052,  0.0371, -0.0640, -0.0524, -0.0375, -0.1239, -0.0685, -0.0245,\n",
            "        -0.0145,  0.3901], grad_fn=<SliceBackward0>)\n",
            "total_loss 5.003939628601074\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2224,  0.1440, -0.1270, -0.3697,  0.2308, -0.3370,  0.0387,  0.0075,\n",
            "         0.0530,  0.6381])\n",
            "total_loss 5.2157111167907715\n",
            "Saving model (epoch =    7, loss = 5.2157)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3197,  0.0771, -0.0279, -0.3129,  0.0957, -0.0619, -0.0893,  0.0151,\n",
            "        -0.0687,  0.3119], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.444748401641846\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2380,  0.3526, -0.0368, -0.0960,  0.2300, -0.1037,  0.0809,  0.2478,\n",
            "        -0.0920,  0.4204], grad_fn=<SliceBackward0>)\n",
            "total_loss 5.016007423400879\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0687,  0.1113,  0.0713, -0.1107,  0.1899, -0.3547,  0.0652, -0.0188,\n",
            "        -0.1712,  0.4556], grad_fn=<SliceBackward0>)\n",
            "total_loss 5.140204429626465\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1922,  0.3102,  0.1521, -0.2428,  0.2228, -0.2504,  0.0022,  0.1428,\n",
            "        -0.1526,  0.3763], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.764037609100342\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1984,  0.3140,  0.1533, -0.2478,  0.2261, -0.2548,  0.0037,  0.1438,\n",
            "        -0.1547,  0.3860], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.394566535949707\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3182,  0.2509,  0.0486, -0.3471,  0.2022, -0.1107,  0.0224, -0.0166,\n",
            "        -0.0392,  0.5104], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.8921685218811035\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2528,  0.1367,  0.1298, -0.0824,  0.1140, -0.3699, -0.0291,  0.1083,\n",
            "         0.0218,  0.3910], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.448229789733887\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2558,  0.1385,  0.1303, -0.0850,  0.1156, -0.3722, -0.0283,  0.1087,\n",
            "         0.0207,  0.3957], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.000957012176514\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0475,  0.1558,  0.0096, -0.0716, -0.0012, -0.2335, -0.0305,  0.2527,\n",
            "        -0.0730,  0.3700], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.708391189575195\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2643,  0.1696, -0.1190, -0.4047,  0.2531, -0.3680,  0.0491,  0.0146,\n",
            "         0.0382,  0.7039])\n",
            "total_loss 4.282058238983154\n",
            "Saving model (epoch =    8, loss = 4.2821)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1439,  0.3095,  0.0206, -0.3006,  0.0901, -0.1252,  0.0197,  0.1091,\n",
            "        -0.0173,  0.7241], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.392759799957275\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3168,  0.2318,  0.0530, -0.3531,  0.2284, -0.1743, -0.0862,  0.0071,\n",
            "        -0.1137,  0.6064], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.222677230834961\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.0452,  0.0682, -0.0538, -0.0962, -0.0105, -0.1626, -0.0560, -0.0169,\n",
            "        -0.0332,  0.4720], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.351138114929199\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2595,  0.2827,  0.0144, -0.3788,  0.2306, -0.2169, -0.1651,  0.1807,\n",
            "        -0.1501,  0.5151], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.3310346603393555\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2968,  0.3334,  0.1602, -0.2827,  0.0921, -0.3531, -0.0198,  0.0939,\n",
            "         0.0512,  0.6358], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.905691623687744\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3658,  0.4110, -0.0735, -0.2707,  0.0647, -0.1049, -0.1822,  0.1044,\n",
            "        -0.1367,  0.4062], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.321869850158691\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1346,  0.1534,  0.0864, -0.1689,  0.2254, -0.4066,  0.0811, -0.0064,\n",
            "        -0.1935,  0.5643], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.157679080963135\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3874,  0.2694, -0.1022, -0.1088,  0.0298, -0.1211, -0.1558,  0.0964,\n",
            "        -0.0336,  0.6546], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.868891477584839\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2978,  0.1921, -0.1116, -0.4337,  0.2709, -0.3946,  0.0592,  0.0202,\n",
            "         0.0272,  0.7612], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.811541795730591\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3005,  0.1940, -0.1110, -0.4362,  0.2724, -0.3970,  0.0600,  0.0206,\n",
            "         0.0264,  0.7661])\n",
            "total_loss 3.940115213394165\n",
            "Saving model (epoch =    9, loss = 3.9401)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2647,  0.3571,  0.1677, -0.3072,  0.2627, -0.3066,  0.0228,  0.1541,\n",
            "        -0.1784,  0.4973], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.116989612579346\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3054,  0.1714,  0.1410, -0.1283,  0.1419, -0.4118, -0.0139,  0.1171,\n",
            "         0.0038,  0.4803], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.135466575622559\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1769,  0.2999, -0.0494, -0.1637,  0.2044, -0.1701, -0.0261,  0.1712,\n",
            "        -0.0880,  0.7263], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.117825508117676\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3654,  0.2652,  0.0647, -0.3963,  0.2546, -0.2136, -0.0711,  0.0147,\n",
            "        -0.1293,  0.6920], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.9050393104553223\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 3.8348e-01,  2.5887e-01,  4.9593e-02, -2.0086e-01,  1.3441e-01,\n",
            "        -1.8306e-01, -3.4486e-02, -2.2531e-04, -2.3084e-01,  6.8274e-01],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "total_loss 3.5826117992401123\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3389,  0.3622,  0.1703, -0.3197,  0.1147, -0.3874, -0.0074,  0.1015,\n",
            "         0.0381,  0.7108], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.409298896789551\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2321,  0.1950, -0.0288, -0.2553,  0.0082, -0.1870, -0.0809,  0.0998,\n",
            "         0.0011,  0.5117], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.6818766593933105\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4220,  0.2037,  0.1644, -0.4864,  0.0683, -0.3523, -0.0147, -0.0185,\n",
            "        -0.1418,  0.7182], grad_fn=<SliceBackward0>)\n",
            "total_loss 4.015340805053711\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3930,  0.2464, -0.0208, -0.3111,  0.2080, -0.3549,  0.0977,  0.1991,\n",
            "         0.0490,  0.5691], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.3821563720703125\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3289,  0.2136, -0.1039, -0.4623,  0.2875, -0.4206,  0.0684,  0.0248,\n",
            "         0.0178,  0.8168])\n",
            "total_loss 3.5951151847839355\n",
            "Saving model (epoch =   10, loss = 3.5951)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3375,  0.3896,  0.1924, -0.2336,  0.3134, -0.4347,  0.0678,  0.1917,\n",
            "        -0.2266,  0.8708], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.511481285095215\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2485,  0.3783,  0.0453, -0.3885,  0.1450, -0.2060,  0.0513,  0.1249,\n",
            "        -0.0516,  0.9023], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.88393235206604\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4248,  0.2316, -0.0009, -0.4294,  0.1435, -0.3381, -0.1813,  0.1862,\n",
            "        -0.1114,  0.6436], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.7276997566223145\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3652,  0.4360, -0.0088, -0.2047,  0.2981, -0.2019,  0.1171,  0.2686,\n",
            "        -0.1338,  0.6359], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.8950154781341553\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3955,  0.2373,  0.1127, -0.4657,  0.0693, -0.3955, -0.1250,  0.0349,\n",
            "         0.0576,  0.8042], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.060354709625244\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3049,  0.1377,  0.0029, -0.3353,  0.1513, -0.1647,  0.0608,  0.1258,\n",
            "        -0.1711,  0.6609], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.836759567260742\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2960,  0.3393,  0.1118, -0.3646,  0.1439, -0.2768,  0.0103,  0.2034,\n",
            "        -0.1681,  0.7873], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.4952826499938965\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2641,  0.2170, -0.0203, -0.2843,  0.0248, -0.2139, -0.0718,  0.1050,\n",
            "        -0.0084,  0.5709], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.1104202270507812\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4197,  0.2651, -0.0138, -0.3352,  0.2219, -0.3776,  0.1050,  0.2035,\n",
            "         0.0414,  0.6190], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.436038017272949\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3536,  0.2308, -0.0972, -0.4841,  0.3002, -0.4415,  0.0757,  0.0289,\n",
            "         0.0113,  0.8631])\n",
            "total_loss 3.373117446899414\n",
            "Saving model (epoch =   11, loss = 3.3731)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3565,  0.1637, -0.0762, -0.1706,  0.2201, -0.2418,  0.0903,  0.1553,\n",
            "        -0.0958,  0.6412], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.5253946781158447\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6339,  0.4313,  0.0645, -0.2617,  0.3705, -0.3190,  0.0783,  0.2679,\n",
            "        -0.0960,  0.8147], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.720150947570801\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2177,  0.2021, -0.1018, -0.2563,  0.2777, -0.4135, -0.0263,  0.0875,\n",
            "        -0.2407,  0.7993], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.302501916885376\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3531,  0.3472,  0.0375, -0.4626,  0.2795, -0.2946, -0.1376,  0.1965,\n",
            "        -0.1789,  0.6844], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.108520984649658\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6442,  0.4382,  0.0675, -0.2705,  0.3758, -0.3271,  0.0810,  0.2696,\n",
            "        -0.0989,  0.8335], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.1686503887176514\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.1657,  0.2357,  0.0393, -0.1764,  0.0621, -0.3287,  0.0036,  0.2712,\n",
            "        -0.1097,  0.5801], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.297633409500122\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3699,  0.2417, -0.0925, -0.4978,  0.3085, -0.4546,  0.0802,  0.0317,\n",
            "         0.0074,  0.8932], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.2981555461883545\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4130,  0.2516,  0.1390, -0.3516,  0.1350, -0.1891,  0.1455,  0.0147,\n",
            "        -0.2411,  0.7026], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.4627420902252197\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4542,  0.3067,  0.0686, -0.2633,  0.1715, -0.2404, -0.0152,  0.0115,\n",
            "        -0.2507,  0.8118], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.221205711364746\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3734,  0.2440, -0.0915, -0.5009,  0.3105, -0.4576,  0.0811,  0.0322,\n",
            "         0.0068,  0.9001])\n",
            "total_loss 3.195591449737549\n",
            "Saving model (epoch =   12, loss = 3.1956)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4421,  0.2801, -0.0073, -0.3549,  0.2338, -0.3961,  0.1106,  0.2069,\n",
            "         0.0358,  0.6610], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.201404571533203\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4565,  0.3081,  0.0692, -0.2651,  0.1728, -0.2422, -0.0145,  0.0118,\n",
            "        -0.2511,  0.8160], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.1951537132263184\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4639,  0.2581,  0.0099, -0.4646,  0.1645, -0.3708, -0.1712,  0.1925,\n",
            "        -0.1211,  0.7170], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.0532584190368652\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4103,  0.3607,  0.1760, -0.4193,  0.0353, -0.2617,  0.1401,  0.0781,\n",
            "         0.0227,  0.6539], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.2064850330352783\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3875,  0.1839, -0.0679, -0.1963,  0.2374, -0.2653,  0.0988,  0.1596,\n",
            "        -0.1039,  0.6977], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.2095532417297363\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3380,  0.3674,  0.1241, -0.4015,  0.1667, -0.3109,  0.0211,  0.2103,\n",
            "        -0.1790,  0.8657], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.2709710597991943\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3356,  0.4365,  0.0694, -0.4616,  0.1897, -0.2738,  0.0769,  0.1381,\n",
            "        -0.0770,  1.0600], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.1755425930023193\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4311,  0.2636,  0.1440, -0.3668,  0.1447, -0.2030,  0.1507,  0.0172,\n",
            "        -0.2456,  0.7364], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.8338265419006348\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3423,  0.4410,  0.0713, -0.4671,  0.1931, -0.2789,  0.0788,  0.1392,\n",
            "        -0.0787,  1.0726], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.255171060562134\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3888,  0.2542, -0.0873, -0.5132,  0.3185, -0.4694,  0.0858,  0.0343,\n",
            "         0.0037,  0.9293])\n",
            "total_loss 3.065347909927368\n",
            "Saving model (epoch =   13, loss = 3.0653)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4789,  0.2681,  0.0142, -0.4772,  0.1723, -0.3824, -0.1672,  0.1948,\n",
            "        -0.1246,  0.7453], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.2897677421569824\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4362,  0.2670,  0.1455, -0.3709,  0.1473, -0.2071,  0.1521,  0.0181,\n",
            "        -0.2466,  0.7465], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.047299385070801\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6767,  0.4596,  0.0767, -0.2976,  0.3930, -0.3526,  0.0898,  0.2746,\n",
            "        -0.1067,  0.8946], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.0003604888916016\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3989,  0.4479,  0.2046, -0.4285,  0.3339, -0.4150,  0.0606,  0.1752,\n",
            "        -0.2191,  0.7417], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.2269208431243896\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5891,  0.3390,  0.1644, -0.3803,  0.1965, -0.5003,  0.1386,  0.0315,\n",
            "         0.0362,  0.8624], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.094050645828247\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3013,  0.3627,  0.0197, -0.3828,  0.2518, -0.2672,  0.1137,  0.2200,\n",
            "        -0.0040,  0.6368], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.9668500423431396\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4012,  0.3789,  0.0513, -0.5030,  0.3043, -0.3321, -0.1242,  0.2041,\n",
            "        -0.1911,  0.7751], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7692699432373047\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3053,  0.3652,  0.0209, -0.3860,  0.2539, -0.2699,  0.1148,  0.2204,\n",
            "        -0.0052,  0.6440], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.019787311553955\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2728,  0.2381, -0.0856, -0.3029,  0.3071, -0.4554, -0.0114,  0.0959,\n",
            "        -0.2545,  0.9022], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.0604586601257324\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3974,  0.2594, -0.0849, -0.5195,  0.3232, -0.4757,  0.0882,  0.0356,\n",
            "         0.0024,  0.9461])\n",
            "total_loss 2.9355175495147705\n",
            "Saving model (epoch =   14, loss = 2.9355)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2169,  0.2687,  0.0533, -0.2161,  0.0884, -0.3672,  0.0163,  0.2815,\n",
            "        -0.1212,  0.6754], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7779088020324707\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4134,  0.2005, -0.0604, -0.2171,  0.2519, -0.2841,  0.1058,  0.1632,\n",
            "        -0.1099,  0.7466], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7276344299316406\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4660,  0.3322,  0.0926, -0.4834,  0.3092, -0.2928, -0.0424,  0.0285,\n",
            "        -0.1564,  0.8773], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.91281795501709\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5364,  0.3911,  0.1827, -0.4596,  0.1125, -0.2471, -0.1162,  0.2044,\n",
            "         0.0278,  0.7961], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.0282862186431885\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4164,  0.2024, -0.0597, -0.2191,  0.2535, -0.2863,  0.1066,  0.1637,\n",
            "        -0.1102,  0.7524], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.1193227767944336\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4417,  0.3806,  0.1850, -0.4441,  0.0522, -0.2849,  0.1482,  0.0832,\n",
            "         0.0158,  0.7132], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.90299129486084\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2292,  0.2948,  0.1219, -0.3307,  0.2765, -0.4725, -0.1624,  0.2033,\n",
            "        -0.2242,  0.7906], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.997727870941162\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5134,  0.3821,  0.0991, -0.5171,  0.3051, -0.2672,  0.0762,  0.0161,\n",
            "        -0.0954,  0.8649], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.970860719680786\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4766,  0.2905,  0.1361, -0.5343,  0.1122, -0.4584, -0.1032,  0.0471,\n",
            "         0.0373,  0.9564], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.280456066131592\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4072,  0.2660, -0.0825, -0.5264,  0.3281, -0.4830,  0.0909,  0.0374,\n",
            "         0.0010,  0.9653])\n",
            "total_loss 2.8843865394592285\n",
            "Saving model (epoch =   15, loss = 2.8844)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4669,  0.2871,  0.1544, -0.3957,  0.1630, -0.2299,  0.1605,  0.0230,\n",
            "        -0.2544,  0.8052], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.926060676574707\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4792,  0.3045,  0.0032, -0.3851,  0.2535, -0.4249,  0.1204,  0.2121,\n",
            "         0.0279,  0.7334], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.950662136077881\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2359,  0.2812,  0.0580, -0.2295,  0.0977, -0.3810,  0.0211,  0.2858,\n",
            "        -0.1249,  0.7112], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.872891426086426\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3199,  0.3747,  0.0246, -0.3967,  0.2619, -0.2801,  0.1190,  0.2224,\n",
            "        -0.0081,  0.6716], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.0879111289978027\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4618,  0.5004,  0.0178, -0.2844,  0.3482, -0.2760,  0.1446,  0.2837,\n",
            "        -0.1585,  0.8167], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.8025641441345215\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5045,  0.2845,  0.0210, -0.4969,  0.1858, -0.4010, -0.1606,  0.1985,\n",
            "        -0.1297,  0.7944], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.78574275970459\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4597,  0.4703,  0.2263, -0.3339,  0.3766, -0.5277,  0.1020,  0.2108,\n",
            "        -0.2588,  1.0958], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.9326658248901367\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4410,  0.4758,  0.2164, -0.4635,  0.3556, -0.4461,  0.0721,  0.1815,\n",
            "        -0.2305,  0.8215], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.6720752716064453\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3915,  0.4733,  0.0849, -0.5064,  0.2178, -0.3151,  0.0928,  0.1466,\n",
            "        -0.0916,  1.1658], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.668084144592285\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 4.1413e-01,  2.7048e-01, -8.1120e-02, -5.3103e-01,  3.3164e-01,\n",
            "        -4.8763e-01,  9.3009e-02,  3.8260e-02, -3.2178e-04,  9.7862e-01])\n",
            "total_loss 2.8733129501342773\n",
            "Saving model (epoch =   16, loss = 2.8733)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3228,  0.5053, -0.1157, -0.3309,  0.0932, -0.2166, -0.1455,  0.3008,\n",
            "        -0.0096,  0.8627], grad_fn=<SliceBackward0>)\n",
            "total_loss 3.0373661518096924\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3926,  0.4032,  0.1400, -0.4463,  0.1954, -0.3519,  0.0347,  0.2196,\n",
            "        -0.1926,  0.9707], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7191784381866455\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5271,  0.3911,  0.1023, -0.5272,  0.3122, -0.2766,  0.0803,  0.0176,\n",
            "        -0.0987,  0.8907], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.743356704711914\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5997,  0.3305,  0.2173, -0.6446,  0.1556, -0.5018,  0.0355,  0.0141,\n",
            "        -0.1852,  1.0672], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.664210319519043\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4116,  0.3409, -0.0045, -0.5351,  0.2545, -0.4439, -0.1571,  0.2961,\n",
            "        -0.2636,  1.0552], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.561079978942871\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6238,  0.3612,  0.1732, -0.4062,  0.2146, -0.5247,  0.1482,  0.0364,\n",
            "         0.0278,  0.9274], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.757171869277954\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4064,  0.2038,  0.0305, -0.4147,  0.2049, -0.2393,  0.0882,  0.1404,\n",
            "        -0.1955,  0.8494], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.894634246826172\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3097,  0.3866, -0.0150, -0.2730,  0.2707, -0.2740,  0.0090,  0.1929,\n",
            "        -0.1245,  0.9708], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7789039611816406\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2514,  0.3581,  0.0328, -0.4199,  0.3085, -0.3382, -0.0912,  0.1271,\n",
            "         0.0114,  0.6170], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.9714300632476807\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 4.1700e-01,  2.7191e-01, -8.1036e-02, -5.3165e-01,  3.3346e-01,\n",
            "        -4.8895e-01,  9.3798e-02,  3.8617e-02, -4.1804e-04,  9.8363e-01])\n",
            "total_loss 2.7175590991973877\n",
            "Saving model (epoch =   17, loss = 2.7176)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2623,  0.2985,  0.0640, -0.2480,  0.1105, -0.3992,  0.0280,  0.2914,\n",
            "        -0.1314,  0.7609], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.800349712371826\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4945,  0.3017,  0.1402, -0.5474,  0.1216, -0.4701, -0.0983,  0.0490,\n",
            "         0.0326,  0.9900], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5712544918060303\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2477,  0.3059,  0.1256, -0.3425,  0.2862, -0.4840, -0.1570,  0.2056,\n",
            "        -0.2289,  0.8255], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5649490356445312\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3225,  0.2790,  0.1409, -0.3358,  0.3236, -0.5600,  0.1289,  0.0264,\n",
            "        -0.2448,  0.9174], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7373440265655518\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4431,  0.4065,  0.0618, -0.5355,  0.3253, -0.3626, -0.1123,  0.2107,\n",
            "        -0.2019,  0.8565], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7269132137298584\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.7216,  0.4884,  0.0880, -0.3315,  0.4162, -0.3846,  0.1017,  0.2813,\n",
            "        -0.1177,  0.9803], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.485761880874634\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6319,  0.3660,  0.1752, -0.4121,  0.2188, -0.5300,  0.1503,  0.0373,\n",
            "         0.0254,  0.9428], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.877108573913574\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3186,  0.2477,  0.1595, -0.3933,  0.1780, -0.2692, -0.0315,  0.0185,\n",
            "        -0.0246,  0.9743], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.8845326900482178\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4993,  0.3529,  0.1003, -0.5069,  0.3272, -0.3141, -0.0333,  0.0320,\n",
            "        -0.1654,  0.9380], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7162327766418457\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4215,  0.2745, -0.0802, -0.5345,  0.3358, -0.4916,  0.0950,  0.0389,\n",
            "        -0.0017,  0.9919])\n",
            "total_loss 2.6658501625061035\n",
            "Saving model (epoch =   18, loss = 2.6659)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5252,  0.2976,  0.0259, -0.5127,  0.1964, -0.4151, -0.1551,  0.2011,\n",
            "        -0.1356,  0.8340], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.600001335144043\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3538,  0.2748,  0.0048, -0.3590,  0.0724, -0.2808, -0.0468,  0.1156,\n",
            "        -0.0322,  0.7407], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.639315128326416\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4751,  0.4525,  0.2077, -0.4333,  0.1868, -0.4922,  0.0307,  0.1220,\n",
            "         0.0023,  0.9680], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7225823402404785\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2629,  0.3652,  0.0355, -0.4285,  0.3143, -0.3457, -0.0881,  0.1284,\n",
            "         0.0078,  0.6389], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.706835985183716\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4533,  0.2686,  0.1803, -0.2518,  0.2188, -0.5269,  0.0260,  0.1402,\n",
            "        -0.0360,  0.7562], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.6871135234832764\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5664,  0.2383,  0.0331, -0.5212,  0.2262, -0.2514, -0.0223,  0.0543,\n",
            "        -0.1413,  0.7532], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.463775396347046\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4239,  0.2759, -0.0799, -0.5357,  0.3370, -0.4929,  0.0956,  0.0394,\n",
            "        -0.0021,  0.9966], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5761613845825195\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4992,  0.5251,  0.0269, -0.3135,  0.3663, -0.3023,  0.1549,  0.2900,\n",
            "        -0.1692,  0.8903], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.622751235961914\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6407,  0.3714,  0.1772, -0.4189,  0.2233, -0.5354,  0.1525,  0.0383,\n",
            "         0.0224,  0.9595], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.67323637008667\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4280,  0.2786, -0.0790, -0.5391,  0.3388, -0.4957,  0.0967,  0.0402,\n",
            "        -0.0034,  1.0046])\n",
            "total_loss 2.643550395965576\n",
            "Saving model (epoch =   19, loss = 2.6436)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5499,  0.4057,  0.1075, -0.5447,  0.3237, -0.2915,  0.0867,  0.0202,\n",
            "        -0.1056,  0.9348], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7031283378601074\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5747,  0.2438,  0.0351, -0.5282,  0.2300, -0.2573, -0.0201,  0.0559,\n",
            "        -0.1439,  0.7698], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.6823019981384277\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4350,  0.2223,  0.0380, -0.4379,  0.2187, -0.2586,  0.0956,  0.1440,\n",
            "        -0.2047,  0.9045], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.375753879547119\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3630,  0.2807,  0.0070, -0.3668,  0.0768, -0.2867, -0.0442,  0.1166,\n",
            "        -0.0354,  0.7586], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.809115171432495\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4857,  0.4594,  0.2103, -0.4422,  0.1919, -0.4991,  0.0337,  0.1233,\n",
            "        -0.0013,  0.9887], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.663515567779541\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5628,  0.3822, -0.0579, -0.2525,  0.1236, -0.2521, -0.1077,  0.1188,\n",
            "        -0.0824,  0.9748], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5446746349334717\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 4.3455e-01,  3.5480e-01,  9.8458e-04, -5.5282e-01,  2.6642e-01,\n",
            "        -4.5818e-01, -1.5123e-01,  2.9860e-01, -2.7104e-01,  1.0980e+00],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3695812225341797\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4597,  0.4171,  0.0658, -0.5492,  0.3334, -0.3731, -0.1076,  0.2123,\n",
            "        -0.2080,  0.8881], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.6463522911071777\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6394,  0.3575,  0.2280, -0.6787,  0.1745, -0.5307,  0.0467,  0.0199,\n",
            "        -0.1973,  1.1485], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.457977056503296\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4295,  0.2792, -0.0788, -0.5401,  0.3399, -0.4959,  0.0970,  0.0398,\n",
            "        -0.0043,  1.0063])\n",
            "total_loss 2.529289484024048\n",
            "Saving model (epoch =   20, loss = 2.5293)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4194,  0.4905,  0.0911, -0.5273,  0.2322, -0.3328,  0.1002,  0.1498,\n",
            "        -0.1002,  1.2181], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5986814498901367\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4781,  0.4022,  0.1930, -0.4694,  0.0718, -0.3066,  0.1576,  0.0871,\n",
            "         0.0052,  0.7788], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.6553397178649902\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4219,  0.4921,  0.0917, -0.5292,  0.2334, -0.3345,  0.1008,  0.1504,\n",
            "        -0.1010,  1.2232], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.7519073486328125\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3622,  0.5310, -0.1061, -0.3635,  0.1125, -0.2440, -0.1343,  0.3063,\n",
            "        -0.0229,  0.9416], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5799412727355957\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3635,  0.5318, -0.1058, -0.3646,  0.1131, -0.2449, -0.1340,  0.3066,\n",
            "        -0.0234,  0.9443], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3575398921966553\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3698,  0.2848,  0.0084, -0.3721,  0.0802, -0.2909, -0.0426,  0.1175,\n",
            "        -0.0381,  0.7714], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.562955379486084\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.7435,  0.5019,  0.0930, -0.3487,  0.4270, -0.3983,  0.1069,  0.2837,\n",
            "        -0.1255,  1.0212], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5401573181152344\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5143,  0.3134,  0.1448, -0.5629,  0.1317, -0.4820, -0.0934,  0.0506,\n",
            "         0.0253,  1.0269], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3226871490478516\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 2.5655e-01,  2.0875e-01,  2.3238e-04, -2.7360e-01,  9.9653e-02,\n",
            "        -3.2382e-01,  3.4366e-03,  1.4829e-02, -9.3402e-02,  8.6334e-01],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5034005641937256\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4317,  0.2799, -0.0787, -0.5404,  0.3410, -0.4966,  0.0972,  0.0403,\n",
            "        -0.0049,  1.0091])\n",
            "total_loss 2.530395984649658\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5131,  0.3252,  0.0104, -0.4094,  0.2709, -0.4464,  0.1287,  0.2157,\n",
            "         0.0176,  0.7968], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5040695667266846\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3466,  0.2935,  0.1467, -0.3546,  0.3355, -0.5751,  0.1348,  0.0293,\n",
            "        -0.2533,  0.9630], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5208048820495605\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5559,  0.3721,  0.0945, -0.3429,  0.2234, -0.3115,  0.0125,  0.0258,\n",
            "        -0.2786,  1.0028], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.385335683822632\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5694,  0.3852, -0.0570, -0.2558,  0.1270, -0.2553, -0.1067,  0.1195,\n",
            "        -0.0849,  0.9854], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5885560512542725\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4955,  0.4650,  0.2123, -0.4490,  0.1970, -0.5045,  0.0359,  0.1245,\n",
            "        -0.0049,  1.0063], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.4321515560150146\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5711,  0.3863, -0.0566, -0.2571,  0.1279, -0.2564, -0.1062,  0.1199,\n",
            "        -0.0855,  0.9890], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.6332976818084717\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5179,  0.3281,  0.0115, -0.4132,  0.2733, -0.4493,  0.1298,  0.2165,\n",
            "         0.0160,  0.8062], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1953792572021484\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5082,  0.4964,  0.0784, -0.2698,  0.2474, -0.3955, -0.1303,  0.2743,\n",
            "        -0.0749,  0.8055], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.427851438522339\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6501,  0.3756,  0.1790, -0.4244,  0.2287, -0.5391,  0.1542,  0.0391,\n",
            "         0.0187,  0.9744], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.762101888656616\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4363,  0.2826, -0.0780, -0.5433,  0.3433, -0.4990,  0.0982,  0.0413,\n",
            "        -0.0062,  1.0178])\n",
            "total_loss 2.572883129119873\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5503,  0.3131,  0.0314, -0.5321,  0.2086, -0.4306, -0.1489,  0.2047,\n",
            "        -0.1442,  0.8820], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.35386323928833\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4368,  0.2829, -0.0779, -0.5437,  0.3436, -0.4993,  0.0983,  0.0414,\n",
            "        -0.0064,  1.0187], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.4375483989715576\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3451,  0.2637,  0.1652, -0.4133,  0.1911, -0.2848, -0.0250,  0.0219,\n",
            "        -0.0339,  1.0237], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.493968963623047\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2654,  0.2142,  0.0021, -0.2804,  0.1041, -0.3289,  0.0056,  0.0162,\n",
            "        -0.0964,  0.8801], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.4935927391052246\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5952,  0.2561,  0.0391, -0.5428,  0.2401, -0.2693, -0.0153,  0.0591,\n",
            "        -0.1509,  0.8076], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.4678707122802734\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4769,  0.2829,  0.1854, -0.2700,  0.2308, -0.5409,  0.0316,  0.1433,\n",
            "        -0.0444,  0.8000], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.519329071044922\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.7502,  0.5056,  0.0942, -0.3531,  0.4308, -0.4015,  0.1082,  0.2844,\n",
            "        -0.1280,  1.0325], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.4483673572540283\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.7502,  0.5055,  0.0942, -0.3529,  0.4308, -0.4013,  0.1082,  0.2844,\n",
            "        -0.1280,  1.0323], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5692343711853027\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5587,  0.5339, -0.0260, -0.4311,  0.1654, -0.2482, -0.1331,  0.1308,\n",
            "        -0.1973,  0.7532], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.29850435256958\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4374,  0.2829, -0.0780, -0.5436,  0.3442, -0.4990,  0.0983,  0.0415,\n",
            "        -0.0065,  1.0189])\n",
            "total_loss 2.466007709503174\n",
            "Saving model (epoch =   23, loss = 2.4660)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3747,  0.2871,  0.0092, -0.3752,  0.0832, -0.2924, -0.0415,  0.1175,\n",
            "        -0.0402,  0.7792], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.4127368927001953\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4878,  0.4069,  0.1944, -0.4746,  0.0772, -0.3105,  0.1593,  0.0887,\n",
            "         0.0019,  0.7946], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.450242519378662\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5442,  0.3368,  0.1724, -0.4564,  0.2011, -0.2807,  0.1814,  0.0342,\n",
            "        -0.2798,  0.9539], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5065383911132812\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5577,  0.3178,  0.0328, -0.5379,  0.2124, -0.4349, -0.1472,  0.2059,\n",
            "        -0.1469,  0.8964], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.501936197280884\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3414,  0.4045, -0.0093, -0.2937,  0.2855, -0.2920,  0.0160,  0.1976,\n",
            "        -0.1357,  1.0284], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.411670207977295\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5688,  0.4167,  0.1111, -0.5582,  0.3336, -0.3014,  0.0911,  0.0222,\n",
            "        -0.1125,  0.9685], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3141937255859375\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2965,  0.3859,  0.0423, -0.4535,  0.3309, -0.3660, -0.0801,  0.1341,\n",
            "        -0.0039,  0.7024], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3172428607940674\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4827,  0.2865,  0.1864, -0.2742,  0.2338, -0.5440,  0.0327,  0.1446,\n",
            "        -0.0461,  0.8111], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3965535163879395\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4878,  0.2486, -0.0433, -0.2747,  0.2911, -0.3320,  0.1264,  0.1732,\n",
            "        -0.1312,  0.8905], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3820223808288574\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4417,  0.2855, -0.0773, -0.5468,  0.3464, -0.5013,  0.0991,  0.0424,\n",
            "        -0.0080,  1.0269])\n",
            "total_loss 2.360837459564209\n",
            "Saving model (epoch =   24, loss = 2.3608)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3852,  0.5457, -0.1015, -0.3822,  0.1238, -0.2584, -0.1287,  0.3104,\n",
            "        -0.0312,  0.9878], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3460588455200195\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4845,  0.4325,  0.0704, -0.5676,  0.3455, -0.3879, -0.1016,  0.2172,\n",
            "        -0.2164,  0.9365], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.426422119140625\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4845,  0.4325,  0.0703, -0.5673,  0.3455, -0.3878, -0.1016,  0.2172,\n",
            "        -0.2164,  0.9363], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.4929604530334473\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 4.9228e-01,  4.0953e-01,  1.9505e-01, -4.7728e-01,  7.9616e-02,\n",
            "        -3.1252e-01,  1.6019e-01,  8.9578e-02,  5.2252e-04,  8.0243e-01],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "total_loss 2.505295753479004\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4860,  0.2886,  0.1868, -0.2763,  0.2354, -0.5459,  0.0335,  0.1454,\n",
            "        -0.0470,  0.8173], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.322451114654541\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5279,  0.3341,  0.0129, -0.4199,  0.2785, -0.4544,  0.1318,  0.2186,\n",
            "         0.0128,  0.8249], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.353065013885498\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3029,  0.3900,  0.0433, -0.4584,  0.3339, -0.3700, -0.0787,  0.1356,\n",
            "        -0.0061,  0.7154], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.315560817718506\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6098,  0.2653,  0.0415, -0.5533,  0.2469, -0.2781, -0.0122,  0.0627,\n",
            "        -0.1554,  0.8364], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3782119750976562\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3849,  0.4152,  0.0383, -0.4453,  0.2951, -0.3196,  0.1355,  0.2321,\n",
            "        -0.0292,  0.7947], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.390026092529297\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4441,  0.2867, -0.0771, -0.5480,  0.3476, -0.5023,  0.0994,  0.0431,\n",
            "        -0.0087,  1.0306])\n",
            "total_loss 2.3982067108154297\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3571,  0.2709,  0.1672, -0.4219,  0.1971, -0.2912, -0.0226,  0.0242,\n",
            "        -0.0380,  1.0460], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.5078635215759277\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5750,  0.4206,  0.1121, -0.5628,  0.3367, -0.3049,  0.0925,  0.0233,\n",
            "        -0.1147,  0.9801], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.406574249267578\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4578,  0.3679,  0.0050, -0.5684,  0.2787, -0.4704, -0.1465,  0.3029,\n",
            "        -0.2790,  1.1396], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.4511585235595703\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4931,  0.2520, -0.0425, -0.2785,  0.2938, -0.3350,  0.1276,  0.1743,\n",
            "        -0.1329,  0.9007], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2546494007110596\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5122,  0.4753,  0.2151, -0.4611,  0.2059, -0.5138,  0.0399,  0.1277,\n",
            "        -0.0104,  1.0384], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.278597354888916\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2807,  0.3247,  0.1312, -0.3645,  0.3032, -0.5006, -0.1490,  0.2096,\n",
            "        -0.2409,  0.8843], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2763614654541016\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3380,  0.3464,  0.0784, -0.3013,  0.1456, -0.4468,  0.0457,  0.3080,\n",
            "        -0.1542,  0.9057], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2820117473602295\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5601,  0.3469,  0.1754, -0.4687,  0.2086, -0.2903,  0.1850,  0.0373,\n",
            "        -0.2853,  0.9851], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2811269760131836\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5113,  0.5190,  0.2315, -0.5168,  0.3914, -0.4897,  0.0890,  0.1928,\n",
            "        -0.2529,  0.9537], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2682533264160156\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4451,  0.2870, -0.0773, -0.5477,  0.3484, -0.5024,  0.0994,  0.0435,\n",
            "        -0.0087,  1.0317])\n",
            "total_loss 2.348097324371338\n",
            "Saving model (epoch =   26, loss = 2.3481)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6159,  0.2690,  0.0423, -0.5569,  0.2499, -0.2816, -0.0110,  0.0642,\n",
            "        -0.1571,  0.8478], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.20697283744812\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3476,  0.4076, -0.0088, -0.2963,  0.2886, -0.2946,  0.0169,  0.1990,\n",
            "        -0.1378,  1.0388], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.320619583129883\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5867,  0.3948, -0.0549, -0.2653,  0.1364, -0.2638, -0.1035,  0.1233,\n",
            "        -0.0904,  1.0166], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.400054454803467\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5303,  0.3223,  0.1476, -0.5746,  0.1405, -0.4894, -0.0902,  0.0526,\n",
            "         0.0195,  1.0554], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1894102096557617\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4005,  0.5559, -0.0988, -0.3950,  0.1309, -0.2685, -0.1251,  0.3136,\n",
            "        -0.0366,  1.0199], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.190939426422119\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3487,  0.4082, -0.0086, -0.2971,  0.2891, -0.2951,  0.0170,  0.1991,\n",
            "        -0.1384,  1.0406], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2429866790771484\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5733,  0.5422, -0.0239, -0.4411,  0.1725, -0.2559, -0.1309,  0.1334,\n",
            "        -0.2030,  0.7787], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3573880195617676\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4051,  0.3161,  0.0708, -0.3777,  0.2974, -0.3793,  0.1788,  0.2764,\n",
            "        -0.0869,  0.9086], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2760581970214844\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4820,  0.2515,  0.0478, -0.4736,  0.2418, -0.2866,  0.1057,  0.1516,\n",
            "        -0.2209,  0.9941], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3729209899902344\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4461,  0.2874, -0.0773, -0.5478,  0.3491, -0.5024,  0.0995,  0.0435,\n",
            "        -0.0092,  1.0322])\n",
            "total_loss 2.2692203521728516\n",
            "Saving model (epoch =   27, loss = 2.2692)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4059,  0.3166,  0.0708, -0.3781,  0.2978, -0.3796,  0.1789,  0.2765,\n",
            "        -0.0872,  0.9097], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.0995373725891113\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4948,  0.2939,  0.1881, -0.2824,  0.2400, -0.5505,  0.0352,  0.1469,\n",
            "        -0.0501,  0.8334], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1966168880462646\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6623,  0.3817,  0.1804, -0.4308,  0.2360, -0.5436,  0.1560,  0.0412,\n",
            "         0.0143,  0.9935], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.107051372528076\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4648,  0.3719,  0.0060, -0.5729,  0.2825, -0.4740, -0.1453,  0.3042,\n",
            "        -0.2814,  1.1523], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.269313335418701\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2881,  0.3295,  0.1321, -0.3694,  0.3070, -0.5044, -0.1474,  0.2109,\n",
            "        -0.2435,  0.8978], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3326518535614014\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5715,  0.3543,  0.1773, -0.4774,  0.2140, -0.2971,  0.1875,  0.0394,\n",
            "        -0.2892,  1.0077], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.3865981101989746\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2926,  0.2314,  0.0063, -0.3002,  0.1172, -0.3444,  0.0116,  0.0217,\n",
            "        -0.1053,  0.9326], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1760802268981934\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5850,  0.4270,  0.1135, -0.5696,  0.3418, -0.3105,  0.0945,  0.0251,\n",
            "        -0.1180,  0.9993], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.463355302810669\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.2900,  0.3307,  0.1323, -0.3705,  0.3079, -0.5054, -0.1471,  0.2112,\n",
            "        -0.2441,  0.9012], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1751785278320312\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4494,  0.2893, -0.0770, -0.5497,  0.3507, -0.5041,  0.1000,  0.0443,\n",
            "        -0.0102,  1.0382])\n",
            "total_loss 2.2292165756225586\n",
            "Saving model (epoch =   28, loss = 2.2292)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5779,  0.5449, -0.0235, -0.4438,  0.1748, -0.2584, -0.1303,  0.1342,\n",
            "        -0.2049,  0.7867], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.109394073486328\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5764,  0.3294,  0.0355, -0.5510,  0.2216, -0.4453, -0.1435,  0.2094,\n",
            "        -0.1534,  0.9319], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.141726016998291\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5194,  0.5237,  0.2325, -0.5219,  0.3955, -0.4938,  0.0904,  0.1943,\n",
            "        -0.2556,  0.9681], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.419725179672241\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4621,  0.4456,  0.1547, -0.4987,  0.2308, -0.3940,  0.0497,  0.2309,\n",
            "        -0.2160,  1.1028], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1825766563415527\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6257,  0.2751,  0.0436, -0.5633,  0.2546, -0.2871, -0.0091,  0.0662,\n",
            "        -0.1605,  0.8664], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.352980613708496\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5391,  0.5197,  0.2429, -0.3930,  0.4161, -0.5766,  0.1212,  0.2232,\n",
            "        -0.2852,  1.2463], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.231292724609375\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4990,  0.2964,  0.1885, -0.2849,  0.2422, -0.5528,  0.0358,  0.1479,\n",
            "        -0.0516,  0.8411], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.237746238708496\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5767,  0.3576,  0.1780, -0.4811,  0.2164, -0.3002,  0.1885,  0.0404,\n",
            "        -0.2911,  1.0179], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1201653480529785\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4420,  0.5023,  0.0937, -0.5394,  0.2447, -0.3430,  0.1037,  0.1543,\n",
            "        -0.1076,  1.2559], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.101393222808838\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4503,  0.2896, -0.0770, -0.5499,  0.3513, -0.5044,  0.1000,  0.0445,\n",
            "        -0.0107,  1.0395])\n",
            "total_loss 2.2250185012817383\n",
            "Saving model (epoch =   29, loss = 2.2250)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5798,  0.5458, -0.0233, -0.4448,  0.1757, -0.2593, -0.1302,  0.1344,\n",
            "        -0.2059,  0.7896], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1522469520568848\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4932,  0.2586,  0.0496, -0.4817,  0.2471, -0.2934,  0.1079,  0.1538,\n",
            "        -0.2246,  1.0166], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2805798053741455\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5800,  0.5458, -0.0233, -0.4450,  0.1759, -0.2594, -0.1302,  0.1345,\n",
            "        -0.2060,  0.7902], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2664408683776855\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5433,  0.5183,  0.0841, -0.2964,  0.2650, -0.4163, -0.1232,  0.2808,\n",
            "        -0.0875,  0.8742], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2403955459594727\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5419,  0.5214,  0.2433, -0.3952,  0.4176, -0.5784,  0.1217,  0.2238,\n",
            "        -0.2862,  1.2525], grad_fn=<SliceBackward0>)\n",
            "total_loss 1.9486167430877686\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5886,  0.4289,  0.1139, -0.5719,  0.3437, -0.3127,  0.0950,  0.0258,\n",
            "        -0.1194,  1.0067], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.21211314201355\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4507,  0.2896, -0.0769, -0.5501,  0.3517, -0.5047,  0.0999,  0.0447,\n",
            "        -0.0109,  1.0404], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.189751625061035\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5816,  0.3607,  0.1789, -0.4851,  0.2188, -0.3034,  0.1895,  0.0414,\n",
            "        -0.2928,  1.0287], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.2237133979797363\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5371,  0.3261,  0.1484, -0.5788,  0.1443, -0.4926, -0.0892,  0.0535,\n",
            "         0.0168,  1.0675], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1063232421875\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4522,  0.2905, -0.0767, -0.5512,  0.3524, -0.5055,  0.1001,  0.0450,\n",
            "        -0.0114,  1.0434])\n",
            "total_loss 2.1593873500823975\n",
            "Saving model (epoch =   30, loss = 2.1594)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5239,  0.5261,  0.2331, -0.5247,  0.3979, -0.4962,  0.0910,  0.1953,\n",
            "        -0.2572,  0.9767], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1279683113098145\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6687,  0.3850,  0.1810, -0.4342,  0.2396, -0.5469,  0.1567,  0.0426,\n",
            "         0.0119,  1.0050], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.040402412414551\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5834,  0.3617,  0.1792, -0.4863,  0.2196, -0.3044,  0.1898,  0.0418,\n",
            "        -0.2934,  1.0321], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1919193267822266\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.3824,  0.3147,  0.1528, -0.3801,  0.3535, -0.5960,  0.1419,  0.0368,\n",
            "        -0.2655,  1.0335], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.0907440185546875\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5835,  0.3617,  0.1792, -0.4862,  0.2197, -0.3043,  0.1897,  0.0418,\n",
            "        -0.2935,  1.0321], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1029181480407715\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4508,  0.2893, -0.0770, -0.5495,  0.3520, -0.5044,  0.0996,  0.0448,\n",
            "        -0.0111,  1.0397], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.218785285949707\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.7841,  0.5263,  0.0995, -0.3770,  0.4473, -0.4209,  0.1142,  0.2911,\n",
            "        -0.1397,  1.0971], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.270230531692505\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5914,  0.3962, -0.0550, -0.2650,  0.1400, -0.2651, -0.1035,  0.1240,\n",
            "        -0.0926,  1.0222], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.058328628540039\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5916,  0.3963, -0.0550, -0.2651,  0.1401, -0.2652, -0.1035,  0.1240,\n",
            "        -0.0926,  1.0226], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.221827507019043\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4514,  0.2896, -0.0769, -0.5498,  0.3524, -0.5047,  0.0997,  0.0449,\n",
            "        -0.0112,  1.0408])\n",
            "total_loss 2.127405881881714\n",
            "Saving model (epoch =   31, loss = 2.1274)\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5047,  0.2997,  0.1893, -0.2887,  0.2452, -0.5560,  0.0366,  0.1491,\n",
            "        -0.0535,  0.8526], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.121399402618408\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5865,  0.3637,  0.1796, -0.4887,  0.2211, -0.3062,  0.1903,  0.0425,\n",
            "        -0.2945,  1.0388], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.1523637771606445\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6361,  0.2814,  0.0449, -0.5704,  0.2595, -0.2933, -0.0074,  0.0687,\n",
            "        -0.1637,  0.8879], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.191606044769287\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5487,  0.5256,  0.2443, -0.4002,  0.4207, -0.5824,  0.1228,  0.2253,\n",
            "        -0.2885,  1.2666], grad_fn=<SliceBackward0>)\n",
            "total_loss 1.9792511463165283\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5945,  0.3983, -0.0546, -0.2675,  0.1414, -0.2671, -0.1029,  0.1247,\n",
            "        -0.0935,  1.0293], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.076900005340576\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4736,  0.4524,  0.1564, -0.5074,  0.2363, -0.4009,  0.0512,  0.2334,\n",
            "        -0.2199,  1.1264], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.046074628829956\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5547,  0.5257,  0.0858, -0.3058,  0.2702, -0.4235, -0.1212,  0.2831,\n",
            "        -0.0914,  0.8988], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.0878615379333496\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.5915,  0.3671,  0.1804, -0.4928,  0.2232, -0.3092,  0.1914,  0.0434,\n",
            "        -0.2959,  1.0494], grad_fn=<SliceBackward0>)\n",
            "total_loss 2.341221809387207\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.6386,  0.2831,  0.0453, -0.5722,  0.2606, -0.2947, -0.0070,  0.0691,\n",
            "        -0.1645,  0.8929], grad_fn=<SliceBackward0>)\n",
            "total_loss 1.99656081199646\n",
            "x shape is torch.Size([270, 63])\n",
            "x is tensor([ 0.4540,  0.2913, -0.0766, -0.5518,  0.3536, -0.5061,  0.1001,  0.0454,\n",
            "        -0.0120,  1.0460])\n",
            "total_loss 2.083179473876953\n",
            "Saving model (epoch =   32, loss = 2.0832)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-07c5e7cc301a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_loss_record\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdv_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-4ef365126545>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(tr_set, dv_set, model, config, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                           \u001b[0;31m# set model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_set\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0;31m# iterate through the dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# set gradient to zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# move data to device (cpu/cuda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "hsNO9nnXQBvP",
        "outputId": "dd924d4e-daea-44e3-e558-e0440b23920e"
      },
      "source": [
        "plot_learning_curve(model_loss_record, title='deep model')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "3iZTVn5WQFpX",
        "outputId": "6ec25ea9-41a0-4016-b864-76b9aae54a8f"
      },
      "source": [
        "del model\n",
        "# model = NeuralNet(tr_set.dataset.dim).to(device)\n",
        "model = NeuralNet(63).to(device)\n",
        "ckpt = torch.load(config[\n",
        "  'save_path'], map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)\n",
        "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-9bd0692b67f3>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(config[\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQikz3IPiyPf"
      },
      "source": [
        "# **Testing**\n",
        "The predictions of your model on testing set will be stored at `pred.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8cTuQjQQOon",
        "outputId": "89c30cf0-6956-46ac-c914-9ca29c636e34"
      },
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    print('Saving results to {}'.format(file))\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tested_positive'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])\n",
        "\n",
        "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred_63features_32_1_0.003_3000.csv')         # save prediction file to pred.csv"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results to pred_63features_32_1_0.003_3000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfrVxqJanGpE"
      },
      "source": [
        "# **Hints**\n",
        "\n",
        "## **Simple Baseline**\n",
        "* Run sample code\n",
        "\n",
        "## **Medium Baseline**\n",
        "* Feature selection: 40 states + 2 `tested_positive` (`TODO` in dataset)\n",
        "\n",
        "## **Strong Baseline**\n",
        "* Feature selection (what other features are useful?)\n",
        "* DNN architecture (layers? dimension? activation function?)\n",
        "* Training (mini-batch? optimizer? learning rate?)\n",
        "* L2 regularization\n",
        "* There are some mistakes in the sample code, can you find them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tmCwXgpot3t"
      },
      "source": [
        "# **Reference**\n",
        "This code is completely written by Heng-Jui Chang @ NTUEE.  \n",
        "Copying or reusing this code is required to specify the original author.\n",
        "\n",
        "E.g.  \n",
        "Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"
      ]
    }
  ]
}